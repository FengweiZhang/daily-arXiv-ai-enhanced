<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 5]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.SE](#cs.SE) [Total: 21]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Integrating Wearable Data into Process Mining: Event, Case and Activity Enrichment](https://arxiv.org/abs/2512.05203)
*Vinicius Stein Dani,Xixi Lu,Iris Beerepoot*

Main category: cs.DB

TL;DR: 本文探讨了将可穿戴设备数据整合到事件日志中的三种方法，并以真实个人数据为例，讨论了在流程挖掘中融合此类数据的技术与概念挑战。


<details>
  <summary>Details</summary>
Motivation: 为提升个人生产力与福祉，需将来自可穿戴设备的健康数据融入流程挖掘，但如何有效整合尚存挑战。

Method: 提出三种整合方式：(1) 将可穿戴数据作为事件属性；(2) 作为案例属性（按日聚合）；(3) 从可穿戴数据生成新事件（如睡眠、活动）。使用一人的真实智能手表与数字日历数据进行示例说明。

Result: 展示了三种方法在实际数据中的应用，并揭示了各自在技术实现和概念建模上的优劣。

Conclusion: 将可穿戴设备数据融入流程挖掘具有潜力，但仍需解决数据对齐、语义解释及建模范式等技术和概念难题。

Abstract: In this short paper, we explore the enrichment of event logs with data from wearable devices. We discuss three approaches: (1) treating wearable data as event attributes, linking them directly to individual events, (2) treating wearable data as case attributes, using aggregated day-level scores, and (3) introducing new events derived from wearable data, such as sleep episodes or physical activities. To illustrate these approaches, we use real-world data from one person, matching health data from a smartwatch with events extracted from a digital calendar application. Finally, we discuss the technical and conceptual challenges involved in integrating wearable data into process mining for personal productivity and well-being.

</details>


### [2] [Featurized-Decomposition Join: Low-Cost Semantic Joins with Guarantees](https://arxiv.org/abs/2512.05399)
*Sepanta Zeighami,Shreya Shankar,Aditya Parameswaran*

Main category: cs.DB

TL;DR: 本文提出了一种名为Featurized-Decomposition Join（FDJ）的新方法，用于高效执行语义连接操作。该方法通过自动提取文本特征并将其组合为合取范式逻辑表达式，以低成本过滤非匹配元组对，在保持结果质量的同时显著降低大语言模型（LLM）调用开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌入语义相似度的语义连接方法在实践中效果有限，因为语义相似度难以可靠预测连接结果，导致仍需大量调用昂贵的LLM。因此，亟需一种既能大幅降低成本又能保证结果质量的新方法。

Method: FDJ方法利用LLM自动从文本记录中提取关键特征，并将这些特征组合成合取范式的逻辑表达式（称为特征分解），通过廉价的特征比较来有效剪枝非匹配对，同时提供统计结果保证。

Result: 在真实数据集上的实验表明，与当前最先进的方法相比，FDJ可将成本降低多达10倍，同时保持相同的结果质量保证。

Conclusion: FDJ是一种高效且可靠的语义连接方法，通过特征分解机制显著减少了对LLM的依赖，在实际应用中具有重要价值。

Abstract: Large Language Models (LLMs) are being increasingly used within data systems to process large datasets with text fields. A broad class of such tasks involves a semantic join-joining two tables based on a natural language predicate per pair of tuples, evaluated using an LLM. Semantic joins generalize tasks such as entity matching and record categorization, as well as more complex text understanding tasks. A naive implementation is expensive as it requires invoking an LLM for every pair of rows in the cross product. Existing approaches mitigate this cost by first applying embedding-based semantic similarity to filter candidate pairs, deferring to an LLM only when similarity scores are deemed inconclusive. However, these methods yield limited gains in practice, since semantic similarity may not reliably predict the join outcome. We propose Featurized-Decomposition Join (FDJ for short), a novel approach for performing semantic joins that significantly reduces cost while preserving quality. FDJ automatically extracts features and combines them into a logical expression in conjunctive normal form that we call a featurized decomposition to effectively prune out non-matching pairs. A featurized decomposition extracts key information from text records and performs inexpensive comparisons on the extracted features. We show how to use LLMs to automatically extract reliable features and compose them into logical expressions while providing statistical guarantees on the output result-an inherently challenging problem due to dependencies among features. Experiments on real-world datasets show up to 10 times reduction in cost compared with the state-of-the-art while providing the same quality guarantees.

</details>


### [3] [PETGraphDB: A Property Evolution Temporal Graph Data Management System](https://arxiv.org/abs/2512.05417)
*Jinghe Song,Zongyu Zuo,Xuelian Lin,Yang Wang,Shuai Ma*

Main category: cs.DB

TL;DR: PETGraph 是一个面向属性演化时序图（Property Evolution Temporal Graph）的数据管理系统，通过有效的时序属性图模型、高效存储结构和细粒度多级锁机制，在存储空间、事务吞吐量和查询延迟方面显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有图数据管理系统未针对属性频繁变化而拓扑结构稳定的属性演化时序图进行优化，导致建模复杂、查询性能低下。

Method: 提出 PETGraph 系统，采用有效时间时序属性图模型支持 ACID 事务，并设计空间高效的时序属性存储结构与细粒度多级锁定机制以提升查询性能。

Result: 实验表明，PETGraph 的存储空间仅为当前最优方案的33%，在 HTAP 负载下事务吞吐量平均提升58.8倍，查询延迟平均降低267倍。

Conclusion: PETGraph 能高效管理属性演化时序图数据，在建模简洁性与查询性能方面显著优于现有系统，适用于物联网等场景。

Abstract: Temporal graphs are graphs whose nodes and edges, together with their associated properties, continuously change over time. With the development of Internet of Things (IoT) systems, a subclass of the temporal graph, i.e., Property Evolution Temporal Graph, in which the value of properties on nodes or edges changes frequently while the graph's topology barely changes, is growing rapidly. However, existing temporal graph management solutions are not oriented to the Property Evolution Temporal Graph data, which leads to highly complex data modeling and low-performance query processing of temporal graph queries. To solve these problems, we developed PETGraph, a data management system for Property Evolution Temporal Graph data. PETGraph adopts a valid-time temporal property graph data model to facilitate data modeling, supporting ACID features with transactions. To improve temporal graph query performance, we designed a space-efficient temporal property storage and a fine-granularity multi-level locking mechanism. Experimental results show that PETGraph requires, on average, only 33% of the storage space needed by the current best data management solution. Additionally, it achieves an average of 58.8 times higher transaction throughput in HTAP workloads compared to the best current solutions and outperforms them by an average of 267 times in query latency.

</details>


### [4] [Parajudica: An RDF-Based Reasoner and Metamodel for Multi-Framework Context-Dependent Data Compliance Assessments](https://arxiv.org/abs/2512.05453)
*Luc Moreau,Alfred Rossi,Sophie Stalla-Bourdillon*

Main category: cs.DB

TL;DR: Parajudica is an open, modular RDF/SPARQL-based rule system for evaluating data compliance under multiple legal and industry frameworks.


<details>
  <summary>Details</summary>
Motivation: Implementing policy-based data access control (PBAC) is challenging when multiple compliance frameworks apply simultaneously.

Method: An RDF/SPARQL-based rule system with a metamodel to evaluate context-dependent compliance status.

Result: Demonstrated applicability to real-world legal frameworks and industry standards, enabling comparative analysis and supporting compliance enforcement, monitoring, data discovery, and risk assessment.

Conclusion: Parajudica provides a flexible and extensible solution for managing complex, multi-framework data compliance requirements.

Abstract: Motivated by the challenges of implementing policy-based data access control (PBAC) under multiple simultaneously applicable compliance frameworks, we present Parajudica, an open, modular, and extensible RDF/SPARQL-based rule system for evaluating context-dependent data compliance status. We demonstrate the utility of this resource and accompanying metamodel through application to existing legal frameworks and industry standards, offering insights for comparative framework analysis. Applications include compliance policy enforcement, compliance monitoring, data discovery, and risk assessment.

</details>


### [5] [Poodle: Seamlessly Scaling Down Large Language Models with Just-in-Time Model Replacement](https://arxiv.org/abs/2512.05525)
*Nils Strassenburg,Boris Glavic,Tilmann Rabl*

Main category: cs.DB

TL;DR: 本文提出了一种“即时模型替换”（JITR）机制，在检测到大语言模型（LLM）中重复出现的简单任务时，自动将其替换为更轻量、高效的专用模型，从而在保持易用性的同时显著降低成本与能耗。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽易于使用且无需大量训练样本，但在处理简单重复任务时资源和能耗远高于小型专用模型，而后者往往能达到相近性能。因此需要一种兼顾易用性与效率的解决方案。

Method: 提出JITR框架：通过识别LLM调用中的重复任务，透明地替换为针对该任务优化的低成本模型；依赖模型搜索与迁移学习技术快速构建和微调替代模型，并通过原型系统Poodle实现验证。

Result: 在示例任务上，JITR原型系统Poodle实现了显著的成本与能耗节省。

Conclusion: JITR在保留大语言模型易用性的同时，通过动态替换机制有效提升效率，模型搜索与迁移学习是其实现的关键技术。

Abstract: Businesses increasingly rely on large language models (LLMs) to automate simple repetitive tasks instead of developing custom machine learning models. LLMs require few, if any, training examples and can be utilized by users without expertise in model development. However, this comes at the cost of substantially higher resource and energy consumption compared to smaller models, which often achieve similar predictive performance for simple tasks. In this paper, we present our vision for just-in-time model replacement (JITR), where, upon identifying a recurring task in calls to an LLM, the model is replaced transparently with a cheaper alternative that performs well for this specific task. JITR retains the ease of use and low development effort of LLMs, while saving significant cost and energy. We discuss the main challenges in realizing our vision regarding the identification of recurring tasks and the creation of a custom model. Specifically, we argue that model search and transfer learning will play a crucial role in JITR to efficiently identify and fine-tune models for a recurring task. Using our JITR prototype Poodle, we achieve significant savings for exemplary tasks.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [6] [FedGMR: Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity](https://arxiv.org/abs/2512.05372)
*Chengjie Ma,Seungeun Oh,Jihong Park,Seong-Lyun Kim*

Main category: cs.DC

TL;DR: FedGMR 是一种面向带宽受限客户端的联邦学习方法，通过在训练过程中逐步恢复子模型密度，并结合异步和模型异构环境下的掩码感知聚合规则，显著提升了收敛速度与模型精度。


<details>
  <summary>Details</summary>
Motivation: 在异构联邦学习环境中，带宽受限客户端（BCCs）因通信能力有限只能使用小型子模型，初期学习快但后期欠参数化，导致收敛慢、泛化能力差。

Method: 提出 FedGMR 方法，在训练过程中逐步增加各客户端子模型的密度；同时设计适用于异步模型异构联邦学习的掩码感知聚合规则，并提供理论收敛性保证。

Result: 在 FEMNIST、CIFAR-10 和 ImageNet-100 上的实验表明，FedGMR 在高异构性和非独立同分布（non-IID）设置下实现了更快的收敛速度和更高的准确率。

Conclusion: FedGMR 有效缓解了带宽受限客户端在联邦学习中的性能瓶颈，通过渐进式模型恢复机制缩小了与全模型联邦学习的性能差距，具有良好的实用性和鲁棒性。

Abstract: Federated learning (FL) holds strong potential for distributed machine learning, but in heterogeneous environments, Bandwidth-Constrained Clients (BCCs) often struggle to participate effectively due to limited communication capacity. Their small sub-models learn quickly at first but become under-parameterized in later stages, leading to slow convergence and degraded generalization. We propose FedGMR - Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity. FedGMR progressively increases each client's sub-model density during training, enabling BCCs to remain effective contributors throughout the process. In addition, we develop a mask-aware aggregation rule tailored for asynchronous MHFL and provide convergence guarantees showing that aggregated error scales with the average sub-model density across clients and rounds, while GMR provably shrinks this gap toward full-model FL. Extensive experiments on FEMNIST, CIFAR-10, and ImageNet-100 demonstrate that FedGMR achieves faster convergence and higher accuracy, especially under high heterogeneity and non-IID settings.

</details>


### [7] [Are Bus-Mounted Edge Servers Feasible?](https://arxiv.org/abs/2512.05543)
*Xuezhi Li,Jiancong He,Ming Xie,Xuyang Chen,Le Chang,Li Jiang,Gui Gui*

Main category: cs.DC

TL;DR: 本文研究了在城市车联网中利用公交车部署移动边缘服务器的可行性，基于真实轨迹数据验证其覆盖能力，并提出一种贪心算法在预算限制下最大化需求点覆盖，结果表明该方案能有效应对用户需求的时空动态性。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置的边缘服务器（如路侧单元或基站）部署后位置和容量固定，难以应对车联网中用户需求的时空动态变化；而移动服务器（如公交车）可提供计算弹性，提升服务效率。

Method: 利用上海公交、出租车和电信数据集分析公交车与基站的覆盖情况；构建数学模型并设计贪心启发式算法，在有限预算下选择最优公交车队以最大化需求点覆盖；通过轨迹驱动仿真验证算法性能。

Result: 仿真结果表明，所提出的公交车选择算法在服务器容量和采购数量等现实约束下，能有效覆盖动态用户需求，验证了公交搭载边缘服务器的高覆盖潜力。

Conclusion: 在城市车联网环境中，基于公交车的移动边缘服务器具有可行性、效益性和应用价值，可作为固定边缘基础设施的有效补充。

Abstract: Placement of edge servers is the prerequisite of provisioning edge computing services for Internet of Vehicles (IoV). Fixed-site edge servers at Road Side Units (RSUs) or base stations are able to offer basic service coverage for end users, i.e., vehicles on road. However, the server locations and capacity are fixed after deployment, rendering their inefficiency in handling spationtemporal user dynamics. Mobile servers such as buses, on the other hand, have the potential of adding computation elasticity to such system. To this end, this paper studies the feasibility of bus-mounted edge servers based on real traces. First, we investigate the coverage of the buses and base stations using the Shanghai bus/taxi/Telecom datasets, which shows a great potential of bus-based edge servers as they cover a great portion of geographic area and demand points. Next, we build a mathematical model and design a simple greedy heuristic algorithm to select a limited number of buses that maximizes the coverage of demand points, i.e., with a limited purchase budget. We perform trace-driven simulations to verify the performance of the proposed bus selection algorithm. The results show that our approach effectively handles the dynamic user demand under realistic constraints such as server capacity and purchase quantity. Thus, we claim: bus-mounted edge servers for vehicular networks in urban areas are feasible, beneficial, and valuable.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [8] [From Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation](https://arxiv.org/abs/2512.05907)
*Abrar Hossain Mufakir Qamar Ansari Haziq Jeelani Monia Digra Fayeq Jeelani Syed*

Main category: cs.CE

TL;DR: 本研究利用大型语言模型（如Zypher 7B）结合检索增强生成（RAG）与传统金融优化方法，提升投资组合优化与风险管理效果，结果显示Zypher 7B在收益与风险调整表现上优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 传统投资决策方法在处理复杂经济信号和实时数据方面存在局限，而生成式AI（GenAI）有望通过其强大的上下文理解与推理能力，显著改进资产配置与风险管理。

Method: 采用检索增强生成（RAG）管道，将大型语言模型（LLMs）与外部实时金融数据结合，并融合标准金融优化方法；同时输入宏观经济信号以增强模型的上下文感知能力，测试Phi 2、Mistral 7B和Zypher 7B在构建风险意识型共同基金投资策略中的表现。

Result: Zypher 7B模型在所有测试模型中表现最佳，能持续生成高回报且风险调整后收益更优的投资策略，展现出对复杂关系和上下文信息的卓越处理能力。

Conclusion: 生成式AI显著优于传统资产配置方法，将LLM与实际金融应用结合可为资产管理提供更智能、高效和适应性强的解决方案。

Abstract: Generative AI (GenAI) has enormous potential for improving two critical areas in investing, namely portfolio optimization (choosing the best combination of assets) and risk management (protecting those investments). Our study works at this intersection, using Large Language Models (LLMs) to upgrade how financial decisions are traditionally made. This research specifically tested how well advanced LLMs like Microsoft Phi 2, Mistral 7B, and Zypher 7B can create practical, risk-aware strategies for investing mutual funds in different sectors of the economy. Our method is sophisticated: it combines a Retrieval-Augmented Generation (RAG) pipeline, which enables the LLM to check external, real-time data with standard financial optimization methods. The model's advice is context-aware because we feed it large economic signals, like changes in the global economy. The Zypher 7B model was the clear winner. It consistently produced strategies that maximized investment returns while delivering better risk-adjusted results than the other models. Its ability to process complex relationships and contextual information makes it a highly powerful tool for financial allocation. In conclusion, our findings show that GenAI substantially improves performance over basic allocation methods. By connecting GenAI to real-world financial applications, this work lays the groundwork for creating smarter, more efficient, and more adaptable solutions for asset management professionals.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [9] [Stellis: A Strategy Language for Purifying Separation Logic Entailments](https://arxiv.org/abs/2512.05159)
*Zhiyi Wang,Xiwei Wu,Yi Fang,Chengtao Li,Hongyi Zhong,Lihan Xie,Qinxiang Cao,Zhenjiang Hu*

Main category: cs.SE

TL;DR: 本文提出了一种名为Stellis的策略语言，用于自动净化分离逻辑蕴含式，通过强大的匹配机制和灵活的动作描述，有效简化验证过程，并在基准测试中实现了95.6%的自动净化率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则的方法在自动化证明分离逻辑蕴含时存在不足，因为其规则陈述无法充分描述复杂的自动化策略，尤其是在对齐和消除特定场景下对应内存布局方面。

Method: 提出Stellis策略语言，具备强大的匹配机制和灵活的动作描述能力；引入生成策略健全性条件的算法，并基于机械化归约健全性定理实现整体自动化的正确性证明。

Result: 在包含229个蕴含式的基准测试中（来源于标准链式数据结构和微内核内存模块的验证），系统使用5个库中的98个策略，成功自动净化了95.6%（219/229）的蕴含式。

Conclusion: Stellis通过提供灵活且便捷的策略编码方式，在保证健全性的前提下，显著提升了分离逻辑蕴含自动净化的有效性和实用性。

Abstract: Automatically proving separation logic entailments is a fundamental challenge in verification. While rule-based methods rely on separation logic rules (lemmas) for automation, these rule statements are insufficient for describing automation strategies, which usually involve the alignment and elimination of corresponding memory layouts in specific scenarios. To overcome this limitation, we propose Stellis, a strategy language for purifying separation logic entailments, i.e., removing all spatial formulas to reduce the entailment to a simpler pure entailment. Stellis features a powerful matching mechanism and a flexible action description, enabling the straightforward encoding of a wide range of strategies. To ensure strategy soundness, we introduce an algorithm that generates a soundness condition for each strategy, thereby reducing the soundness of each strategy to the correctness of its soundness condition. Furthermore, based on a mechanized reduction soundness theorem, our prototype implementation generates correctness proofs for the overall automation. We evaluate our system on a benchmark of 229 entailments collected from verification of standard linked data structures and the memory module of a microkernel, and the evaluation results demonstrate that, with such flexibility and convenience provided, our system is also highly effective, which automatically purifies 95.6% (219 out of 229) of the entailments using 5 libraries with 98 strategies.

</details>


### [10] [Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge](https://arxiv.org/abs/2512.05176)
*Brittany Johnson,Erin Reddick,Angela D. R. Smith*

Main category: cs.SE

TL;DR: 本文提出了一种名为CIVIQ的新基准，用于评估大型语言模型（LLM）在美国多元文化背景下的文化对齐能力，借鉴了韩国KorNAT基准的构建方法，以更好地反映社区层面的社会价值观和常识。


<details>
  <summary>Details</summary>
Motivation: 当前主流的大型语言模型多以西方白人叙事为中心，缺乏对其他文化和边缘群体经验的对齐；尽管已有如ChatBlackGPT等文化感知模型的尝试，但在开发与评估这类模型方面仍缺乏有效工具，而现有的国家级对齐基准（如强调国家社会价值观的基准）难以代表美国国内的多元文化身份。

Method: 作者通过复制韩国KorNAT国家对齐基准的构建流程，在美国语境下开发了一个聚焦于社区社会价值观与常识的新基准CIVIQ（Cultural Intelligence and Values Inference Quality benchmark）。

Result: 成功构建了CIVIQ基准，为在美国多元文化背景下开发和评估文化对齐的AI系统提供了可行路径和基础工具。

Conclusion: 本研究为在实践中实现AI技术的文化对齐提供了关键基础，强调需超越国家层面、关注更细粒度的社区文化价值观。

Abstract: Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as "general purpose" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of "culturally-informed" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.

</details>


### [11] [A Survey of Bugs in AI-Generated Code](https://arxiv.org/abs/2512.05239)
*Ruofan Gao,Amjed Tahir,Peng Liang,Teo Susnjak,Foutse Khomh*

Main category: cs.SE

TL;DR: 本文系统综述了AI生成代码中的缺陷与错误，分类其类型与模式，并探讨了修复与缓解策略，为未来模型改进和质量评估提供参考。


<details>
  <summary>Details</summary>
Motivation: AI代码生成模型广泛使用，但其生成的代码常包含来自训练数据的缺陷，引发信任与维护问题；目前缺乏对这些问题的系统性总结。

Method: 系统分析现有AI生成代码相关文献，归纳错误类型、分布及其与模型的关系，并总结修复与缓解策略。

Result: 识别并分类了AI生成代码中常见的缺陷类型和模式，揭示了不同模型生成代码中的错误特征，并整理了相应的修复方法。

Conclusion: 对AI生成代码中的缺陷进行系统梳理有助于提升模型质量和开发实践，为后续研究和工具开发提供基础支持。

Abstract: Developers are widely using AI code-generation models, aiming to increase productivity and efficiency. However, there are also quality concerns regarding the AI-generated code. The generated code is produced by models trained on publicly available code, which are known to contain bugs and quality issues. Those issues can cause trust and maintenance challenges during the development process. Several quality issues associated with AI-generated code have been reported, including bugs and defects. However, these findings are often scattered and lack a systematic summary. A comprehensive review is currently lacking to reveal the types and distribution of these errors, possible remediation strategies, as well as their correlation with the specific models. In this paper, we systematically analyze the existing AI-generated code literature to establish an overall understanding of bugs and defects in generated code, providing a reference for future model improvement and quality assessment. We aim to understand the nature and extent of bugs in AI-generated code, and provide a classification of bug types and patterns present in code generated by different models. We also discuss possible fixes and mitigation strategies adopted to eliminate bugs from the generated code.

</details>


### [12] [Model Gateway: Model Management Platform for Model-Driven Drug Discovery](https://arxiv.org/abs/2512.05462)
*Yan-Shiun Wu,Nathan A. Morin*

Main category: cs.SE

TL;DR: 本文介绍了Model Gateway——一个用于药物发现流程中管理机器学习和科学计算模型的平台，集成了大语言模型（LLM）智能体与生成式AI工具，支持动态共识模型、模型注册与管理、异步执行等功能，并在万级并发客户端测试中实现零失败率。


<details>
  <summary>Details</summary>
Motivation: 在药物发现过程中，需要高效管理大量机器学习和科学计算模型，传统MLOps方法难以满足复杂性与扩展性需求，因此亟需一个集成LLM智能体与生成式AI能力的统一模型管理平台。

Method: 开发了Model Gateway平台，包含模型所有者控制面板、平台管理工具和API服务，利用LLM智能体和生成式AI工具实现模型的注册、信息检索、异步提交/执行、结果获取以及动态共识模型构建等MLOps任务。

Result: 平台在超过10,000个并发客户端同时调用模型的压测中实现了0%的失败率，验证了其高可靠性和可扩展性。

Conclusion: Model Gateway作为模型驱动药物发现流程的核心组件，通过成熟的MLOps基础设施与LLM及生成式AI工具的深度集成，有望显著加速新药研发进程。

Abstract: This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools.

</details>


### [13] [Learning to Code with Context: A Study-Based Approach](https://arxiv.org/abs/2512.05242)
*Uwe M. Borghoff,Mark Minas,Jannis Schopp*

Main category: cs.SE

TL;DR: 本文探讨了在大学编程项目中引入生成式AI工具的教学实践，分析学生在软件开发各阶段如何使用AI助手，并评估一种基于RAG、具备项目上下文感知能力的本地部署大语言模型在教育场景中的表现与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具的快速发展，软件工程教育需适应这一趋势，帮助学生在掌握传统开发方法的同时，学会有效且负责任地使用AI技术。项目式课程为探索AI辅助开发提供了理想环境。

Method: 作者在一门大学编程课程中开展用户研究，学生合作开发电脑游戏；通过观察和分析学生在开发过程中对生成式AI工具的使用情况，并进一步测试一个基于检索增强生成（RAG）的本地部署、仓库感知的LLM助手，对其行为、参数敏感性和失败模式进行定性分析。

Result: 研究识别出AI工具在软件开发中最为有效的任务类型及学生面临的主要挑战；同时发现基于RAG的上下文感知AI助手能提供更贴合项目需求的支持，但也存在特定的局限性和失败模式。

Conclusion: 上下文感知的AI辅助工具可有效支持教育场景中的软件开发，研究结果有助于指导未来软件工程课程中AI技术的整合与教学设计。

Abstract: The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively developed computer games. The study investigates how participants used generative AI tools throughout different phases of the software development process, identifies the types of tasks where such tools were most effective, and analyzes the challenges students encountered. Building on these insights, we further examine a repository-aware, locally deployed large language model (LLM) assistant designed to provide project-contextualized support. The system employs Retrieval-Augmented Generation (RAG) to ground responses in relevant documentation and source code, enabling qualitative analysis of model behavior, parameter sensitivity, and common failure modes. The findings deepen our understanding of context-aware AI support in educational software projects and inform future integration of AI-based assistance into software engineering curricula.

</details>


### [14] [Metronome: Differentiated Delay Scheduling for Serverless Functions](https://arxiv.org/abs/2512.05703)
*Zhuangbin Chen,Juzheng Zheng,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文提出 Metronome，一种面向 FaaS 的差异化延迟调度框架，通过在线随机森林回归模型预测函数在不同节点上的执行时间，实现兼顾数据与基础设施局部性的智能调度，在 OpenLambda 上显著降低函数平均执行时间并保障 SLA。


<details>
  <summary>Details</summary>
Motivation: 传统延迟调度在服务器无感知（serverless）环境中效果有限，因其未考虑函数输入特征差异、更复杂的局部性模式（包括数据与基础设施局部性）以及异构执行时间对固定延迟阈值的挑战。

Method: 设计 Metronome 框架，采用在线随机森林回归模型预测各函数在不同节点的执行时间，据此动态决策延迟调度策略，以优化局部性并避免违反服务等级协议（SLA）。

Result: 在 OpenLambda 平台上，Metronome 相比基线方法将函数平均执行时间降低 64.88%–95.83%，在高并发下仍保持性能优势，并满足 SLA 要求。

Conclusion: 针对 serverless 环境中延迟调度的特殊挑战，Metronome 通过预测驱动的差异化调度有效提升性能，验证了局部性优化在 FaaS 中的可行性和重要性。

Abstract: Function-as-a-Service (FaaS) computing is an emerging cloud computing paradigm for its ease-of-management and elasticity. However, optimizing scheduling for serverless functions remains challenging due to their dynamic and event-driven nature. While data locality has been proven effective in traditional cluster computing systems through delay scheduling, its application in serverless platforms remains largely unexplored. In this paper, we systematically evaluate existing delay scheduling methods in serverless environments and identify three key observations: 1) delay scheduling benefits vary significantly based on function input characteristics; 2) serverless computing exhibits more complex locality patterns than cluster computing systems, encompassing both data locality and infrastructure locality; and 3) heterogeneous function execution times make rule-based delay thresholds ineffective. Based on these insights, we propose Metronome, a differentiated delay scheduling framework that employs predictive mechanisms to identify optimal locality-aware nodes for individual functions. Metronome leverages an online Random Forest Regression model to forecast function execution times across various nodes, enabling informed delay decisions while preventing SLA violations. Our implementation on OpenLambda shows that Metronome significantly outperforms baselines, achieving 64.88%-95.83% reduction in mean execution time for functions, while maintaining performance advantages under increased concurrency levels and ensuring SLA compliance.

</details>


### [15] [Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions](https://arxiv.org/abs/2512.05309)
*Adam Alami,Nathan Cassee,Thiago Rocha Silva,Elda Paja,Neil A. Ernst*

Main category: cs.SE

TL;DR: 该研究通过两阶段定性实验（20名软件工程师）比较了人类同行评审与大语言模型（LLM）辅助代码评审中工程师的情感反应、自我调节策略与行为参与差异，发现LLM辅助可降低情感负担并转移关注点至认知负荷管理，提出AI应作为支持性伙伴以减轻认知与情感负担，同时保留人类问责与社会意义。


<details>
  <summary>Details</summary>
Motivation: 理解软件工程师在LLM辅助代码评审与传统人类同行评审中的情感反应、自我调节机制及行为参与方式的差异，填补当前对这一社会技术实践中人-AI协作机制理解的空白。

Method: 采用两阶段定性研究方法：第一阶段让参与者进行同行评审并访谈其情感反应与参与决策；第二阶段引入符合其偏好的新提示，探究不同反馈特征对其反应的影响，并结合情感自我调节理论分析行为参与与问题解决路径。

Result: 识别出工程师应对负面反馈的四种情感自我调节策略（重构、对话调节、回避、防御）；发现同行评审中的参与依赖于社会校准，解决路径受责任主体（个人/双人/团队）和内在意义建构影响；而LLM辅助评审显著降低情感成本与自我调节需求，当反馈符合认知预期时更易被采纳，参与焦点从情绪管理转向认知负荷管理。

Conclusion: LLM在代码评审中最适合作为支持性伙伴，通过减轻认知与情感负担提升效率，但需保留人类在问责机制和社会互动中的核心作用，以维护此类社会技术活动的本质价值。

Abstract: Code review is a socio-technical practice, yet how software engineers engage in Large Language Model (LLM)-assisted code reviews compared to human peer-led reviews is less understood. We report a two-phase qualitative study with 20 software engineers to understand this. In Phase I, participants exchanged peer reviews and were interviewed about their affective responses and engagement decisions. In Phase II, we introduced a new prompt matching engineers' preferences and probed how characteristics shaped their reactions. We develop an integrative account linking emotional self-regulation to behavioral engagement and resolution. We identify self-regulation strategies that engineers use to regulate their emotions in response to negative feedback: reframing, dialogic regulation, avoidance, and defensiveness. Engagement proceeds through social calibration; engineers align their responses and behaviors to the relational climate and team norms. Trajectories to resolution, in the case of peer-led review, vary by locus (solo/dyad/team) and an internal sense-making process. With the LLM-assisted review, emotional costs and the need for self-regulation seem lower. When LLM feedback aligned with engineers' cognitive expectations, participants reported reduced processing effort and a potentially higher tendency to adopt. We show that LLM-assisted review redirects engagement from emotion management to cognitive load management. We contribute an integrative model of engagement that links emotional self-regulation to behavioral engagement and resolution, showing how affective and cognitive processes influence feedback adoption in peer-led and LLM-assisted code reviews. We conclude that AI is best positioned as a supportive partner to reduce cognitive and emotional load while preserving human accountability and the social meaning of peer review and similar socio-technical activities.

</details>


### [16] [WhatsCode: Large-Scale GenAI Deployment for Developer Efficiency at WhatsApp](https://arxiv.org/abs/2512.05314)
*Ke Mao,Timotej Kapus,Cons T Åhs,Matteo Marescotti,Daniel Ip,Ákos Hajdu,Sopot Cela,Aparup Banerjee*

Main category: cs.SE

TL;DR: 该论文介绍了WhatsCode——一个在WhatsApp大规模工业环境中部署的领域特定AI开发系统，展示了其在隐私合规、代码生成和DevOps集成方面的显著成效，并强调有效的人机协作模式及组织因素对AI工具成功落地的关键作用。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辅助开发工具在工业界被广泛采用，但在合规相关的大型工业环境中的部署研究在学术界仍存在显著空白。本文旨在填补这一空白，通过分析WhatsCode在WhatsApp的实际部署经验，提供可推广的实践指导。

Method: 作者报告了WhatsCode在25个月（2023–2025）内的工业部署过程，从隐私自动化逐步演进为集成到端到端功能开发与DevOps流程中的自主智能体工作流，并通过量化指标（如代码变更接受率、隐私验证覆盖率、bug triage精度等）评估其效果，同时识别出两种稳定的人机协作模式。

Result: WhatsCode将自动隐私验证覆盖率提升了3.5倍（从15%到53%），生成了超过3,000个被接受的代码变更，执行了692次自动重构/修复、711次框架采纳和141次功能开发辅助，在bug triage中保持86%的准确率；并识别出“一键发布”（60%）和“接管-修订”（40%）两种人机协作模式。

Conclusion: 在合规敏感的大规模企业环境中，AI工具的成功不仅依赖技术能力，更取决于组织因素（如所有权模型、采用动态和风险管理）；可持续的业务影响源于高效的人机协作，而非完全自动化。

Abstract: The deployment of AI-assisted development tools in compliance-relevant, large-scale industrial environments represents significant gaps in academic literature, despite growing industry adoption. We report on the industrial deployment of WhatsCode, a domain-specific AI development system that supports WhatsApp (serving over 2 billion users) and processes millions of lines of code across multiple platforms. Over 25 months (2023-2025), WhatsCode evolved from targeted privacy automation to autonomous agentic workflows integrated with end-to-end feature development and DevOps processes.
  WhatsCode achieved substantial quantifiable impact, improving automated privacy verification coverage 3.5x from 15% to 53%, identifying privacy requirements, and generating over 3,000 accepted code changes with acceptance rates ranging from 9% to 100% across different automation domains. The system committed 692 automated refactor/fix changes, 711 framework adoptions, 141 feature development assists and maintained 86% precision in bug triage. Our study identifies two stable human-AI collaboration patterns that emerged from production deployment: one-click rollout for high-confidence changes (60% of cases) and commandeer-revise for complex decisions (40%). We demonstrate that organizational factors, such as ownership models, adoption dynamics, and risk management, are as decisive as technical capabilities for enterprise-scale AI success. The findings provide evidence-based guidance for large-scale AI tool deployment in compliance-relevant environments, showing that effective human-AI collaboration, not full automation, drives sustainable business impact.

</details>


### [17] [Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering](https://arxiv.org/abs/2512.05350)
*Munazza Zaib,Wei Wang,Dulaji Hidellaarachchi,Isma Farah Siddiqui*

Main category: cs.SE

TL;DR: 本文提出一种结合InclusiveMag包容性框架与GenderMag走查流程的混合方法，以系统研究软件工程领域神经多样性女性所面临的独特挑战，并通过三阶段设计（文献综述、构建用户画像与分析流程、协作工作坊）推动包容性实践。


<details>
  <summary>Details</summary>
Motivation: 神经多样性女性在软件工程中面临性别偏见与神经差异交织的特殊障碍，如误诊/晚诊、伪装行为及以男性为中心的职场文化，导致压力、倦怠与离职率上升；而现有软件工程研究尚未系统关注该群体。

Method: 采用混合方法论，整合InclusiveMag包容性框架与GenderMag走查流程，分三阶段进行：通过文献综述界定问题范围，提炼用户画像与分析流程，并在协作工作坊中应用该方法。

Result: 通过针对性文献综述，将神经多样性女性在软件工程中面临的挑战归纳为认知、社交、组织、结构性及职业发展五大类，并揭示了诊断不足与伪装行为如何加剧排斥现象，为后续开发包容性分析工具奠定基础。

Conclusion: 本研究为理解和应对神经多样性女性在软件工程中的多重障碍提供了系统性方法，未来将基于此开发可操作的包容性分析手段，以促进职场公平与多样性。

Abstract: Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.

</details>


### [18] [Legacy Modernization with AI -- Mainframe modernization](https://arxiv.org/abs/2512.05375)
*Sunil Khemka,Arunava Majumdar*

Main category: cs.SE

TL;DR: AI-assisted modernization transforms legacy mainframe systems into agile, cloud-compatible architectures by leveraging automated refactoring, intelligent data migration, and predictive maintenance to boost efficiency and innovation.


<details>
  <summary>Details</summary>
Motivation: Legacy mainframe systems, though reliable, face challenges like high maintenance costs, skill shortages, and poor integration with modern cloud environments, necessitating a shift toward more flexible and scalable solutions.

Method: The paper proposes AI-driven strategies including automated code refactoring, smart data migration tools, predictive maintenance, and machine learning models to analyze legacy code, optimize performance, and enable automated testing and deployment.

Result: Organizations can successfully transition to microservices, containerized setups, and hybrid clouds, achieving improved operational efficiency, anomaly detection, workload balancing, and system resilience.

Conclusion: Integrating AI into mainframe modernization not only preserves critical business logic but also accelerates digital transformation, reduces downtime, and supports sustainable enterprise growth.

Abstract: Artificial Intelligence-assisted legacy modernization is essential in changing the stalwart mainframe systems of the past into flexible, scalable, and smart architecture. While mainframes are generally dependable, they can be difficult to maintain due to their high maintenance costs, the shortage of skills, and the problems in integrating them with cloud-based systems. By adopting AI-driven modernization strategies such as automated code refactoring, migration of data using smart tools, and predictive maintenance, companies can easily move to microservices, containerized environments, and hybrid cloud platforms. Machine learning models have the capability to go through legacy codebases, figure out efficiency opportunities, and carry out automated testing and deployment. Besides that, AI improves the organization's operational efficiency by generating the insights that can be used to level the workload and detect the anomalies. The coupling of the two is not only about saving the core business logic but also about enabling quicker innovation, less downtime, and enhanced system resilience. Therefore, the use of AI in mainframe modernization is a catalyst for digital transformation and enterprise growth that is sustainable over time.

</details>


### [19] [Fuzzing the brain: Automated stress testing for the safety of ML-driven neurostimulation](https://arxiv.org/abs/2512.05383)
*Mara Downing,Matthew Peng,Jacob Granley,Michael Beyeler,Tevfik Bultan*

Main category: cs.SE

TL;DR: 本文提出一种基于覆盖引导模糊测试的系统性方法，用于检测机器学习驱动的神经刺激系统中不安全的电刺激模式，并通过两个覆盖指标有效识别多种违反生物物理安全限制的输出。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在神经假体（如视觉假体）中用于生成电刺激模式，虽具个性化优势，但其直接输出至神经组织可能带来新的安全风险，亟需系统化、可量化的安全评估方法。

Method: 将软件工程中的覆盖引导模糊测试技术适配到神经刺激领域，通过扰动模型输入并追踪输出是否违反电荷密度、瞬时电流或电极共激活等生物物理安全限制；将编码器视为黑盒，并利用覆盖度量引导测试用例探索输出空间和违规类型。

Result: 在视网膜和皮层深度刺激编码器上的实验表明，该方法能系统揭示多种超出安全限值的刺激模式；其中两种违规-输出覆盖度量在发现违规数量和多样性方面表现最优，支持对不同架构和训练策略的可解释比较。

Conclusion: 以违规为中心的模糊测试将安全性评估转化为可复现的实证过程，使安全成为部署模型的可测量属性，为下一代神经接口的基准测试、监管合规与伦理保障奠定基础。

Abstract: Objective: Machine learning (ML) models are increasingly used to generate electrical stimulation patterns in neuroprosthetic devices such as visual prostheses. While these models promise precise and personalized control, they also introduce new safety risks when model outputs are delivered directly to neural tissue. We propose a systematic, quantitative approach to detect and characterize unsafe stimulation patterns in ML-driven neurostimulation systems. Approach: We adapt an automated software testing technique known as coverage-guided fuzzing to the domain of neural stimulation. Here, fuzzing performs stress testing by perturbing model inputs and tracking whether resulting stimulation violates biophysical limits on charge density, instantaneous current, or electrode co-activation. The framework treats encoders as black boxes and steers exploration with coverage metrics that quantify how broadly test cases span the space of possible outputs and violation types. Main results: Applied to deep stimulus encoders for the retina and cortex, the method systematically reveals diverse stimulation regimes that exceed established safety limits. Two violation-output coverage metrics identify the highest number and diversity of unsafe outputs, enabling interpretable comparisons across architectures and training strategies. Significance: Violation-focused fuzzing reframes safety assessment as an empirical, reproducible process. By transforming safety from a training heuristic into a measurable property of the deployed model, it establishes a foundation for evidence-based benchmarking, regulatory readiness, and ethical assurance in next-generation neural interfaces.

</details>


### [20] [Bita: A Conversational Assistant for Fairness Testing](https://arxiv.org/abs/2512.05428)
*Keeryn Johnson,Cleyton Magalhaes,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 本文提出了Bita——一个基于大语言模型的对话式助手，用于支持软件测试人员在实际工作中开展公平性测试，帮助识别偏见来源、评估测试计划并生成探索性测试章程。


<details>
  <summary>Details</summary>
Motivation: 现有公平性测试工具难以使用，通常需要高级专业知识且对现实工作流程支持有限，因此亟需一种更易用、系统化且适用于工业实践的解决方案。

Method: Bita结合了大语言模型与检索增强生成技术，其回答基于精选的公平性文献，以支持测试人员执行公平性测试任务。

Result: 验证表明，Bita能在真实AI系统中有效支持公平性测试，并提供结构化、可复现的证据证明其效用。

Conclusion: 本研究贡献了一个实用工具Bita，使公平性测试变得易于访问、系统化，并可直接应用于工业实践。

Abstract: Bias in AI systems can lead to unfair and discriminatory outcomes, especially when left untested before deployment. Although fairness testing aims to identify and mitigate such bias, existing tools are often difficult to use, requiring advanced expertise and offering limited support for real-world workflows. To address this, we introduce Bita, a conversational assistant designed to help software testers detect potential sources of bias, evaluate test plans through a fairness lens, and generate fairness-oriented exploratory testing charters. Bita integrates a large language model with retrieval-augmented generation, grounding its responses in curated fairness literature. Our validation demonstrates how Bita supports fairness testing tasks on real-world AI systems, providing structured, reproducible evidence of its utility. In summary, our work contributes a practical tool that operationalizes fairness testing in a way that is accessible, systematic, and directly applicable to industrial practice.

</details>


### [21] [Everything is Context: Agentic File System Abstraction for Context Engineering](https://arxiv.org/abs/2512.05470)
*Xiwei Xu,Robert Mao,Quan Bai,Xuewu Gu,Yechao Li,Liming Zhu*

Main category: cs.SE

TL;DR: 本文提出一种受Unix“一切皆文件”理念启发的上下文工程文件系统抽象，通过统一挂载、元数据和访问控制，为生成式AI系统提供可追溯、可验证且以人类为中心的上下文管理架构，并在AIGNE框架中实现。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI将基础模型作为预训练子系统集成到软件系统中，系统设计的核心挑战已从模型微调转向上下文工程——即如何有效捕获、组织和治理外部知识、记忆、工具与人类输入，以支持可信推理。然而，当前的实践（如提示工程、RAG和工具集成）仍处于碎片化状态，缺乏持久性和可问责性。

Method: 作者提出一种基于文件系统抽象的上下文工程架构，借鉴Unix“一切皆文件”的思想，通过统一接口管理异构上下文构件，并在开源AIGNE框架中实现，包含上下文构造器、加载器和评估器三个组件，在令牌限制下完成上下文的组装、交付与验证。

Result: 该架构在两个示例中得到验证：具备记忆能力的智能体和基于MCP的GitHub助手，展示了其在开发者和工业环境中构建可验证、可维护且适用于产业级生成式AI系统的可行性。

Conclusion: 所提出的文件系统抽象为上下文工程提供了可复用、可治理的基础，强化了人类在AI协作中的核心角色（如策展人、验证者和共同推理者），推动了负责任且以人为中心的生成式AI协同工作范式。

Abstract: Generative AI (GenAI) has reshaped software system design by introducing foundation models as pre-trained subsystems that redefine architectures and operations. The emerging challenge is no longer model fine-tuning but context engineering-how systems capture, structure, and govern external knowledge, memory, tools, and human input to enable trustworthy reasoning. Existing practices such as prompt engineering, retrieval-augmented generation (RAG), and tool integration remain fragmented, producing transient artefacts that limit traceability and accountability. This paper proposes a file-system abstraction for context engineering, inspired by the Unix notion that 'everything is a file'. The abstraction offers a persistent, governed infrastructure for managing heterogeneous context artefacts through uniform mounting, metadata, and access control. Implemented within the open-source AIGNE framework, the architecture realises a verifiable context-engineering pipeline, comprising the Context Constructor, Loader, and Evaluator, that assembles, delivers, and validates context under token constraints. As GenAI becomes an active collaborator in decision support, humans play a central role as curators, verifiers, and co-reasoners. The proposed architecture establishes a reusable foundation for accountable and human-centred AI co-work, demonstrated through two exemplars: an agent with memory and an MCP-based GitHub assistant. The implementation within the AIGNE framework demonstrates how the architecture can be operationalised in developer and industrial settings, supporting verifiable, maintainable, and industry-ready GenAI systems.

</details>


### [22] [A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language Models](https://arxiv.org/abs/2512.05498)
*Xiao He,Ru Chen,Zeqing Zhang,Yanling Wang,Qiuyan Dong*

Main category: cs.SE

TL;DR: 本文提出iEcoreGen，一种结合Eclipse建模框架（EMF）与大语言模型（LLM）的混合代码生成方法，在保证结构正确性的同时提升灵活性。


<details>
  <summary>Details</summary>
Motivation: 模板化代码生成虽能保证正确性但缺乏灵活性，而LLM虽灵活却可能生成错误代码。为兼顾两者优势，作者提出融合二者的方法。

Method: iEcoreGen首先基于Ecore模型分解需求并生成操作规范，利用EMF模板生成初始Java代码，并将规范序列化为文档字符串；随后调用LLM补全和修复未实现的方法。

Result: 在20个任务上对5个LLM的评估表明，iEcoreGen在pass@k指标上优于纯LLM基线，在compilation@k上表现相当；消融实验验证了各组件的有效性。

Conclusion: 结合LLM的模型驱动开发是一种有前景的软件自动化路径，能在保持结构约束的同时提升生成灵活性。

Abstract: Template-based and LLM-based code generation are both key enablers of automated software development. The former provides correctness guarantees but are rigid for complex requirements, whereas LLMs offer high flexibility at the risk of producing faulty code.This paper proposes iEcoreGen, a hybrid approach that integrates Eclipse Modeling Framework (EMF) and LLMs. In EMF, an Ecore model defines a system structure and acts as a blueprint for code-generation.iEcoreGen decomposes requirements to derive operation specifications, uses EMF's template-based generator to produce initial Java code, and serializes specifications into docstrings. LLMs are then invoked to complete and fix unimplemented methods. We assessed iEcoreGen on twenty code-generation tasks across five LLMs. It surpasses LLM-only baselines on pass@k and performs on par with them on compilation@k. An ablation study clarified the contribution of each component of iEcoreGen. Overall, the findings indicate that LLM-enhanced model-driven development is a promising path toward more efficient software automation.

</details>


### [23] [Generative AI in Simulation-Based Test Environments for Large-Scale Cyber-Physical Systems: An Industrial Study](https://arxiv.org/abs/2512.05507)
*Masoud Sadrnezhaad,José Antonio Hernández López,Torvald Mårtensson,Daniel Varro*

Main category: cs.SE

TL;DR: 本文探讨了生成式AI在大规模信息物理系统仿真测试中的应用潜力与挑战，基于六家企业的跨公司研讨会，提出了三项高优先级研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大规模信息物理系统的复杂性增加，开发和维护仿真模型所需资源日益庞大；尽管生成式AI已在软件测试中展现价值，但其在仿真测试中的应用仍缺乏深入研究。

Method: 通过组织六家企业的跨公司研讨会，收集并分析从业者对生成式AI在仿真测试中应用的看法与经验。

Result: 识别出工程师在实践中面临的关键挑战，并提出三项高优先级研究方向：(a) AI生成的场景与环境模型，(b) 仿真器与CI/CD流水线中的AI集成，(c) 生成式AI在仿真中的可信度问题。

Conclusion: 生成式AI在仿真测试中具有巨大潜力，但仍存在未解决的挑战；本文旨在引导学术界与工业界合作，推动其负责任地应用。

Abstract: Quality assurance for large-scale cyber-physical systems relies on sophisticated test activities using complex test environments investigated with the help of numerous types of simulators. As these systems grow, extensive resources are required to develop and maintain simulation models of hardware and software components, as well as physical environments. Meanwhile, recent advances in generative AI have led to tools that can produce executable test cases for software systems, offering potential benefits such as reducing manual efforts or increasing test coverage. However, the application of generative AI techniques to simulation-based testing of large-scale cyber-physical systems remains underexplored. To better understand this gap, this study captures practitioners' perspectives on leveraging generative AI, based on a cross-company workshop with six organizations. Our contribution is twofold: (1) detailed, experience-based insights into challenges faced by engineers, and (2) a research agenda comprising three high-priority directions: (a) AI-generated scenarios and environment models, (b) simulators and AI in CI/CD pipelines, and (c) trustworthiness in generative AI for simulation. While participants acknowledged substantial potential, they also highlighted unresolved challenges. By detailing these issues, the paper aims to guide future academia-industry collaboration towards the responsible adoption of generative AI in simulation-based testing.

</details>


### [24] [From Challenge to Change: Design Principles for AI Transformations](https://arxiv.org/abs/2512.05533)
*Theocharis Tavantzis,Stefano Lambiase,Daniel Russo,Robert Feldt*

Main category: cs.SE

TL;DR: 本文提出一个基于行为软件工程（BSE）的人本框架，以支持软件工程组织在早期采用人工智能（AI）时应对技术与非技术挑战。该框架包含九个维度，并通过文献综述、访谈、问卷调查（N=105）和专家研讨会（N=4）进行构建与验证，强调技能提升和AI战略设计的重要性，为AI在软件工程中的人本整合提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究指出AI整合中的行为与非技术因素，但多数仍聚焦于技术问题，缺乏对团队如何适应并信任AI的深入理解。因此，亟需一个以人为本的框架来指导组织在早期AI采用阶段兼顾社会与技术层面。

Method: 采用混合方法：首先通过组织变革模型的文献综述和访谈数据的主题分析构建并完善框架；随后通过一项包含105名从业者的问卷调查和两场共4位专家参与的工作坊收集初步反馈，验证框架的实用性与重点维度。

Result: 框架包含九个维度：AI战略设计、AI战略评估、协作、沟通、治理与伦理、领导力、组织文化、组织动态和技能提升。调查显示，从业者最重视“技能提升”（15.2%）和“AI战略设计”（15.1%）。当前组织更关注程序性要素，而人本保障机制尚不成熟。

Conclusion: 本研究通过识别关键行为维度并提供可操作建议，为软件工程组织在早期AI采纳中应对社会技术复杂性提供了实用路线图，并指出了未来在人本AI方向的研究路径。

Abstract: The rapid rise of Artificial Intelligence (AI) is reshaping Software Engineering (SE), creating new opportunities while introducing human-centered challenges. Although prior work notes behavioral and other non-technical factors in AI integration, most studies still emphasize technical concerns and offer limited insight into how teams adapt to and trust AI. This paper proposes a Behavioral Software Engineering (BSE)-informed, human-centric framework to support SE organizations during early AI adoption. Using a mixed-methods approach, we built and refined the framework through a literature review of organizational change models and thematic analysis of interview data, producing concrete, actionable steps. The framework comprises nine dimensions: AI Strategy Design, AI Strategy Evaluation, Collaboration, Communication, Governance and Ethics, Leadership, Organizational Culture, Organizational Dynamics, and Up-skilling, each supported by design principles and actions. To gather preliminary practitioner input, we conducted a survey (N=105) and two expert workshops (N=4). Survey results show that Up-skilling (15.2%) and AI Strategy Design (15.1%) received the highest $100-method allocations, underscoring their perceived importance in early AI initiatives. Findings indicate that organizations currently prioritize procedural elements such as strategy design, while human-centered guardrails remain less developed. Workshop feedback reinforced these patterns and emphasized the need to ground the framework in real-world practice. By identifying key behavioral dimensions and offering actionable guidance, this work provides a pragmatic roadmap for navigating the socio-technical complexity of early AI adoption and highlights future research directions for human-centric AI in SE.

</details>


### [25] [Automated Code Review Assignments: An Alternative Perspective of Code Ownership on GitHub](https://arxiv.org/abs/2512.05551)
*Jai Lal Lulla,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 本文首次对 GitHub 的 CODEOWNERS 功能进行了大规模实证研究，分析其在超过 84.4 万次 Pull Request 中的使用情况。研究发现，代码所有者普遍遵守规则、行为模式与传统所有权指标一致，并有助于提升 PR 流程效率；采用 CODEOWNERS 后，审查责任从核心开发者向更广泛群体转移，表明该机制在提升软件治理和韧性方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 随着软件供应链攻击等外部威胁增加，确保代码问责制和质量变得愈发重要。GitHub 在 2017 年推出 CODEOWNERS 功能以加强关键代码部分的责任归属，但其实际采用和效果尚不清楚。

Method: 对超过 844,000 次 Pull Request（含 190 万条评论和 200 多万次审查）进行大规模实证分析，识别出 10,287 名代码所有者并追踪其审查行为；采用断点回归设计（RDD）分析 CODEOWNERS 对审查动态的影响。

Result: 代码所有者普遍遵守 CODEOWNERS 文件中的规则，其协作行为与传统所有权指标相似，且有助于实现更顺畅、更快速的 PR 流程；CODEOWNERS 的引入使审查责任从核心开发者向外扩散。

Conclusion: CODEOWNERS 是一种有前景但尚未被充分利用的机制，可提升开源项目的软件治理、安全性和流程效率，值得项目采纳以增强问责制与开发韧性。

Abstract: Code ownership is central to ensuring accountability and maintaining quality in large-scale software development. Yet, as external threats such as software supply chain attacks on project health and quality assurance increase, mechanisms for assigning and enforcing responsibility have become increasingly critical. In 2017, GitHub introduced the CODEOWNERS feature, which automatically designates reviewers for specific files to strengthen accountability and protect critical parts of the codebase. Despite its potential, little is known about how CODEOWNERS is actually adopted and practiced. We present the first large-scale empirical study of CODEOWNERS usage across over 844,000 pull requests with 1.9 million comments and over 2 million reviews. We identify 10,287 code owners to track their review activities. Results indicate that codeowners tend to adhere the rules specified in the CODEOWNERS file, exhibit similar collaborative behaviours to traditional metrics of ownership, but tend to contribute to a smoother and faster PR workflow over time. Finally, using regression discontinuity design (RDD) analysis, we find that repositories adopting CODEOWNERS experience shifts in review dynamics, as ownership redistributes review responsibilities away from core developers. Our results position CODEOWNERS as a promising yet underutilized mechanism for improving software governance and resilience. We discuss how projects can leverage this alternative ownership method as a perspective to enhance security, accountability, and workflow efficiency in open-source development.

</details>


### [26] [Executing Discrete/Continuous Declarative Process Specifications via Complex Event Processing](https://arxiv.org/abs/2512.05653)
*Stefan Schönig,Leo Poss,Fabrizio Maria Maggi*

Main category: cs.SE

TL;DR: 本文提出了一种基于复杂事件处理（CEP）的三层执行架构，将信号时序逻辑（STL）融入业务流程执行中，以实现实时监控与控制混合声明式模型。


<details>
  <summary>Details</summary>
Motivation: 传统业务流程管理（BPM）仅关注离散事件，无法有效整合信息物理环境中关键的连续传感器数据；现有混合声明式方法虽能描述离散与连续行为，但仅限于事后监测，缺乏实时执行能力。

Method: 设计了一种基于复杂事件处理（CEP）的三层执行架构，将受信号时序逻辑（STL）启发的谓词嵌入执行流程中，实现对混合声明式模型的实时触发与边界控制。

Result: 该架构能够根据连续传感器数据主动触发流程活动并强制执行过程边界，从而在混合规范与运行控制之间建立桥梁。

Conclusion: 所提出的架构成功实现了混合声明式业务流程的实时执行与控制，弥补了现有方法在操作层面的不足。

Abstract: Traditional Business Process Management (BPM) focuses on discrete events and fails to incorporate critical continuous sensor data in cyber-physical environments. Hybrid declarative specifications, utilizing Signal Temporal Logic (STL), address this limitation by allowing constraints over both discrete events and real-valued signals. However, existing work has been limited to monitoring and post-hoc conformance checking. This paper introduces a novel Complex Event Processing (CEP)-based execution architecture that enables the real-time execution and enforcement of hybrid declarative models. Our three-layer approach integrates STL-inspired predicates into the execution flow, allowing the system to actively trigger activities and enforce process boundaries based on continuous sensor behavior. This approach bridges the gap between hybrid specification and operational control.

</details>


### [27] [MicroRacer: Detecting Concurrency Bugs for Cloud Service Systems](https://arxiv.org/abs/2512.05716)
*Zhiling Deng,Juepeng Wang,Zhuangbin Chen*

Main category: cs.SE

TL;DR: MicroRacer 是一种非侵入式、自动化的并发缺陷检测框架，通过动态插桩常用库收集运行时追踪数据，分析操作间的 happens-before 关系和资源访问模式，并结合三阶段验证流程有效识别微服务系统中的并发缺陷。


<details>
  <summary>Details</summary>
Motivation: 现代云应用常基于微服务架构，用户请求穿越多个服务和机器，导致复杂的交互，使系统易受并发缺陷影响；而现有检测方法因侵入性强且难以应对微服务架构复杂性而效果有限。

Method: MicroRacer 在运行时动态插桩广泛使用的库以收集详细追踪数据，无需修改应用代码；利用这些数据解析操作的 happens-before 关系与资源访问模式，识别可疑并发操作，并通过三阶段验证流程确认缺陷。

Result: 在包含复现工业级缺陷的开源微服务基准测试中，MicroRacer 能高效准确地检测并定位并发问题。

Conclusion: MicroRacer 为微服务系统提供了一种非侵入、自动化且高效的并发缺陷检测方案，显著提升了云服务系统的可靠性保障能力。

Abstract: Modern cloud applications delivering global services are often built on distributed systems with a microservice architecture. In such systems, end-to-end user requests traverse multiple different services and machines, exhibiting intricate interactions. Consequently, cloud service systems are vulnerable to concurrency bugs, which pose significant challenges to their reliability. Existing methods for concurrency bug detection often fall short due to their intrusive nature and inability to handle the architectural complexities of microservices. To address these limitations, we propose MicroRacer, a non-intrusive and automated framework for detecting concurrency bugs in such environments. By dynamically instrumenting widely-used libraries at runtime, MicroRacer collects detailed trace data without modifying the application code. Such data are utilized to analyze the happened-before relationship and resource access patterns of common operations within service systems. Based on this information, MicroRacer identifies suspicious concurrent operations and employs a three-stage validation process to test and confirm concurrency bugs. Experiments on open-source microservice benchmarks with replicated industrial bugs demonstrate MicroRacer's effectiveness and efficiency in accurately detecting and pinpointing concurrency issues.

</details>


### [28] [Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models](https://arxiv.org/abs/2512.05887)
*Sairam Vaidya,Marcel Böhme,Loris D'Antoni*

Main category: cs.SE

TL;DR: 本文提出了一种适用于可扩展编译器（如MLIR）的方言无关且高效的模糊测试方法，通过自动提取方言文法并结合大语言模型生成多样化种子输入，显著提升了测试覆盖率并发现了大量未知漏洞。


<details>
  <summary>Details</summary>
Motivation: 现代可扩展编译器框架（如MLIR）支持快速创建领域特定语言方言，但其灵活性使得正确性验证变得困难。现有测试方法要么依赖人工构建的种子语料库，要么无法有效覆盖方言特有特性，难以兼顾方言无关性和有效性。

Method: 提出一种基于文法和覆盖引导的模糊测试方法：（1）从方言规范中自动提取编码了结构与类型约束的文法；（2）结合预训练大语言模型，无需人工干预即可从整个方言空间自动生成具有代表性和多样性的种子输入，并用于引导覆盖导向的模糊测试。

Result: 在涵盖91个方言的6个MLIR项目上评估表明，Germinator生成的种子相比基于文法的基线方法提升10%-120%的行覆盖率；共发现88个新漏洞（40个已确认），其中23个位于此前无自动化测试工具的方言中。

Conclusion: 该方法实现了对低资源方言的大规模、高效且可控的自动化测试，解决了可扩展编译器中方言测试的可扩展性与有效性难题。

Abstract: Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR's heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.

</details>


### [29] [Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures](https://arxiv.org/abs/2512.05908)
*Amirkia Rafiei Oskooei,S. Selcan Yukcu,Mehmet Cevheri Bozoglan,Mehmet S. Aktas*

Main category: cs.SE

TL;DR: 该论文提出将多仓库微服务架构中的缺陷定位问题转化为自然语言推理任务，通过构建代码库的分层自然语言摘要并执行自然语言到自然语言的检索，在工业级系统DNext上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 在多仓库微服务架构中，缺陷定位面临自然语言缺陷报告与代码之间的语义鸿沟、大语言模型上下文限制以及需先识别正确仓库等挑战。

Method: 将代码库转换为文件级、目录级和仓库级的上下文感知自然语言摘要，采用两阶段搜索策略：首先将缺陷报告路由到相关仓库，然后在目标仓库内自顶向下进行定位。

Result: 在包含46个仓库和110万行代码的工业系统DNext上，该方法达到Pass@10为0.82、MRR为0.50，显著优于传统检索基线和GitHub Copilot、Cursor等基于RAG的智能体系统。

Conclusion: 工程化的自然语言表示比原始源代码更适用于可扩展的缺陷定位，其提供的“仓库→目录→文件”可解释搜索路径有助于提升企业级AI工具的透明度与可信度。

Abstract: Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.

</details>
