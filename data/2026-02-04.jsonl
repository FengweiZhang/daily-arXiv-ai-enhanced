{"id": "2602.02892", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02892", "abs": "https://arxiv.org/abs/2602.02892", "authors": ["Zhuolun Xiang", "Andrei Tonkikh", "Alexander Spiegelman"], "title": "Prefix Consensus For Censorship Resistant BFT", "comment": null, "summary": "Despite broad use of BFT consensus in blockchains, censorship resistance is weak: leaders can exclude transactions, a growing concern for trading and DeFi.\n  We address this by introducing a new abstraction and protocol stack. First, we introduce \\emph{Prefix Consensus}, where parties input vectors and output $(v^{\\sf low},v^{\\sf high})$ that (i) extend the maximum common prefix of honest inputs and (ii) satisfy $v_i^{\\sf low}\\preceq v_j^{\\sf high}$ for all honest $i,j$. Unlike classical consensus, no single output is required. We show Prefix Consensus is solvable asynchronously and give tight round-complexity bounds.\n  We then define \\emph{Strong Prefix Consensus}, requiring agreement on the \\emph{high} output. Our protocol is leaderless and partially synchronous: one Prefix Consensus instance decides (possibly different) lows, and additional instances yield a unique safe-to-extend high, even if an adversary can suspend one party per round.\n  We lift this to a leaderless, multi-proposer, censorship-resistant BFT SMR protocol: per slot, all parties broadcast proposals, deterministically rank them, and run one Strong Prefix Consensus on proposal hashes, committing honest proposals in \\emph{four rounds}. A deterministic demotion rule updates the ranking when a party's proposal is excluded, implying that after GST at most $f$ slots can miss an honest proposal while progress remains leaderless under suspension and up to $f{-}1$ Byzantine faults.\n  Finally, we connect Prefix Consensus to graded and binary/validated consensus: we obtain an optimal-latency graded consensus (3 message delays) and leaderless Binary/Validated Consensus with worst-case message complexity $O(n^3)$ and communication $O(n^4)$."}
{"id": "2602.02987", "categories": ["cs.DC", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.02987", "abs": "https://arxiv.org/abs/2602.02987", "authors": ["Ruihan Lin", "Zezhen Ding", "Zean Han", "Jiheng Zhang"], "title": "Large-Scale LLM Inference with Heterogeneous Workloads: Prefill-Decode Contention and Asymptotically Optimal Control", "comment": null, "summary": "Large Language Models (LLMs) are rapidly becoming critical infrastructure for enterprise applications, driving unprecedented demand for GPU-based inference services. A key operational challenge arises from the two-phase nature of LLM inference: a compute-intensive \\emph{prefill} phase that processes user input, followed by a memory-bound \\emph{decode} phase that generates output tokens. When these phases share GPU resources, prefill tasks throttle the processing speed of concurrent decodes, creating state-dependent contention. This contention is further complicated by workload heterogeneity, as different applications exhibit vastly different input and output lengths. We develop a stochastic control framework for scheduling heterogeneous LLM workloads across large GPU clusters. We formulate LLM inference as a multiclass many-server queueing network with state-dependent service rates, grounded in empirical iteration-time measurements. We analyze the fluid approximation of this system and solve steady-state linear programs that characterize optimal resource allocation. We design gate-and-route policies that regulate prefill admission and decode routing, and prove that they are asymptotically optimal in the many-GPU limit under both bundled and separate token-pricing schemes. We further extend the framework to incorporate Service Level Indicators (SLIs) such as latency and fairness, providing a general approach to constrained scheduling. Numerical experiments calibrated to empirical iteration-time data demonstrate that our policies outperform standard serving heuristics."}
{"id": "2602.03081", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.03081", "abs": "https://arxiv.org/abs/2602.03081", "authors": ["Mohammadali Khodabandehlou", "Jared Coleman", "Niranjan Suri", "Bhaskar Krishnamachari"], "title": "Studying the Effect of Schedule Preemption on Dynamic Task Graph Scheduling", "comment": null, "summary": "Dynamic scheduling of task graphs is often addressed without revisiting prior task allocations, with a primary focus on minimizing makespan. We study controlled schedule preemption, introducing the Last-K Preemption model, which selectively reschedules recent task graphs while preserving earlier allocations. Using synthetic, RIoTBench, WFCommons, and adversarial workloads, we compare preemptive, non-preemptive, and partial-preemptive strategies across makespan, fairness, utilization, and runtime. Results show moderate preemption can match most makespan and utilization gains of full preemption while maintaining fairness and low overhead."}
{"id": "2602.02999", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.02999", "abs": "https://arxiv.org/abs/2602.02999", "authors": ["Zhengle Wang", "Yanfei Zhang", "Chunwei Liu"], "title": "ResQ: Realistic Performance-Aware Query Generation", "comment": "13 pages, 4 figures", "summary": "Database research and development rely heavily on realistic user workloads for benchmarking, instance optimization, migration testing, and database tuning. However, acquiring real-world SQL queries is notoriously challenging due to strict privacy regulations. While cloud database vendors have begun releasing anonymized performance traces to the research community, these traces typi- cally provide only high-level execution statistics without the origi- nal query text or data, which is insufficient for scenarios that require actual execution. Existing tools fail to capture fine-grained perfor- mance patterns or generate runnable workloads that reproduce these public traces with both high fidelity and efficiency. To bridge this gap, we propose ResQ, a fine-grained workload synthesis sys- tem designed to generate executable SQL workloads that faithfully match the per-query execution targets and operator distributions of production traces. ResQ constructs execution-aware query graphs, instantiates them into SQL via Bayesian Optimization-driven pred- icate search, and explicitly models workload repetition through reuse at both exact-query and parameterized-template levels. To ensure practical scalability, ResQ combines search-space bounding with lightweight local cost models to accelerate optimization. Ex- periments on public cloud traces (Snowset, Redset) and a newly released industrial trace (Bendset) demonstrate that ResQ signif- icantly outperforms state-of-the-art baselines, achieving 96.71% token savings and a 86.97% reduction in runtime, while lowering maximum Q-error by 14.8x on CPU time and 997.7x on scanned bytes, and closely matching operator composition."}
{"id": "2602.03246", "categories": ["cs.DC", "cs.NI", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03246", "abs": "https://arxiv.org/abs/2602.03246", "authors": ["Tamoghna Sarkar", "Bhaskar Krishnamachari"], "title": "Joint Network-and-Server Congestion in Multi-Source Traffic Allocation: A Convex Formulation and Price-Based Decentralization", "comment": "10pages, 7 figures, submitted a version conference", "summary": "This paper studies an important rate allocation problem that arises in many networked and distributed systems: steady-state traffic rate allocation from multiple sources to multiple service nodes when both (i) the access-path delay on each source-node route is rate-dependent (capacity-constrained) and convex, and (ii) each service node (also capacity-constrained) experiences a load-dependent queueing delay driven by aggregate load from all sources. We show that the resulting flow-weighted end-to-end delay minimization is a convex program, yielding a global system-optimal solution characterized by KKT conditions that equalize total marginal costs (a path marginal access term plus a node congestion price) across all utilized routes. This condition admits a Wardrop-type interpretation: for each source, all utilized options equalize total marginal cost, while any option with strictly larger total marginal cost receives no flow. Building on this structure, we develop a lightweight distributed pricing-based algorithm in which each service node locally computes and broadcasts a scalar congestion price from its observed aggregate load, while each source updates its traffic split by solving a small separable convex allocation problem under the advertised prices. Numerical illustrations demonstrate convergence of the distributed iteration to the centralized optimum and highlight the trade-offs induced by jointly modeling access and service congestion."}
{"id": "2602.03069", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.03069", "abs": "https://arxiv.org/abs/2602.03069", "authors": ["Yue Wu", "Tianhao Su", "Shunbo Hu", "Deng Pan"], "title": "Skill-Based Autonomous Agents for Material Creep Database Construction", "comment": null, "summary": "The advancement of data-driven materials science is currently constrained by a fundamental bottleneck: the vast majority of historical experimental data remains locked within the unstructured text and rasterized figures of legacy scientific literature. Manual curation of this knowledge is prohibitively labor-intensive and prone to human error. To address this challenge, we introduce an autonomous, agent-based framework powered by Large Language Models (LLMs) designed to excavate high-fidelity datasets from scientific PDFs without human intervention. By deploying a modular \"skill-based\" architecture, the agent orchestrates complex cognitive tasks - including semantic filtering, multi-modal information extraction, and physics-informed validation. We demonstrate the efficacy of this framework by constructing a physically self-consistent database for material creep mechanics, a domain characterized by complex graphical trajectories and heterogeneous constitutive models. Applying the pipeline to 243 publications, the agent achieved a verified extraction success rate exceeding 90% for graphical data digitization. Crucially, we introduce a cross-modal verification protocol, demonstrating that the agent can autonomously align visually extracted data points with textually extracted constitutive parameters ($R^2 > 0.99$), ensuring the physical self-consistency of the database. This work not only provides a critical resource for investigating time-dependent deformation across diverse material systems but also establishes a scalable paradigm for autonomous knowledge acquisition, paving the way for the next generation of self-driving laboratories."}
{"id": "2602.02696", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02696", "abs": "https://arxiv.org/abs/2602.02696", "authors": ["Zhen Fang", "Miao Yang", "Zehang Lin", "Zheng Lin", "Zihan Fang", "Zongyuan Zhang", "Tianyang Duan", "Dong Huang", "Shunzhi Zhu"], "title": "NSC-SL: A Bandwidth-Aware Neural Subspace Compression for Communication-Efficient Split Learning", "comment": "5 pages, 3 figures", "summary": "The expanding scale of neural networks poses a major challenge for distributed machine learning, particularly under limited communication resources. While split learning (SL) alleviates client computational burden by distributing model layers between clients and server, it incurs substantial communication overhead from frequent transmission of intermediate activations and gradients. To tackle this issue, we propose NSC-SL, a bandwidth-aware adaptive compression algorithm for communication-efficient SL. NSC-SL first dynamically determines the optimal rank of low-rank approximation based on the singular value distribution for adapting real-time bandwidth constraints. Then, NSC-SL performs error-compensated tensor factorization using alternating orthogonal iteration with residual feedback, effectively minimizing truncation loss. The collaborative mechanisms enable NSC-SL to achieve high compression ratios while preserving semantic-rich information essential for convergence. Extensive experiments demonstrate the superb performance of NSC-SL."}
{"id": "2602.02584", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02584", "abs": "https://arxiv.org/abs/2602.02584", "authors": ["Srinivas Rao Marri"], "title": "Constitutional Spec-Driven Development: Enforcing Security by Construction in AI-Assisted Code Generation", "comment": "15 pages, 2 figures, 5 tables, 11 code listings, 14 references. Includes reference implementation and compliance traceability matrix", "summary": "The proliferation of AI-assisted \"vibe coding\" enables rapid software development but introduces significant security risks, as Large Language Models (LLMs) prioritize functional correctness over security. We present Constitutional Spec-Driven Development, a methodology that embeds non-negotiable security principles into the specification layer, ensuring AI-generated code adheres to security requirements by construction rather than inspection. Our approach introduces a Constitution: a versioned, machine-readable document encoding security constraints derived from Common Weakness Enumeration (CWE)/MITRE Top 25 vulnerabilities and regulatory frameworks. We demonstrate the methodology through a banking microservices application, selected as a representative example domain due to its stringent regulatory and security requirements, implementing customer management, account operations, and transaction processing. The methodology itself is domain-agnostic. The implementation addresses 10 critical CWE vulnerabilities through constitutional constraints with full traceability from principles to code locations. Our case study shows that constitutional constraints reduce security defects by 73% compared to unconstrained AI generation while maintaining developer velocity. We contribute a formal framework for constitutional security, a complete development methodology, and empirical evidence that proactive security specification outperforms reactive security verification in AI-assisted development workflows."}
{"id": "2602.02811", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.02811", "abs": "https://arxiv.org/abs/2602.02811", "authors": ["Vikram Krishnamurthy", "Luke Snow"], "title": "Efficient Counterfactual Estimation of Conditional Greeks via Malliavin-based Weak Derivatives", "comment": null, "summary": "We study counterfactual gradient estimation of conditional loss functionals of diffusion processes. In quantitative finance, these gradients are known as conditional Greeks: the sensitivity of expected market values, conditioned on some event of interest. The difficulty is that when the conditioning event has vanishing or zero probability, naive Monte Carlo estimators are prohibitively inefficient; kernel smoothing, though common, suffers from slow convergence. We propose a two-stage kernel-free methodology. First, we show using Malliavin calculus that the conditional loss functional of a diffusion process admits an exact representation as a Skorohod integral, yielding classical Monte-Carlo estimator variance and convergence rates. Second, we establish that a weak derivative estimate of the conditional loss functional with respect to model parameters can be evaluated algorithmically with constant variance, in contrast to the widely used score function method whose variance grows linearly in the sample path length. Together, these results yield an efficient framework for counterfactual conditional stochastic gradient algorithms and financial Greek computations in rare-event regimes."}
{"id": "2602.02579", "categories": ["cs.OS", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02579", "abs": "https://arxiv.org/abs/2602.02579", "authors": ["Shihao Wang", "Jiahao Chen", "Yanqi Pan", "Hao Huang", "Yichen Hao", "Xiangyu Zou", "Wen Xia", "Wentao Zhang", "Haitao Wang", "Junhong Li", "Chongyang Qiu", "Pengfei Wang"], "title": "ProphetKV: User-Query-Driven Selective Recomputation for Efficient KV Cache Reuse in Retrieval-Augmented Generation", "comment": null, "summary": "The prefill stage of long-context Retrieval-Augmented Generation (RAG) is severely bottlenecked by computational overhead. To mitigate this, recent methods assemble pre-calculated KV caches of retrieved RAG documents (by a user query) and reprocess selected tokens to recover cross-attention between these pre-calculated KV caches. However, we identify a fundamental \"crowding-out effect\" in current token selection criteria: globally salient but user-query-irrelevant tokens saturate the limited recomputation budget, displacing the tokens truly essential for answering the user query and degrading inference accuracy.\n  We propose ProphetKV, a user-query-driven KV Cache reuse method for RAG scenarios. ProphetKV dynamically prioritizes tokens based on their semantic relevance to the user query and employs a dual-stage recomputation pipeline to fuse layer-wise attention metrics into a high-utility set. By ensuring the recomputation budget is dedicated to bridging the informational gap between retrieved context and the user query, ProphetKV achieves high-fidelity attention recovery with minimal overhead. Our extensive evaluation results show that ProphetKV retains 96%-101% of full-prefill accuracy with only a 20% recomputation ratio, while achieving accuracy improvements of 8.8%-24.9% on RULER and 18.6%-50.9% on LongBench over the state-of-the-art approaches (e.g., CacheBlend, EPIC, and KVShare)."}
{"id": "2602.03444", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.03444", "abs": "https://arxiv.org/abs/2602.03444", "authors": ["Arivarasan Karmegam", "Lucianna Kiffer", "Antonio Fernández Anta"], "title": "Exploiting Multi-Core Parallelism in Blockchain Validation and Construction", "comment": null, "summary": "Blockchain validators can reduce block processing time by exploiting multi-core CPUs, but deterministic execution must preserve a given total order while respecting transaction conflicts and per-block runtime limits. This paper systematically examines how validators can exploit multi-core parallelism during both block construction and execution without violating blockchain semantics. We formalize two validator-side optimization problems: (i) executing an already ordered block on \\(p\\) cores to minimize makespan while ensuring equivalence to sequential execution; and (ii) selecting and scheduling a subset of mempool transactions under a runtime limit \\(B\\) to maximize validator reward. For both, we develop exact Mixed-Integer Linear Programming (MILP) formulations that capture conflict, order, and capacity constraints, and propose fast deterministic heuristics that scale to realistic workloads. Using Ethereum mainnet traces and including a Solana-inspired declared-access baseline (Sol) for ordered-block scheduling and a simple reward-greedy baseline (RG) for block construction, we empirically quantify the trade-offs between optimality and runtime."}
{"id": "2602.03189", "categories": ["cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.03189", "abs": "https://arxiv.org/abs/2602.03189", "authors": ["Yong Fang", "Yuxing Han", "Meng Wang", "Yifan Zhang", "Yue Ma", "Chi Zhang"], "title": "StreamShield: A Production-Proven Resiliency Solution for Apache Flink at ByteDance", "comment": null, "summary": "Distributed Stream Processing Systems (DSPSs) form the backbone of real-time processing and analytics at ByteDance, where Apache Flink powers one of the largest production clusters worldwide. Ensuring resiliency, the ability to withstand and rapidly recover from failures, together with operational stability, which provides consistent and predictable performance under normal conditions, is essential for meeting strict Service Level Objectives (SLOs). However, achieving resiliency and stability in large-scale production environments remains challenging due to the cluster scale, business diversity, and significant operational overhead. In this work, we present StreamShield, a production-proven resiliency solution deployed in ByteDance's Flink clusters. Designed along complementary perspectives of the engine and cluster, StreamShield introduces key techniques to enhance resiliency, covering runtime optimization, fine-grained fault-tolerance, hybrid replication strategy, and high availability under external systems. Furthermore, StreamShield proposes a robust testing and deployment pipeline that ensures reliability and robustness in production releases. Extensive evaluations on a production cluster demonstrate the efficiency and effectiveness of techniques proposed by StreamShield."}
{"id": "2602.02787", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.02787", "abs": "https://arxiv.org/abs/2602.02787", "authors": ["Simran Saxena", "Arpad Kovesdy"], "title": "Real-World Applications of AI in LTE and 5G-NR Network Infrastructure", "comment": "6 pages and 3 figures", "summary": "Telecommunications networks generate extensive performance and environmental telemetry, yet most LTE and 5G-NR deployments still rely on static, manually engineered configurations. This limits adaptability in rural, nomadic, and bandwidth-constrained environments where traffic distributions, propagation characteristics, and user behavior fluctuate rapidly. Artificial Intelligence (AI), more specifically Machine Learning (ML) models, provide new opportunities to transition Radio Access Networks (RANs) from rigid, rule-based systems toward adaptive, self-optimizing infrastructures that can respond autonomously to these dynamics. This paper proposes a practical architecture incorporating AI-assisted planning, reinforcement-learning-based RAN optimization, real-time telemetry analytics, and digital-twin-based validation. In parallel, the paper addresses the challenge of delivering embodied-AI healthcare services, educational tools, and large language model (LLM) applications to communities with insufficient backhaul for cloud computing. We introduce an edge-hosted execution model in which applications run directly on LTE/5G-NR base stations using containers, reducing latency and bandwidth consumption while improving resilience. Together, these contributions demonstrate how AI can enhance network performance, reduce operational overhead, and expand access to advanced digital services, aligning with broader goals of sustainable and inclusive network development."}
{"id": "2602.02585", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02585", "abs": "https://arxiv.org/abs/2602.02585", "authors": ["Aprameya Bharadwaj", "Kyle Tu"], "title": "Agentic Observability: Automated Alert Triage for Adobe E-Commerce", "comment": "Accepted at AAAI'26 Agentic AI Benchmarks and Applications for Enterprise Tasks Workshop", "summary": "Modern enterprise systems exhibit complex interdependencies that make observability and incident response increasingly challenging. Manual alert triage, which typically involves log inspection, API verification, and cross-referencing operational knowledge bases, remains a major bottleneck in reducing mean recovery time (MTTR). This paper presents an agentic observability framework deployed within Adobe's e-commerce infrastructure that autonomously performs alert triage using a ReAct paradigm. Upon alert detection, the agent dynamically identifies the affected service, retrieves and analyzes correlated logs across distributed systems, and plans context-dependent actions such as handbook consultation, runbook execution, or retrieval-augmented analysis of recently deployed code. Empirical results from production deployment indicate a 90% reduction in mean time to insight compared to manual triage, while maintaining comparable diagnostic accuracy. Our results show that agentic AI enables an order-of-magnitude reduction in triage latency and a step-change in resolution accuracy, marking a pivotal shift toward autonomous observability in enterprise operations."}
{"id": "2602.03092", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.03092", "abs": "https://arxiv.org/abs/2602.03092", "authors": ["Vahidullah Tac", "Christopher Gardner", "Ellen Kuhl"], "title": "Generative Artificial Intelligence creates delicious, sustainable, and nutritious burgers", "comment": "13 pages, 4 figures", "summary": "Food choices shape both human and planetary health; yet, designing foods that are delicious, nutritious, and sustainable remains challenging. Here we show that generative artificial intelligence can learn the structure of the human palate directly from large-scale, human-generated recipe data to create novel foods within a structured design space. Using burgers as a model system, the generative AI rediscovers the classic Big Mac without explicit supervision and generates novel burgers optimized for deliciousness, sustainability, or nutrition. Compared to the Big Mac, its delicious burgers score the same or better in overall liking, flavor, and texture in a blinded sensory evaluation conducted in a restaurant setting with 101 participants; its mushroom burger achieves an environmental impact score more than an order of magnitude lower; and its bean burger attains nearly twice the nutritional score. Together, these results establish generative AI as a quantitative framework for learning human taste and navigating complex trade-offs in principled food design."}
{"id": "2602.03474", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.03474", "abs": "https://arxiv.org/abs/2602.03474", "authors": ["Shachar Meir", "David Peleg"], "title": "Recursive Energy Efficient Agreement", "comment": null, "summary": "Agreement is a foundational problem in distributed computing that have been studied extensively for over four decades. Recently, Meir, Mirault, Peleg and Robinson introduced the notion of \\emph{Energy Efficient Agreement}, where the goal is to solve Agreement while minimizing the number of round a party participates in, thereby reducing the energy cost per participant. We show a recursive Agreement algorithm that has $O(\\log f)$ active rounds per participant, where $f<n$ represents the maximum number of crash faults in the system."}
{"id": "2602.03278", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.03278", "abs": "https://arxiv.org/abs/2602.03278", "authors": ["Saige Rutherford", "Zeshawn Zahid", "Robert C. Welsh", "Andrea Avena-Koenigsberger", "Vincent Koppelmans", "Amanda F. Mejia"], "title": "A Pipeline for ADNI Resting-State Functional MRI Processing and Quality Control", "comment": null, "summary": "The Alzheimer's Disease Neuroimaging Initiative (ADNI) provides a comprehensive multimodal neuroimaging resource for studying aging and Alzheimer's disease (AD). Since its second wave, ADNI has increasingly collected resting-state functional MRI (rs-fMRI), a valuable resource for discovering brain connectivity changes predictive of cognitive decline and AD. A major barrier to its use is the considerable variability in acquisition protocols and data quality, compounded by missing imaging sessions and inconsistencies in how functional scans temporally align with clinical assessments. As a result, many studies only utilize a small subset of the total rs-fMRI data, limiting statistical power, reproducibility, and the ability to study longitudinal functional brain changes at scale. Here, we describe a pipeline for ADNI rs-fMRI data that encompasses the download of necessary imaging and clinical data, temporally aligning the clinical and imaging data, preprocessing, and quality control. We integrate data curation and preprocessing across all ADNI sites and scanner types using a combination of open-source software (Clinica, fMRIPrep, and MRIQC) and bespoke tools. Quality metrics and reports are generated for each subject and session to facilitate rigorous data screening. All scripts and configuration files are available to enable reproducibility. The pipeline, which currently supports ADNI-GO, ADNI-2, and ADNI-3 data releases, outputs high-quality rs-fMRI time series data adhering to the BIDS-derivatives specification. This protocol provides a transparent and scalable framework for curating and utilizing ADNI fMRI data, empowering large-scale functional biomarker discovery and integrative multimodal analyses in Alzheimer's disease research."}
{"id": "2602.03140", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.03140", "abs": "https://arxiv.org/abs/2602.03140", "authors": ["Antonio Boiano", "Dalin Zheng", "Fabio Palmese", "Andrea Pimpinella", "Alessandro E. C. Redondi"], "title": "Analyzing Zigbee Traffic: Datasets, Classification and Storage Trade-offs", "comment": null, "summary": "Zigbee is widely used in smart home environments due to its low power consumption and support for mesh networking, making it a relevant target for traffic-based IoT forensic analysis. However, existing studies often rely on limited datasets and fixed network configurations. In this paper, we analyze Zigbee network traffic from three complementary perspectives: data collection, traffic classification, and storage efficiency. We introduce ZIOTP2025, a publicly available dataset of Zigbee traffic collected from commercial smart home devices deployed under multiple network configurations and capturing realistic interaction scenarios. Using this dataset, we study two traffic classification tasks: device type classification and individual device identification, and evaluate their robustness under both intra-configuration and cross-configuration settings. Our results show that while high classification accuracy can be achieved under controlled conditions, performance degrades significantly when models are evaluated across different network configurations, particularly for fine-grained identification tasks. Finally, we investigate the trade-off between traffic storage requirements and classification accuracy. We show that lossy compression of traffic features through quantization can reduce storage requirements by approximately 4-5x compared to lossless storage of raw packet traces, while preserving near-lossless classification performance. Overall, our results highlight the need for topology-aware Zigbee traffic analysis and storage-efficient feature compression to enable robust and scalable IoT forensic systems."}
{"id": "2602.02614", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02614", "abs": "https://arxiv.org/abs/2602.02614", "authors": ["Ying Wang", "Jiahui Chen", "Dejun Jiang"], "title": "Testing Storage-System Correctness: Challenges, Fuzzing Limitations, and AI-Augmented Opportunities", "comment": null, "summary": "Storage systems are fundamental to modern computing infrastructures, yet ensuring their correctness remains challenging in practice. Despite decades of research on system testing, many storage-system failures (including durability, ordering, recovery, and consistency violations) remain difficult to expose systematically. This difficulty stems not primarily from insufficient testing tooling, but from intrinsic properties of storage-system execution, including nondeterministic interleavings, long-horizon state evolution, and correctness semantics that span multiple layers and execution phases.\n  This survey adopts a storage-centric view of system testing and organizes existing techniques according to the execution properties and failure mechanisms they target. We review a broad spectrum of approaches, ranging from concurrency testing and long-running workloads to crash-consistency analysis, hardware-level semantic validation, and distributed fault injection, and analyze their fundamental strengths and limitations. Within this framework, we examine fuzzing as an automated testing paradigm, highlighting systematic mismatches between conventional fuzzing assumptions and storage-system semantics, and discuss how recent artificial intelligence advances may complement fuzzing through state-aware and semantic guidance. Overall, this survey provides a unified perspective on storage-system correctness testing and outlines key challenges"}
{"id": "2602.03495", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03495", "abs": "https://arxiv.org/abs/2602.03495", "authors": ["Zeyu Zhu", "Gang Li", "Peisong Wang", "Zitao Mo", "Minnan Pei", "Zhuoran Song", "Xiaoyao Liang", "Jian Cheng"], "title": "DALI: A Workload-Aware Offloading Framework for Efficient MoE Inference on Local PCs", "comment": null, "summary": "Mixture of Experts (MoE) architectures significantly enhance the capacity of LLMs without proportional increases in computation, but at the cost of a vast parameter size. Offloading MoE expert parameters to host memory and leveraging both CPU and GPU computation has recently emerged as a promising direction to support such models on resourceconstrained local PC platforms. While promising, we notice that existing approaches mismatch the dynamic nature of expert workloads, which leads to three fundamental inefficiencies: (1) Static expert assignment causes severe CPUGPU load imbalance, underutilizing CPU and GPU resources; (2) Existing prefetching techniques fail to accurately predict high-workload experts, leading to costly inaccurate prefetches; (3) GPU cache policies neglect workload dynamics, resulting in poor hit rates and limited effectiveness. To address these challenges, we propose DALI, a workloaDAware offLoadIng framework for efficient MoE inference on local PCs. To fully utilize hardware resources, DALI first dynamically assigns experts to CPU or GPU by modeling assignment as a 0-1 integer optimization problem and solving it efficiently using a Greedy Assignment strategy at runtime. To improve prefetching accuracy, we develop a Residual-Based Prefetching method leveraging inter-layer residual information to accurately predict high-workload experts. Additionally, we introduce a Workload-Aware Cache Replacement policy that exploits temporal correlation in expert activations to improve GPU cache efficiency. By evaluating across various MoE models and settings, DALI achieves significant speedups in the both prefill and decoding phases over the state-of-the-art offloading frameworks."}
{"id": "2602.03262", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.03262", "abs": "https://arxiv.org/abs/2602.03262", "authors": ["Inhar Yeregui", "Ángel Martín", "Mikel Zorrilla", "Roberto Viola", "Jasone Astorga", "Eduardo Jacob"], "title": "Towards Context-Aware Edge-Cloud Continuum Orchestration for Multi-user XR Services", "comment": null, "summary": "The rapid growth of multi-user eXtended Reality (XR) applications, spanning fields such as entertainment, education, and telemedicine, demands seamless, immersive experiences for users interacting within shared, distributed environments. Delivering such latency-sensitive experiences involves considerable challenges in orchestrating network, computing, and service resources, where existing limitations highlight the need for a structured approach to analyse and optimise these complex systems. This challenge is amplified by the need for high-performance, low-latency connectivity, where 5G and 6G networks provide essential infrastructure to meet the requirements of XR services at scale. This article addresses these challenges by developing a model that parametrises multi-user XR services across four critical layers of the standard virtualisation architecture. We formalise this model mathematically, proposing a context-aware framework that defines key parameters at each level and integrates them into a comprehensive Edge-Cloud Continuum orchestration strategy. Our contributions include a detailed analysis of the current limitations and needs in existing Edge-Cloud Continuum orchestration approaches, the formulation of a layered mathematical model, and a validation framework that demonstrates the utility and feasibility of the proposed solution."}
{"id": "2602.02690", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02690", "abs": "https://arxiv.org/abs/2602.02690", "authors": ["Chenxi Huang", "Alex Mathai", "Feiyang Yu", "Aleksandr Nogikh", "Petros Maniatis", "Franjo Ivančić", "Eugene Wu", "Kostis Kaffes", "Junfeng Yang", "Baishakhi Ray"], "title": "Outrunning LLM Cutoffs: A Live Kernel Crash Resolution Benchmark for All", "comment": null, "summary": "Repairing system crashes discovered by kernel fuzzers like Syzkaller is a critical yet underexplored challenge in software engineering. While recent works have introduced Large Language Model (LLM) based agents for Linux kernel crash-resolution, their evaluation benchmarks are usually static and thus, do not capture the evolving nature of the Linux kernel, and suffer from potential data contamination due to LLM knowledge cutoffs. To address the above problem, we present (i) Live-kBench, an evaluation framework for self-evolving benchmarks that continuously scrapes and evaluates agents on freshly discovered kernel bugs, and (ii) kEnv, an agent-agnostic standardized crash-resolution environment for kernel compilation, execution, and feedback. This design decouples agent workflows from heavy-weight execution, enabling fair and scalable comparison across diverse agent frameworks under identical conditions.\n  To this end, we curate an inaugural dataset of 534 Linux kernel bugs and empirically demonstrate a significant performance gap, with agents achieving up to 25% higher equivalent patch rate on bugs fixed before the LLM knowledge cutoff. Using kEnv, we benchmark three state-of-the-art agents, showing that they resolve 74% of crashes on the first attempt (plausible patches); however only ~20% of generated patches closely match developer fixes. Additionally, exposing crash resolution feedback improves crash resolution rate by 29%. Live-kBench provides the community with an evaluation infrastructure for self-evolving benchmarks that is both time and attribute sensitive; complete with a public dashboard to track agent progress on Linux kernel bugs."}
{"id": "2602.03802", "categories": ["cs.DC", "cs.AI", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03802", "abs": "https://arxiv.org/abs/2602.03802", "authors": ["Grigory Begunov", "Alexander Tyurin"], "title": "Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods", "comment": null, "summary": "Modern distributed optimization methods mostly rely on traditional synchronous approaches, despite substantial recent progress in asynchronous optimization. We revisit Synchronous SGD and its robust variant, called $m$-Synchronous SGD, and theoretically show that they are nearly optimal in many heterogeneous computation scenarios, which is somewhat unexpected. We analyze the synchronous methods under random computation times and adversarial partial participation of workers, and prove that their time complexities are optimal in many practical regimes, up to logarithmic factors. While synchronous methods are not universal solutions and there exist tasks where asynchronous methods may be necessary, we show that they are sufficient for many modern heterogeneous computation scenarios."}
{"id": "2602.03354", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.03354", "abs": "https://arxiv.org/abs/2602.03354", "authors": ["Hari Hara Sudhan Selvam", "Sameer G. Kulkarni"], "title": "QASM: A Novel Framework for QUIC-Aware Stateful Middleboxes", "comment": null, "summary": "Stateful Middleboxes are integral part of enterprise and campus networks that provide essential in-network, security, and value-added services. These stateful middleboxes rely on precise network flow identification. However, the adoption of HTTP/3, which uses the QUIC protocol, poses significant challenges to the proper functioning of these devices. QUIC's encryption and connection migration features obscure flow semantics, disrupting middlebox visibility and functionality. We examine how QUIC disrupts middleboxes like Network Address Translators (NATs), Rate Limiters, Load Balancers, etc., and affects Kubernetes-based service deployments. To address these challenges, we propose a novel, generalized framework that enables stateful middleboxes to reliably track QUIC connections, even when the endpoints change their internet protocol (IP) address or port numbers. Our prototype implementation demonstrates that the proposed approach preserves middlebox functionality with HTTP/3 with negligible performance overhead (< 5%) on both throughput and latency, and works effectively even under high QUIC connection migration rates of up to 100 Hz."}
{"id": "2602.02752", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02752", "abs": "https://arxiv.org/abs/2602.02752", "authors": ["Srinath Srinivasan", "Tim Menzies"], "title": "Beyond the Prompt: Assessing Domain Knowledge Strategies for High-Dimensional LLM Optimization in Software Engineering", "comment": "Accepted at MSR 2026 (Registered Reports Track)", "summary": "Background/Context: Large Language Models (LLMs) demonstrate strong performance on low-dimensional software engineering optimization tasks ($\\le$11 features) but consistently underperform on high-dimensional problems where Bayesian methods dominate. A fundamental gap exists in understanding how systematic integration of domain knowledge (whether from humans or automated reasoning) can bridge this divide.\n  Objective/Aim: We compare human versus artificial intelligence strategies for generating domain knowledge. We systematically evaluate four distinct architectures to determine if structured knowledge integration enables LLMs to generate effective warm starts for high-dimensional optimization.\n  Method: We evaluate four approaches on MOOT datasets stratified by dimensionality: (1) Human-in-the-Loop Domain Knowledge Prompting (H-DKP), utilizing asynchronous expert feedback loops; (2) Adaptive Multi-Stage Prompting (AMP), implementing sequential constraint identification and validation; (3) Dimension-Aware Progressive Refinement (DAPR), conducting optimization in progressively expanding feature subspaces; and (4) Hybrid Knowledge-Model Approach (HKMA), synthesizing statistical scouting (TPE) with RAG-enhanced prompting. Performance is quantified via Chebyshev distance to optimal solutions and ranked using Scott-Knott clustering against an established baseline for LLM generated warm starts.\n  Note that all human studies conducted as part of this study will comply with the policies of our local Institutional Review Board."}
{"id": "2602.03189", "categories": ["cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.03189", "abs": "https://arxiv.org/abs/2602.03189", "authors": ["Yong Fang", "Yuxing Han", "Meng Wang", "Yifan Zhang", "Yue Ma", "Chi Zhang"], "title": "StreamShield: A Production-Proven Resiliency Solution for Apache Flink at ByteDance", "comment": null, "summary": "Distributed Stream Processing Systems (DSPSs) form the backbone of real-time processing and analytics at ByteDance, where Apache Flink powers one of the largest production clusters worldwide. Ensuring resiliency, the ability to withstand and rapidly recover from failures, together with operational stability, which provides consistent and predictable performance under normal conditions, is essential for meeting strict Service Level Objectives (SLOs). However, achieving resiliency and stability in large-scale production environments remains challenging due to the cluster scale, business diversity, and significant operational overhead. In this work, we present StreamShield, a production-proven resiliency solution deployed in ByteDance's Flink clusters. Designed along complementary perspectives of the engine and cluster, StreamShield introduces key techniques to enhance resiliency, covering runtime optimization, fine-grained fault-tolerance, hybrid replication strategy, and high availability under external systems. Furthermore, StreamShield proposes a robust testing and deployment pipeline that ensures reliability and robustness in production releases. Extensive evaluations on a production cluster demonstrate the efficiency and effectiveness of techniques proposed by StreamShield."}
{"id": "2602.03529", "categories": ["cs.NI", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.03529", "abs": "https://arxiv.org/abs/2602.03529", "authors": ["Tianyi Gong", "Zijian Cao", "Zixing Zhang", "Jiangkai Wu", "Xinggong Zhang", "Shuguang Cui", "Fangxin Wang"], "title": "Morphe: High-Fidelity Generative Video Streaming with Vision Foundation Model", "comment": "Accepted by NSDI 2026 Fall", "summary": "Video streaming is a fundamental Internet service, while the quality still cannot be guaranteed especially in poor network conditions such as bandwidth-constrained and remote areas. Existing works mainly work towards two directions: traditional pixel-codec streaming nearly approaches its limit and is hard to step further in compression; the emerging neural-enhanced or generative streaming usually fall short in latency and visual fidelity, hindering their practical deployment. Inspired by the recent success of vision foundation model (VFM), we strive to harness the powerful video understanding and processing capacities of VFM to achieve generalization, high fidelity and loss resilience for real-time video streaming with even higher compression rate. We present the first revolutionized paradigm that enables VFM-based end-to-end generative video streaming towards this goal. Specifically, Morphe employs joint training of visual tokenizers and variable-resolution spatiotemporal optimization under simulated network constraints. Additionally, a robust streaming system is constructed that leverages intelligent packet dropping to resist real-world network perturbations. Extensive evaluation demonstrates that Morphe achieves comparable visual quality while saving 62.5\\% bandwidth compared to H.265, and accomplishes real-time, loss-resilient video delivery in challenging network environments, representing a milestone in VFM-enabled multimedia streaming solutions."}
{"id": "2602.02869", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02869", "abs": "https://arxiv.org/abs/2602.02869", "authors": ["Wei Wang", "Anuradha Madugalla", "John Grundy", "Paul McIntosh", "Charmine E. J. Härtel"], "title": "A Proxy Stakeholder Approach to Requirements Engineering for Inclusive Navigation", "comment": null, "summary": "Wayfinding, or the ability to navigate one's surroundings, is crucial for independent living and requires a complex combination of cognitive abilities, environmental awareness, and technology to manage this successfully. Individuals with cognitive impairment (IwCI) often face significant challenges in learning and navigating their environment. Despite its importance, mainstream navigation technologies are rarely designed with their diverse needs in mind. This study reframes the search for places as a socially distributed task and emphasizes the role of proxy stakeholders, who act on behalf or in coordination with IwCI during navigation. Using a qualitatively led mixed-methods approach, which includes an international survey and a three-stage interview study, we examine the real-world strategies that proxy stakeholders employ to support daily navigation. The findings are synthesized into a set of empirically grounded design recommendations that emphasize customisability, collaborative use, and support for routine-based navigation. Our findings highlight key challenges and adaptive practices, which are synthesized into design recommendations that prioritize customisability, routine-based navigation, and multi-user coordination. By introducing the proxy stakeholder concept into the software engineering literature, we propose a more inclusive approach to requirements elicitation and offer practical guidance for designing navigation technologies that better reflect the complex realities of cognitive support."}
{"id": "2602.03662", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.03662", "abs": "https://arxiv.org/abs/2602.03662", "authors": ["Federico Giarrè", "Holger Karl"], "title": "RIPPLE: Lifecycle-aware Embedding of Service Function Chains in Multi-access Edge Computing", "comment": null, "summary": "In Multi-access Edge Computing networks, services can be deployed on nearby edge clouds (EC) as service function chains (SFCs) to meet strict quality of service (QoS) requirements. As users move, frequent SFC reconfigurations are required, but these are non-trivial: SFCs can serve users only when all required virtual network functions (VNFs) are available, and VNFs undergo time-consuming lifecycle operations before becoming operational. We show that ignoring lifecycle dynamics oversimplifies deployment, jeopardizes QoS, and must be avoided in practical SFC management. To address this, forecasts of user connectivity can be leveraged to proactively deploy VNFs and reconfigure SFCs. But forecasts are inherently imperfect, requiring lifecycle and connectivity uncertainty to be jointly considered. We present RIPPLE, a lifecycle-aware SFC embedding approach to deploy VNFs at the right time and location, reducing service interruptions. We show that RIPPLE closes the gap with solutions that unrealistically assume instantaneous lifecycle, even under realistic lifecycle constraints."}
{"id": "2602.02881", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02881", "abs": "https://arxiv.org/abs/2602.02881", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Learning-Infused Formal Reasoning: From Contract Synthesis to Artifact Reuse and Formal Semantics", "comment": "18 pages. Accepted at VERIFAI-2026: The Interplay between Artificial Intelligence and Software Verification LASER center, Villebrumier, France, March 8-11, 2026", "summary": "This vision paper articulates a long-term research agenda for formal methods at the intersection with artificial intelligence, outlining multiple conceptual and technical dimensions and reporting on our ongoing work toward realising this agenda. It advances a forward-looking perspective on the next generation of formal methods based on the integration of automated contract synthesis, semantic artifact reuse, and refinement-based theory. We argue that future verification systems must move beyond isolated correctness proofs toward a cumulative, knowledge-driven paradigm in which specifications, contracts, and proofs are continuously synthesised and transferred across systems. To support this shift, we outline a hybrid framework combining large language models with graph-based representations to enable scalable semantic matching and principled reuse of verification artifacts. Learning-based components provide semantic guidance across heterogeneous notations and abstraction levels, while symbolic matching ensures formal soundness. Grounded in compositional reasoning, this vision points toward verification ecosystems that evolve systematically, leveraging past verification efforts to accelerate future assurance."}
{"id": "2602.03821", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.03821", "abs": "https://arxiv.org/abs/2602.03821", "authors": ["Angelo Feraudo", "Stefano Maxenti", "Andrea Lacava", "Leonardo Bonati", "Paolo Bellavista", "Michele Polese", "Tommaso Melodia"], "title": "xDevSM: An Open-Source Framework for Portable, AI-Ready xApps Across Heterogeneous O-RAN Deployments", "comment": null, "summary": "Openness and programmability in the O-RAN architecture enable closed-loop control of the Radio Access Network (RAN). Artificial Intelligence (AI)-driven xApps, in the near-real-time RAN Intelligent Controller (RIC), can learn from network data, anticipate future conditions, and dynamically adapt radio configurations. However, their development and adoption are hindered by the complexity of low-level RAN control and monitoring message models exposed over the O-RAN E2 interface, limited interoperability across heterogeneous RAN software stacks, and the lack of developer-friendly frameworks. In this paper, we introduce xDevSM, a framework that significantly lowers the barrier to xApp development by unifying observability and control in O-RAN deployment. By exposing a rich set of Key Performance Measurements (KPMs) and enabling fine-grained radio resource management controls, xDevSM provides the essential foundation for practical AI-driven xApps. We validate xDevSM on real-world testbeds, leveraging Commercial Off-the-Shelf (COTS) devices together with heterogeneous RAN hardware, including Universal Software Radio Peripheral (USRP)-based Software-defined Radios (SDRs) and Foxconn radio units, and show its seamless interoperability across multiple open-source RAN software stacks. Furthermore, we discuss and evaluate the capabilities of our framework through three O-RAN-based scenarios of high interest: (i) KPM-based monitoring of network performance, (ii) slice-level Physical Resource Block (PRB) allocation control across multiple User Equipments (UEs) and slices, and (iii) mobility-aware handover control, showing that xDevSM can implement intelligent closed-loop applications, laying the groundwork for learning-based optimization in heterogeneous RAN deployments. xDevSM is open source and available as foundational tool for the research community."}
{"id": "2602.02896", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02896", "abs": "https://arxiv.org/abs/2602.02896", "authors": ["Jianru Shen", "Zedong Peng", "Lucy Owen"], "title": "Failure-Aware Enhancements for Large Language Model (LLM) Code Generation: An Empirical Study on Decision Framework", "comment": "Accepted at SANER 2026", "summary": "Large language models (LLMs) show promise for automating software development by translating requirements into code. However, even advanced prompting workflows like progressive prompting often leave some requirements unmet. Although methods such as self-critique, multi-model collaboration, and retrieval-augmented generation (RAG) have been proposed to address these gaps, developers lack clear guidance on when to use each. In an empirical study of 25 GitHub projects, we found that progressive prompting achieves 96.9% average task completion, significantly outperforming direct prompting (80.5%, Cohen's d=1.63, p<0.001) but still leaving 8 projects incomplete. For 6 of the most representative projects, we evaluated each enhancement strategy across 4 failure types. Our results reveal that method effectiveness depends critically on failure characteristics: Self-Critique succeeds on code-reviewable logic errors but fails completely on external service integration (0% improvement), while RAG achieves highest completion across all failure types with superior efficiency. Based on these findings, we propose a decision framework that maps each failure pattern to the most suitable enhancement method, giving practitioners practical, data-driven guidance instead of trial-and-error."}
{"id": "2602.03246", "categories": ["cs.DC", "cs.NI", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03246", "abs": "https://arxiv.org/abs/2602.03246", "authors": ["Tamoghna Sarkar", "Bhaskar Krishnamachari"], "title": "Joint Network-and-Server Congestion in Multi-Source Traffic Allocation: A Convex Formulation and Price-Based Decentralization", "comment": "10pages, 7 figures, submitted a version conference", "summary": "This paper studies an important rate allocation problem that arises in many networked and distributed systems: steady-state traffic rate allocation from multiple sources to multiple service nodes when both (i) the access-path delay on each source-node route is rate-dependent (capacity-constrained) and convex, and (ii) each service node (also capacity-constrained) experiences a load-dependent queueing delay driven by aggregate load from all sources. We show that the resulting flow-weighted end-to-end delay minimization is a convex program, yielding a global system-optimal solution characterized by KKT conditions that equalize total marginal costs (a path marginal access term plus a node congestion price) across all utilized routes. This condition admits a Wardrop-type interpretation: for each source, all utilized options equalize total marginal cost, while any option with strictly larger total marginal cost receives no flow. Building on this structure, we develop a lightweight distributed pricing-based algorithm in which each service node locally computes and broadcasts a scalar congestion price from its observed aggregate load, while each source updates its traffic split by solving a small separable convex allocation problem under the advertised prices. Numerical illustrations demonstrate convergence of the distributed iteration to the centralized optimum and highlight the trade-offs induced by jointly modeling access and service congestion."}
{"id": "2602.02934", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02934", "abs": "https://arxiv.org/abs/2602.02934", "authors": ["Yu Shi", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "Beyond Blame: Rethinking SZZ with Knowledge Graph Search", "comment": null, "summary": "Identifying Bug-Inducing Commits (BICs) is fundamental for understanding software defects and enabling downstream tasks such as defect prediction and automated program repair. Yet existing SZZ-based approaches are limited by their reliance on git blame, which restricts the search space to commits that directly modified the fixed lines. Our preliminary study on 2,102 validated bug-fixing commits reveals that this limitation is significant: over 40% of cases cannot be solved by blame alone, as 28% of BICs require traversing commit history beyond blame results and 14% are blameless.\n  We present AgenticSZZ, the first approach to apply Temporal Knowledge Graphs (TKGs) to software evolution analysis. AgenticSZZ reframes BIC identification from a ranking problem over blame commits into a graph search problem, where temporal ordering is fundamental to causal reasoning about bug introduction. The approach operates in two phases: (1) constructing a TKG that encodes commits with temporal and structural relationships, expanding the search space by traversing file history backward from two reference points (blame commits and the BFC); and (2) leveraging an LLM agent to navigate the graph using specialized tools for candidate exploration and causal analysis.\n  Evaluation on three datasets shows that AgenticSZZ achieves F1-scores of 0.48 to 0.74, with statistically significant improvements over state-of-the-art by up to 27%. Our ablation study confirms that both components are essential, reflecting a classic exploration-exploitation trade-off: the TKG expands the search space while the agent provides intelligent selection. By transforming BIC identification into a graph search problem, we open a new research direction for temporal and causal reasoning in software evolution analysis."}
{"id": "2602.02964", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02964", "abs": "https://arxiv.org/abs/2602.02964", "authors": ["Altino Alves", "João Eduardo Montandon", "Andre Hora"], "title": "Testing Framework Migration with Large Language Models", "comment": "Accepted for publication at AST 2026", "summary": "Python developers rely on two major testing frameworks: \\texttt{unittest} and \\texttt{Pytest}. While \\texttt{Pytest} offers simpler assertions, reusable fixtures, and better interoperability, migrating existing suites from \\texttt{unittest} remains a manual and time-consuming process. Automating this migration could substantially reduce effort and accelerate test modernization. In this paper, we investigate the capability of Large Language Models (LLMs) to automate test framework migrations from \\texttt{unittest} to \\texttt{Pytest}. We evaluate GPT 4o and Claude Sonnet 4 under three prompting strategies (Zero-shot, One-shot, and Chain-of-Thought) and two temperature settings (0.0 and 1.0). To support this analysis, we first introduce a curated dataset of real-world migrations extracted from the top 100 Python open-source projects. Next, we actually execute the LLM-generated test migrations in their respective test suites. Overall, we find that 51.5% of the LLM-generated test migrations failed, while 48.5% passed. The results suggest that LLMs can accelerate test migration, but there are often caveats. For example, Claude Sonnet 4 exhibited more conservative migrations (e.g., preserving class-based tests and legacy \\texttt{unittest} references), while GPT-4o favored more transformations (e.g., to function-based tests). We conclude by discussing multiple implications for practitioners and researchers."}
{"id": "2602.02965", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02965", "abs": "https://arxiv.org/abs/2602.02965", "authors": ["Andre Hora", "Gordon Fraser"], "title": "Understanding Bug-Reproducing Tests: A First Empirical Study", "comment": "Accepted for publication at AST 2026", "summary": "Developers create bug-reproducing tests that support debugging by failing as long as the bug is present, and passing once the bug has been fixed. These tests are usually integrated into existing test suites and executed regularly alongside all other tests to ensure that future regressions are caught. Despite this co-existence with other types of tests, the properties of bug-reproducing tests are scarcely researched, and it remains unclear whether they differ fundamentally. In this short paper, we provide an initial empirical study to understand bug-reproducing tests better. We analyze 642 bug-reproducing tests of 15 real-world Python systems. Overall, we find that bug-reproducing tests are not (statistically significantly) different from other tests regarding LOC, number of assertions, and complexity. However, bug-reproducing tests contain slightly more try/except blocks and ``weak assertions'' (e.g.,~\\texttt{assertNotEqual}). Lastly, we detect that the majority (95%) of the bug-reproducing tests reproduce a single bug, while 5% reproduce multiple bugs. We conclude by discussing implications and future research directions."}
{"id": "2602.02966", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02966", "abs": "https://arxiv.org/abs/2602.02966", "authors": ["Bruna Falcucci", "Felipe Gomide", "Andre Hora"], "title": "What Do Contribution Guidelines Say About Software Testing?", "comment": "Published at MSR 2025", "summary": "Software testing plays a crucial role in the contribution process of open-source projects. For example, contributions introducing new features are expected to include tests, and contributions with tests are more likely to be accepted. Although most real-world projects require contributors to write tests, the specific testing practices communicated to contributors remain unclear. In this paper, we present an empirical study to understand better how software testing is approached in contribution guidelines. We analyze the guidelines of 200 Python and JavaScript open-source software projects. We find that 78\\% of the projects include some form of test documentation for contributors. Test documentation is located in multiple sources, including \\texttt{CONTRIBUTING} files (58\\%), external documentation (24\\%), and \\texttt{README} files (8\\%). Furthermore, test documentation commonly explains how to run tests (83.5\\%), but less often provides guidance on how to write tests (37\\%). It frequently covers unit tests (71\\%), but rarely addresses integration (20.5\\%) and end-to-end tests (15.5\\%). Other key testing aspects are also less frequently discussed: test coverage (25.5\\%) and mocking (9.5\\%). We conclude by discussing implications and future research."}
{"id": "2602.03093", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03093", "abs": "https://arxiv.org/abs/2602.03093", "authors": ["Yang Yue", "Zheng Jiang", "Yi Wang"], "title": "Maintaining the Heterogeneity in the Organization of Software Engineering Research", "comment": "Accepted at the 48th International Conference on Software Engineering, Future of Software Engineering (ICSE 2026-FoSE)", "summary": "The heterogeneity in the organization of software engineering (SE) research historically exists, i.e., funded research model and hands-on model, which makes software engineering become a thriving interdisciplinary field in the last 50 years. However, the funded research model is becoming dominant in SE research recently, indicating such heterogeneity has been seriously and systematically threatened. In this essay, we first explain why the heterogeneity is needed in the organization of SE research, then present the current trend of SE research nowadays, as well as the consequences and potential futures. The choice is at our hands, and we urge our community to seriously consider maintaining the heterogeneity in the organization of software engineering research."}
{"id": "2602.03181", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03181", "abs": "https://arxiv.org/abs/2602.03181", "authors": ["Ziyue Hua", "Tianyu Chen", "Yeyun Gong", "Shuai Lu", "Peng Cheng", "Qinglin Zhu", "Yibo He", "Yingjie Fu", "Wenpin Jiao", "Wei Yang", "Tao Xie"], "title": "Synthesizing File-Level Data for Unit Test Generation with Chain-of-Thoughts via Self-Debugging", "comment": null, "summary": "Automatic unit test (UT) generation is essential for software quality assurance, but existing approaches--including symbolic execution, search-based approaches, and recent LLM-based generators--struggle to produce human-quality tests with correct, meaningful assertions and reliable chain-of-thought (CoT) explanations. We identify a gap in UT training data: repository-mined tests lack developer CoTs, while LLM-distilled CoTs are often incorrect or incomplete. To address this issue, we propose a novel data-distillation approach that uses self-debugging to produce high-quality UT training examples paired with faithful CoTs. Our approach combines (1) guided test repair, a heuristic loop (error-, failure-, and coverage-focused steps) that asks the used model to diagnose and iteratively fix generated tests, and (2) CoT compression, which compacts original and debugging CoTs into concise explanations that directly justify correct tests. We apply this pipeline to a large corpus of open-source projects to construct a dataset of 74,518 high-quality <focal method, test, CoT> examples, and then use it for supervised fine-tuning of a base model. An empirical evaluation shows that the fine-tuned model achieves high UT generation effectiveness: it attains a pass rate of 36.17% on test assertions, a branch coverage of 43.90%, and a mutation score of 88.66%, substantially higher than state-of-the-art commercial models like o4-mini."}
{"id": "2602.03311", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03311", "abs": "https://arxiv.org/abs/2602.03311", "authors": ["Elena Masserini"], "title": "Multi-Level Testing of Conversational AI Systems", "comment": "3 pages, 1 figure, Accepted at IEEE/ACM International Conference on Software Engineering (ICSE) - Doctoral Symposium Track, 2026", "summary": "Conversational AI systems combine AI-based solutions with the flexibility of conversational interfaces. However, most existing testing solutions do not straightforwardly adapt to the characteristics of conversational interaction or to the behavior of AI components. To address this limitation, this Ph.D. thesis investigates a new family of testing approaches for conversational AI systems, focusing on the validation of their constituent elements at different levels of granularity, from the integration between the language and the AI components, to individual conversational agents, up to multi-agent implementations of conversational AI systems"}
{"id": "2602.03400", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03400", "abs": "https://arxiv.org/abs/2602.03400", "authors": ["Jintai Li", "Songqiang Chen", "Shuo Jin", "Xiaoyuan Xie"], "title": "Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations", "comment": null, "summary": "Code summaries are essential for helping developers understand code functionality and reducing maintenance and collaboration costs. Although recent advances in large language models (LLMs) have significantly improved automatic code summarization, the practical usefulness of generated summaries in industrial settings remains insufficiently explored. In collaboration with documentation experts from the industrial HarmonyOS project, we conducted a questionnaire study showing that over 57.4% of code summaries produced by state-of-the-art approaches were rejected due to violations of developers' expectations for industrial documentation. Beyond semantic similarity to reference summaries, developers emphasize additional requirements, including the use of appropriate domain terminology, explicit function categorization, and the avoidance of redundant implementation details.\n  To address these expectations, we propose ExpSum, an expectation-aware code summarization approach that integrates function metadata abstraction, informative metadata filtering, context-aware domain knowledge retrieval, and constraint-driven prompting to guide LLMs in generating structured, expectation-aligned summaries. We evaluate ExpSum on the HarmonyOS project and widely used code summarization benchmarks. Experimental results show that ExpSum consistently outperforms all baselines, achieving improvements of up to 26.71% in BLEU-4 and 20.10% in ROUGE-L on HarmonyOS. Furthermore, LLM-based evaluations indicate that ExpSum-generated summaries better align with developer expectations across other projects, demonstrating its effectiveness for industrial code documentation."}
{"id": "2602.03411", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03411", "abs": "https://arxiv.org/abs/2602.03411", "authors": ["Huatong Song", "Lisheng Huang", "Shuang Sun", "Jinhao Jiang", "Ran Le", "Daixuan Cheng", "Guoxin Chen", "Yiwen Hu", "Zongchao Chen", "Wayne Xin Zhao", "Yang Song", "Tao Zhang", "Ji-Rong Wen"], "title": "SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training", "comment": null, "summary": "In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master."}
{"id": "2602.03419", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03419", "abs": "https://arxiv.org/abs/2602.03419", "authors": ["Shuang Sun", "Huatong Song", "Lisheng Huang", "Jinhao Jiang", "Ran Le", "Zhihao Lv", "Zongchao Chen", "Yiwen Hu", "Wenyang Luo", "Wayne Xin Zhao", "Yang Song", "Hongteng Xu", "Tao Zhang", "Ji-Rong Wen"], "title": "SWE-World: Building Software Engineering Agents in Docker-Free Environments", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\\% to 52.0\\% via Docker-free SFT, 55.0\\% with Docker-free RL, and 68.2\\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World"}
{"id": "2602.03462", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03462", "abs": "https://arxiv.org/abs/2602.03462", "authors": ["Ruwei Pan", "Yakun Zhang", "Qingyuan Liang", "Yueheng Zhu", "Chao Liu", "Lu Zhang", "Hongyu Zhang"], "title": "RAL-Bench: Benchmarking for Application-Level Functional Correctness and Non-Functional Quality Attributes", "comment": null, "summary": "Code generation has advanced rapidly with code-focused large language models (LLMs), especially on snippet-level tasks. However, application-level generation requires producing a runnable multi-file repository with correct structure, dependencies, and end-to-end executability, and real-world software must satisfy both functional correctness and non-functional quality (e.g., maintainability, security). Existing benchmarks provide a limited execution-based assessment of these requirements at the application level. We ask: Can current LLMs generate application-level repositories that meet both functional and non-functional criteria? We propose RAL-Bench, a benchmark and evaluation framework for application-level code generation. For each task, we distill a concise natural-language requirement from a high-quality reference project, build black-box system tests covering functional and non-functional attributes, and keep only tests that pass on the reference repository to ensure a sound oracle and an end-to-end executable suite. Functional correctness is measured by system-test pass rate. Non-functional quality is measured along five ISO/IEC 25010-inspired dimensions and aggregated with an Analytic Hierarchy Process (AHP)-derived weight vector, with per-dimension diagnostics and baseline-normalized scoring using reference measurements. Across 16 LLMs evaluated zero-shot with greedy decoding, functional correctness is the dominant bottleneck: no model exceeds a 45% functional pass rate under our requirement-driven, reference-validated tests. We release RAL-Bench at https://github.com/Wwstarry/RAL-Bench. ."}
{"id": "2602.03550", "categories": ["cs.SE", "cs.FL", "cs.LO", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.03550", "abs": "https://arxiv.org/abs/2602.03550", "authors": ["Fang Yan", "Simon Foster", "Ana Cavalcanti", "Ibrahim Habli", "James Baxter"], "title": "Formal Evidence Generation for Assurance Cases for Robotic Software Models", "comment": "This is a preprint. The paper is currently under review at Software and Systems Modeling", "summary": "Robotics and Autonomous Systems are increasingly deployed in safety-critical domains, so that demonstrating their safety is essential. Assurance Cases (ACs) provide structured arguments supported by evidence, but generating and maintaining this evidence is labour-intensive, error-prone, and difficult to keep consistent as systems evolve. We present a model-based approach to systematically generating AC evidence by embedding formal verification into the assurance workflow. The approach addresses three challenges: systematically deriving formal assertions from natural language requirements using templates, orchestrating multiple formal verification tools to handle diverse property types, and integrating formal evidence production into the workflow. Leveraging RoboChart, a domain-specific modelling language with formal semantics, we combine model checking and theorem proving in our approach. Structured requirements are automatically transformed into formal assertions using predefined templates, and verification results are automatically integrated as evidence. Case studies demonstrate the effectiveness of our approach."}
{"id": "2602.03556", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03556", "abs": "https://arxiv.org/abs/2602.03556", "authors": ["Alexander Berndt", "Thomas Bach", "Sebastian Baltes"], "title": "Flaky Tests in a Large Industrial Database Management System: An Empirical Study of Fixed Issue Reports for SAP HANA", "comment": "8 pages, 2 tables, 5 figures, 3rd International Flaky Tests Workshop 2026 (FTW 2026)", "summary": "Flaky tests yield different results when executed multiple times for the same version of the source code. Thus, they provide an ambiguous signal about the quality of the code and interfere with the automated assessment of code changes. While a variety of factors can cause test flakiness, approaches to fix flaky tests are typically tailored to address specific causes. However, the prevalent root causes of flaky tests can vary depending on the programming language, application domain, or size of the software project. Since manually labeling flaky tests is time-consuming and tedious, this work proposes an LLMs-as-annotators approach that leverages intra- and inter-model consistency to label issue reports related to fixed flakiness issues with the relevant root cause category. This allows us to gain an overview of prevalent flakiness categories in the issue reports. We evaluated our labeling approach in the context of SAP HANA, a large industrial database management system. Our results suggest that SAP HANA's tests most commonly suffer from issues related to concurrency (23%, 130 of 559 analyzed issue reports). Moreover, our results suggest that different test types face different flakiness challenges. Therefore, we encourage future research on flakiness mitigation to consider evaluating the generalizability of proposed approaches across different test types."}
{"id": "2602.03557", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03557", "abs": "https://arxiv.org/abs/2602.03557", "authors": ["Yunhao Liang", "Ruixuan Ying", "Shiwen Ni", "Zhe Cui"], "title": "Scaling Test-Driven Code Generation from Functions to Classes: An Empirical Study", "comment": null, "summary": "Test-driven development (TDD) has been adopted to improve Large Language Model (LLM)-based code generation by using tests as executable specifications. However, existing TDD-style code generation studies are largely limited to function-level tasks, leaving class-level synthesis where multiple methods interact through shared state and call dependencies underexplored. In this paper, we scale test-driven code generation from functions to classes via an iterative TDD framework. Our approach first analyzes intra-class method dependencies to derive a feasible generation schedule, and then incrementally implements each method under method-level public tests with reflection-style execution feedback and bounded repair iterations. To support test-driven generation and rigorous class-level evaluation, we construct ClassEval-TDD, a cleaned and standardized variant of ClassEval with consistent specifications, deterministic test environments, and complete method-level public tests. We conduct an empirical study across eight LLMs and compare against the strongest direct-generation baseline (the best of holistic, incremental, and compositional strategies). Our class-level TDD framework consistently improves class-level correctness by 12 to 26 absolute points and achieves up to 71% fully correct classes, while requiring only a small number of repairs on average. These results demonstrate that test-driven generation can effectively scale beyond isolated functions and substantially improve class-level code generation reliability. All code and data are available at https://anonymous.4open.science/r/ClassEval-TDD-C4C9/"}
{"id": "2602.03585", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03585", "abs": "https://arxiv.org/abs/2602.03585", "authors": ["Lukas Schulte", "Gordon Fraser", "Steffen Herbold"], "title": "Causal Inference for the Effect of Code Coverage on Bug Introduction", "comment": "Registered Report with Continuity Acceptance (CA) for submission to Empirical Software Engineering granted by RR-Committee of the MSR'26", "summary": "Context: Code coverage is widely used as a software quality assurance measure. However, its effect, and specifically the advisable dose, are disputed in both the research and engineering communities. Prior work reports only correlational associations, leaving results vulnerable to confounding factors. Objective: We aim to quantify the causal effect of code coverage (exposure) on bug introduction (outcome) in the context of mature JavaScript and TypeScript open source projects, addressing both the overall effect and its variance across coverage levels. Method: We construct a causal directed acyclic graph to identify confounders within the software engineering process, modeling key variables from the source code, issue- and review systems, and continuous integration. Using generalized propensity score adjustment, we will apply doubly robust regression-based causal inference for continuous exposure to a novel dataset of bug-introducing and non-bug-introducing changes. We estimate the average treatment effect and dose-response relationship to examine potential non-linear patterns (e.g., thresholds or diminishing returns) within the projects of our dataset."}
{"id": "2602.03593", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03593", "abs": "https://arxiv.org/abs/2602.03593", "authors": ["Valerie Chen", "Jasmyn He", "Behnjamin Williams", "Jason Valentino", "Ameet Talwalkar"], "title": "Beyond the Commit: Developer Perspectives on Productivity with AI Coding Assistants", "comment": "ICSE SEIP", "summary": "Measuring developer productivity is a topic that has attracted attention from both academic research and industrial practice. In the age of AI coding assistants, it has become even more important for both academia and industry to understand how to measure their impact on developer productivity, and to reconsider whether earlier measures and frameworks still apply. This study analyzes the validity of different approaches to evaluating the productivity impacts of AI coding assistants by leveraging mixed-method research. At BNY Mellon, we conduct a survey with 2989 developer responses and 11 in-depth interviews. Our findings demonstrate that a multifaceted approach is needed to measure AI productivity impacts: survey results expose conflicting perspectives on AI tool usefulness, while interviews elicit six distinct factors that capture both short-term and long-term dimensions of productivity. In contrast to prior work, our factors highlight the importance of long-term metrics like technical expertise and ownership of work. We hope this work encourages future research to incorporate a broader range of human-centered factors, and supports industry in adopting more holistic approaches to evaluating developer productivity."}
{"id": "2602.03632", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03632", "abs": "https://arxiv.org/abs/2602.03632", "authors": ["Hemang Jain", "Divyansh Pandey", "Karthik Vaidhyanathan"], "title": "CALM: A Self-Adaptive Orchestration Approach for QoS-Aware Routing in Small Language Model based Systems", "comment": "Accepted as full paper at SEAMS 2026", "summary": "AI-enabled systems are subjected to various types of runtime uncertainties, ranging from dynamic workloads, resource requirements, model drift, etc. These uncertainties have a big impact on the overall Quality of Service (QoS). This is particularly true in the case of Language Model (LM) enabled systems where the autoregressive nature of token generation introduces variability in latency, energy usage and response quality. These systems, powered by LLMs, are either resource-intensive (if run on-prem) or raise privacy/cost concerns (if leveraged using APIs). While deploying a Small Language Model (SLM) can be resource-efficient, it often falls short in addressing the diversity and scale of real-world requirements. To this, we argue that, rather than relying on any one SLM, leveraging a coordinated fleet of SLMs, each with specialized strengths can enable systems to dynamically adapt to shifting contexts and workload patterns. However, realizing the full potential of such an approach demands intelligent orchestration and continuous adaptation. To this end, we introduce CALM , a self-adaptive orchestration mechanism based on MAPE-K. Our approach continuously monitors user queries, analyzes the QoS metrics of the SLMs, identifies the optimal SLM to be used, routes the query to the identified SLM and further to enhance the effectiveness and efficiency, leverages caching and scheduling to decide the SLMs to be kept in memory. Our evaluation shows that CALM reduces latency by approximately 40% and energy consumption by 50%, while preserving domain-specific task performance when compared to single-LLM baselines."}
{"id": "2602.03712", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03712", "abs": "https://arxiv.org/abs/2602.03712", "authors": ["Yisen Xu", "Jinqiu Yang", "Tse-Hsun", "Chen"], "title": "SWE-Refactor: A Repository-Level Benchmark for Real-World LLM-Based Code Refactoring", "comment": null, "summary": "Large Language Models (LLMs) have recently attracted wide interest for tackling software engineering tasks. In contrast to code generation, refactoring demands precise, semantics-preserving edits that improve program structure, which also makes automated evaluation challenging. However, existing refactoring benchmarks commonly suffer from three shortcomings: limited coverage of refactoring scenarios, the inclusion of instances that mix refactoring with unrelated changes, and insufficient repository-level context for realistic assessment. To mitigate these issues, we introduce SWE-Refactor, a new benchmark for LLM-based code refactoring. SWE-Refactor comprises 1,099 developer-written, behavior-preserving refactorings mined from 18 Java projects, including 922 atomic and 177 compound instances. Each instance is validated via compilation, test execution, and automated refactoring detection tools to ensure correctness. We evaluate nine widely used LLMs on SWE-Refactor, covering models such as GPT-4o-mini, DeepSeek-V3, and CodeLLaMa, to provide representative reference results. Our results show that complex and compound refactorings remain the primary source of failures; notably, an OpenAI Codex agent achieves only 39.4% success on compound instances. We release SWE-Refactor and all evaluation results to facilitate future research on LLM-based code refactoring."}
{"id": "2602.03755", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03755", "abs": "https://arxiv.org/abs/2602.03755", "authors": ["Facundo Molina", "M M Abid Naziri", "Feiran Qin", "Alessandra Gorla", "Marcelo d'Amorim"], "title": "Improving Deep Learning Library Testing with Machine Learning", "comment": "In proceedings of the 7th ACM/IEEE International Conference on Automation of Software Test (AST 2026)", "summary": "Deep Learning (DL) libraries like TensorFlow and Pytorch simplify machine learning (ML) model development but are prone to bugs due to their complex design. Bug-finding techniques exist, but without precise API specifications, they produce many false alarms. Existing methods to mine API specifications lack accuracy. We explore using ML classifiers to determine input validity. We hypothesize that tensor shapes are a precise abstraction to encode concrete inputs and capture relationships of the data. Shape abstraction severely reduces problem dimensionality, which is important to facilitate ML training. Labeled data are obtained by observing runtime outcomes on a sample of inputs and classifiers are trained on sets of labeled inputs to capture API constraints. Our evaluation, conducted over 183 APIs from TensorFlow and Pytorch, shows that the classifiers generalize well on unseen data with over 91% accuracy. Integrating these classifiers into the pipeline of ACETest, a SoTA bug-finding technique, improves its pass rate from ~29% to ~61%. Our findings suggest that ML-enhanced input classification is an important aid to scale DL library testing."}
{"id": "2602.03798", "categories": ["cs.SE", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.03798", "abs": "https://arxiv.org/abs/2602.03798", "authors": ["Zimu Lu", "Houxing Ren", "Yunqiao Yang", "Ke Wang", "Zhuofan Zong", "Mingjie Zhan", "Hongsheng Li"], "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation", "comment": null, "summary": "Assisting non-expert users to develop complex interactive websites has become a popular task for LLM-powered code agents. However, existing code agents tend to only generate frontend web pages, masking the lack of real full-stack data processing and storage with fancy visual effects. Notably, constructing production-level full-stack web applications is far more challenging than only generating frontend web pages, demanding careful control of data flow, comprehensive understanding of constantly updating packages and dependencies, and accurate localization of obscure bugs in the codebase. To address these difficulties, we introduce FullStack-Agent, a unified agent system for full-stack agentic coding that consists of three parts: (1) FullStack-Dev, a multi-agent framework with strong planning, code editing, codebase navigation, and bug localization abilities. (2) FullStack-Learn, an innovative data-scaling and self-improving method that back-translates crawled and synthesized website repositories to improve the backbone LLM of FullStack-Dev. (3) FullStack-Bench, a comprehensive benchmark that systematically tests the frontend, backend and database functionalities of the generated website. Our FullStack-Dev outperforms the previous state-of-the-art method by 8.7%, 38.2%, and 15.9% on the frontend, backend, and database test cases respectively. Additionally, FullStack-Learn raises the performance of a 30B model by 9.7%, 9.5%, and 2.8% on the three sets of test cases through self-improvement, demonstrating the effectiveness of our approach. The code is released at https://github.com/mnluzimu/FullStack-Agent."}
