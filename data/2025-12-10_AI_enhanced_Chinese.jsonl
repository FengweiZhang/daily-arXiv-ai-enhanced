{"id": "2512.08089", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.08089", "abs": "https://arxiv.org/abs/2512.08089", "authors": ["Jebacyril Arockiaraj", "Dhruv Parikh", "Viktor Prasanna"], "title": "NysX: An Accurate and Energy-Efficient FPGA Accelerator for Hyperdimensional Graph Classification at the Edge", "comment": null, "summary": "Real-time, energy-efficient inference on edge devices is essential for graph classification across a range of applications. Hyperdimensional Computing (HDC) is a brain-inspired computing paradigm that encodes input features into low-precision, high-dimensional vectors with simple element-wise operations, making it well-suited for resource-constrained edge platforms. Recent work enhances HDC accuracy for graph classification via Nystr\u00f6m kernel approximations. Edge acceleration of such methods faces several challenges: (i) redundancy among (landmark) samples selected via uniform sampling, (ii) storing the Nystr\u00f6m projection matrix under limited on-chip memory, (iii) expensive, contention-prone codebook lookups, and (iv) load imbalance due to irregular sparsity in SpMV. To address these challenges, we propose NysX, the first end-to-end FPGA accelerator for Nystr\u00f6m-based HDC graph classification at the edge. NysX integrates four key optimizations: (i) a hybrid landmark selection strategy combining uniform sampling with determinantal point processes (DPPs) to reduce redundancy while improving accuracy; (ii) a streaming architecture for Nystr\u00f6m projection matrix maximizing external memory bandwidth utilization; (iii) a minimal-perfect-hash lookup engine enabling $O(1)$ key-to-index mapping with low on-chip memory overhead; and (iv) sparsity-aware SpMV engines with static load balancing. Together, these innovations enable real-time, energy-efficient inference on resource-constrained platforms. Implemented on an AMD Zynq UltraScale+ (ZCU104) FPGA, NysX achieves $6.85\\times$ ($4.32\\times$) speedup and $169\\times$ ($314\\times$) energy efficiency gains over optimized CPU (GPU) baselines, while improving classification accuracy by $3.4\\%$ on average across TUDataset benchmarks, a widely used standard for graph classification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNysX\uff0c\u4e00\u79cd\u9762\u5411\u8fb9\u7f18\u8bbe\u5907\u7684\u7aef\u5230\u7aefFPGA\u52a0\u901f\u5668\uff0c\u7528\u4e8e\u57fa\u4e8eNystr\u00f6m\u8fd1\u4f3c\u7684\u8d85\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u56fe\u5206\u7c7b\u3002\u901a\u8fc7\u56db\u9879\u5173\u952e\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u3001\u80fd\u6548\u4e0e\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u56fe\u5206\u7c7b\u9700\u8981\u517c\u987e\u5b9e\u65f6\u6027\u4e0e\u80fd\u6548\uff0c\u800c\u73b0\u6709\u57fa\u4e8eNystr\u00f6m\u6838\u8fd1\u4f3c\u7684HDC\u65b9\u6cd5\u5728\u786c\u4ef6\u52a0\u901f\u65b9\u9762\u9762\u4e34\u6837\u672c\u5197\u4f59\u3001\u5185\u5b58\u9650\u5236\u3001\u67e5\u8868\u5f00\u9500\u5927\u548c\u8d1f\u8f7d\u4e0d\u5747\u8861\u7b49\u6311\u6218\u3002", "method": "NysX\u91c7\u7528\u56db\u5927\u4f18\u5316\u7b56\u7565\uff1a(i) \u7ed3\u5408\u5747\u5300\u91c7\u6837\u4e0e\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\uff08DPP\uff09\u7684\u6df7\u5408\u5730\u6807\u9009\u62e9\uff1b(ii) \u6d41\u5f0fNystr\u00f6m\u6295\u5f71\u77e9\u9635\u67b6\u6784\u4ee5\u9ad8\u6548\u5229\u7528\u5916\u90e8\u5e26\u5bbd\uff1b(iii) \u6700\u5c0f\u5b8c\u7f8e\u54c8\u5e0c\u67e5\u8868\u5f15\u64ce\u5b9e\u73b0O(1)\u6620\u5c04\uff1b(iv) \u9759\u6001\u8d1f\u8f7d\u5747\u8861\u7684\u7a00\u758f\u77e9\u9635\u5411\u91cf\u4e58\uff08SpMV\uff09\u5f15\u64ce\u3002", "result": "\u5728AMD Zynq UltraScale+ FPGA\u4e0a\u5b9e\u73b0\u7684NysX\u76f8\u6bd4\u4f18\u5316\u540e\u7684CPU\uff08GPU\uff09\u57fa\u7ebf\uff0c\u5206\u522b\u83b7\u5f976.85\u500d\uff084.32\u500d\uff09\u52a0\u901f\u548c169\u500d\uff08314\u500d\uff09\u80fd\u6548\u63d0\u5347\uff0c\u5e76\u5728TUDataset\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u53473.4%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "NysX\u6709\u6548\u89e3\u51b3\u4e86Nystr\u00f6m-HDC\u56fe\u5206\u7c7b\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u3001\u9ad8\u80fd\u6548\u4e0e\u5b9e\u65f6\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u7684\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.08242", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.08242", "abs": "https://arxiv.org/abs/2512.08242", "authors": ["Marco Kurzynski", "Shaizeen Aga", "Di Wu"], "title": "Chopper: A Multi-Level GPU Characterization Tool & Derived Insights Into LLM Training Inefficiency", "comment": null, "summary": "Training large language models (LLMs) efficiently requires a deep understanding of how modern GPU systems behave under real-world distributed training workloads. While prior work has focused primarily on kernel-level performance or single-GPU microbenchmarks, the complex interaction between communication, computation, memory behavior, and power management in multi-GPU LLM training remains poorly characterized. In this work, we introduce Chopper, a profiling and analysis framework that collects, aligns, and visualizes GPU kernel traces and hardware performance counters across multiple granularities (i.e., from individual kernels to operations, layers, phases, iterations, and GPUs). Using Chopper, we perform a comprehensive end-to-end characterization of Llama 3 8B training under fully sharded data parallelism (FSDP) on an eight-GPU AMD InstinctTM MI300X node. Our analysis reveals several previously underexplored bottlenecks and behaviors, such as memory determinism enabling higher, more stable GPU and memory frequencies. We identify several sources of inefficiencies, with frequency overhead (DVFS effects) being the single largest contributor to the gap between theoretical and observed performance, exceeding the impact of MFMA utilization loss, communication/computation overlap, and kernel launch overheads. Overall, Chopper provides the first holistic, multi-granularity characterization of LLM training on AMD InstinctTM MI300X GPUs, yielding actionable insights for optimizing training frameworks, improving power-management strategies, and guiding future GPU architecture and system design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 Chopper\uff0c\u4e00\u4e2a\u7528\u4e8e\u591a\u7c92\u5ea6\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bad\u7ec3\u4e2d GPU \u6027\u80fd\u7684\u5256\u6790\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e AMD MI300X \u5e73\u53f0\u5bf9 Llama 3 8B \u7684 FSDP \u8bad\u7ec3\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u63ed\u793a\u4e86\u9891\u7387\u8c03\u63a7\uff08DVFS\uff09\u662f\u6027\u80fd\u5dee\u8ddd\u7684\u4e3b\u8981\u6765\u6e90\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u4e8e\u5355 GPU \u6216\u5185\u6838\u7ea7\u6027\u80fd\uff0c\u7f3a\u4e4f\u5bf9\u591a GPU \u5206\u5e03\u5f0f LLM \u8bad\u7ec3\u4e2d\u901a\u4fe1\u3001\u8ba1\u7b97\u3001\u5185\u5b58\u4e0e\u529f\u8017\u7ba1\u7406\u4e4b\u95f4\u590d\u6742\u4ea4\u4e92\u7684\u7cfb\u7edf\u6027\u523b\u753b\u3002", "method": "\u5f00\u53d1 Chopper \u6846\u67b6\uff0c\u6536\u96c6\u3001\u5bf9\u9f50\u5e76\u53ef\u89c6\u5316\u591a\u7c92\u5ea6\uff08\u4ece\u5185\u6838\u5230 GPU\uff09\u7684 GPU \u5185\u6838\u8f68\u8ff9\u4e0e\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\uff0c\u5728\u516b\u5361 AMD MI300X \u8282\u70b9\u4e0a\u5bf9 Llama 3 8B \u7684 FSDP \u8bad\u7ec3\u8fdb\u884c\u7aef\u5230\u7aef\u5256\u6790\u3002", "result": "\u53d1\u73b0\u5185\u5b58\u786e\u5b9a\u6027\u53ef\u63d0\u5347 GPU \u548c\u663e\u5b58\u9891\u7387\u7a33\u5b9a\u6027\uff1b\u8bc6\u522b\u51fa DVFS \u5f15\u8d77\u7684\u9891\u7387\u5f00\u9500\u662f\u7406\u8bba\u4e0e\u5b9e\u9645\u6027\u80fd\u5dee\u8ddd\u7684\u6700\u5927\u56e0\u7d20\uff0c\u8d85\u8fc7 MFMA \u5229\u7528\u7387\u635f\u5931\u3001\u901a\u4fe1/\u8ba1\u7b97\u91cd\u53e0\u4e0d\u8db3\u53ca\u5185\u6838\u542f\u52a8\u5f00\u9500\u3002", "conclusion": "Chopper \u9996\u6b21\u5b9e\u73b0\u4e86\u5bf9 AMD MI300X \u4e0a LLM \u8bad\u7ec3\u7684\u591a\u7c92\u5ea6\u6574\u4f53\u523b\u753b\uff0c\u4e3a\u8bad\u7ec3\u6846\u67b6\u4f18\u5316\u3001\u7535\u6e90\u7ba1\u7406\u7b56\u7565\u6539\u8fdb\u53ca\u672a\u6765 GPU \u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6d1e\u89c1\u3002"}}
{"id": "2512.08858", "categories": ["cs.OS", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.08858", "abs": "https://arxiv.org/abs/2512.08858", "authors": ["Reima Ishii", "Takaaki Fukai", "Takahiro Shinagawa"], "title": "NecoFuzz: Effective Fuzzing of Nested Virtualization via Fuzz-Harness Virtual Machines", "comment": "To appear in EuroSys 2026", "summary": "Nested virtualization is now widely supported by major cloud vendors, allowing users to leverage virtualization-based technologies in the cloud. However, supporting nested virtualization significantly increases host hypervisor complexity and introduces a new attack surface in cloud platforms. While many prior studies have explored hypervisor fuzzing, none has explicitly addressed nested virtualization due to the challenge of generating effective virtual machine (VM) instances with a vast state space as fuzzing inputs.\n  We present NecoFuzz, the first fuzzing framework that systematically targets nested virtualization-specific logic in hypervisors. NecoFuzz synthesizes executable fuzz-harness VMs with internal states near the boundary between valid and invalid, guided by an approximate model of hardware-assisted virtualization specifications. Since vulnerabilities in nested virtualization often stem from incorrect handling of unexpected VM states, this specification-guided, boundary-oriented generation significantly improves coverage of security-critical code across different hypervisors.\n  We implemented NecoFuzz on Intel VT-x and AMD-V by extending AFL++ to support fuzz-harness VMs. NecoFuzz achieved 84.7% and 74.2% code coverage for nested virtualization-specific code on Intel VT-x and AMD-V, respectively, and uncovered six previously unknown vulnerabilities across three hypervisors, including two assigned CVEs.", "AI": {"tldr": "NecoFuzz \u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u5d4c\u5957\u865a\u62df\u5316\u903b\u8f91\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u63a5\u8fd1\u6709\u6548/\u65e0\u6548\u8fb9\u754c\u72b6\u6001\u7684\u53ef\u6267\u884c\u865a\u62df\u673a\u5b9e\u4f8b\uff0c\u5728 Intel VT-x \u548c AMD-V \u4e0a\u5b9e\u73b0\u4e86\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u5e76\u53d1\u73b0\u4e86\u591a\u4e2a\u65b0\u6f0f\u6d1e\u3002", "motivation": "\u5d4c\u5957\u865a\u62df\u5316\u589e\u52a0\u4e86\u5bbf\u4e3b\u673a\u7ba1\u7406\u7a0b\u5e8f\u7684\u590d\u6742\u6027\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\uff0c\u800c\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u8986\u76d6\u5d4c\u5957\u865a\u62df\u5316\u573a\u666f\uff0c\u4e3b\u8981\u56e0\u4e3a\u96be\u4ee5\u5728\u5e9e\u5927\u7684\u865a\u62df\u673a\u72b6\u6001\u7a7a\u95f4\u4e2d\u751f\u6210\u6709\u6548\u7684\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\u3002", "method": "NecoFuzz \u5229\u7528\u5bf9\u786c\u4ef6\u8f85\u52a9\u865a\u62df\u5316\u89c4\u8303\u7684\u8fd1\u4f3c\u5efa\u6a21\uff0c\u751f\u6210\u5185\u90e8\u72b6\u6001\u5904\u4e8e\u6709\u6548\u4e0e\u65e0\u6548\u8fb9\u754c\u9644\u8fd1\u7684\u53ef\u6267\u884c\u6a21\u7cca\u6d4b\u8bd5\u865a\u62df\u673a\uff0c\u5e76\u57fa\u4e8e AFL++ \u6269\u5c55\u5b9e\u73b0\u5bf9 Intel VT-x \u548c AMD-V \u7684\u652f\u6301\u3002", "result": "\u5728 Intel VT-x \u548c AMD-V \u4e0a\u5206\u522b\u8fbe\u5230 84.7% \u548c 74.2% \u7684\u5d4c\u5957\u865a\u62df\u5316\u76f8\u5173\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u5e76\u5728\u4e09\u4e2a\u7ba1\u7406\u7a0b\u5e8f\u4e2d\u53d1\u73b0\u4e86\u516d\u4e2a\u6b64\u524d\u672a\u77e5\u7684\u6f0f\u6d1e\uff0c\u5176\u4e2d\u4e24\u4e2a\u5df2\u5206\u914d CVE \u7f16\u53f7\u3002", "conclusion": "NecoFuzz \u8bc1\u660e\u4e86\u901a\u8fc7\u89c4\u8303\u5f15\u5bfc\u3001\u8fb9\u754c\u5bfc\u5411\u7684\u865a\u62df\u673a\u751f\u6210\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u5d4c\u5957\u865a\u62df\u5316\u5b89\u5168\u5173\u952e\u4ee3\u7801\u7684\u6a21\u7cca\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u5e76\u6210\u529f\u63ed\u793a\u4e86\u771f\u5b9e\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u3002"}}
{"id": "2512.08483", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.08483", "abs": "https://arxiv.org/abs/2512.08483", "authors": ["Lingze Zeng", "Naili Xing", "Shaofeng Cai", "Peng Lu", "Gang Chen", "Jian Pei", "Beng Chin Ooi"], "title": "NeurIDA: Dynamic Modeling for Effective In-Database Analytics", "comment": "13 pages", "summary": "Relational Database Management Systems (RDBMS) manage complex, interrelated data and support a broad spectrum of analytical tasks. With the growing demand for predictive analytics, the deep integration of machine learning (ML) into RDBMS has become critical. However, a fundamental challenge hinders this evolution: conventional ML models are static and task-specific, whereas RDBMS environments are dynamic and must support diverse analytical queries. Each analytical task entails constructing a bespoke pipeline from scratch, which incurs significant development overhead and hence limits wide adoption of ML in analytics.\n  We present NeurIDA, an autonomous end-to-end system for in-database analytics that dynamically \"tweaks\" the best available base model to better serve a given analytical task. In particular, we propose a novel paradigm of dynamic in-database modeling to pre-train a composable base model architecture over the relational data. Upon receiving a task, NeurIDA formulates the task and data profile to dynamically select and configure relevant components from the pool of base models and shared model components for prediction. For friendly user experience, NeurIDA supports natural language queries; it interprets user intent to construct structured task profiles, and generates analytical reports with dedicated LLM agents. By design, NeurIDA enables ease-of-use and yet effective and efficient in-database AI analytics. Extensive experiment study shows that NeurIDA consistently delivers up to 12% improve- ment in AUC-ROC and 25% relative reduction in MAE across ten tasks on five real-world datasets. The source code is available at https://github.com/Zrealshadow/NeurIDA", "AI": {"tldr": "NeurIDA \u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6570\u636e\u5e93\u5185\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u9884\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\u4ee5\u9002\u5e94\u4e0d\u540c\u5206\u6790\u4efb\u52a1\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5e76\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5173\u7cfb\u578b\u6570\u636e\u5e93\u73af\u5883\u4e2d\u5b58\u5728\u9759\u6001\u6027\u548c\u4efb\u52a1\u7279\u5b9a\u6027\u95ee\u9898\uff0c\u96be\u4ee5\u5e94\u5bf9\u591a\u6837\u5316\u7684\u52a8\u6001\u5206\u6790\u9700\u6c42\uff0c\u5bfc\u81f4\u5f00\u53d1\u6210\u672c\u9ad8\u3001ML \u5728\u6570\u636e\u5e93\u5206\u6790\u4e2d\u96be\u4ee5\u5e7f\u6cdb\u91c7\u7528\u3002", "method": "\u63d0\u51fa NeurIDA \u7cfb\u7edf\uff0c\u91c7\u7528\u52a8\u6001\u6570\u636e\u5e93\u5185\u5efa\u6a21\u8303\u5f0f\uff0c\u9884\u8bad\u7ec3\u53ef\u7ec4\u5408\u7684\u57fa\u7840\u6a21\u578b\u67b6\u6784\uff1b\u6839\u636e\u4efb\u52a1\u548c\u6570\u636e\u7279\u5f81\u52a8\u6001\u9009\u62e9\u4e0e\u914d\u7f6e\u6a21\u578b\u7ec4\u4ef6\uff0c\u5e76\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u652f\u6301\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0e\u5206\u6790\u62a5\u544a\u751f\u6210\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5341\u9879\u4efb\u52a1\u4e2d\uff0cNeurIDA \u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6700\u9ad8\u63d0\u5347 12% \u7684 AUC-ROC\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u964d\u4f4e 25%\u3002", "conclusion": "NeurIDA \u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u6613\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u6570\u636e\u5e93\u5185 AI \u5206\u6790\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf ML \u6a21\u578b\u5728 RDBMS \u4e2d\u90e8\u7f72\u4e0e\u9002\u914d\u7684\u96be\u9898\u3002"}}
{"id": "2512.07917", "categories": ["cs.SE", "cs.AI", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.07917", "abs": "https://arxiv.org/abs/2512.07917", "authors": ["Zhehao Dong", "Shanghai Du", "Zhen Lu", "Yue Yang"], "title": "CFD-copilot: leveraging domain-adapted large language model and model context protocol to enhance simulation automation", "comment": null, "summary": "Configuring computational fluid dynamics (CFD) simulations requires significant expertise in physics modeling and numerical methods, posing a barrier to non-specialists. Although automating scientific tasks with large language models (LLMs) has attracted attention, applying them to the complete, end-to-end CFD workflow remains a challenge due to its stringent domain-specific requirements. We introduce CFD-copilot, a domain-specialized LLM framework designed to facilitate natural language-driven CFD simulation from setup to post-processing. The framework employs a fine-tuned LLM to directly translate user descriptions into executable CFD setups. A multi-agent system integrates the LLM with simulation execution, automatic error correction, and result analysis. For post-processing, the framework utilizes the model context protocol (MCP), an open standard that decouples LLM reasoning from external tool execution. This modular design allows the LLM to interact with numerous specialized post-processing functions through a unified and scalable interface, improving the automation of data extraction and analysis. The framework was evaluated on benchmarks including the NACA~0012 airfoil and the three-element 30P-30N airfoil. The results indicate that domain-specific adaptation and the incorporation of the MCP jointly enhance the reliability and efficiency of LLM-driven engineering workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CFD-copilot\uff0c\u4e00\u4e2a\u4e13\u7528\u4e8e\u8ba1\u7b97\u6d41\u4f53\u529b\u5b66\uff08CFD\uff09\u7684\u9886\u57df\u5b9a\u5236\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u4ece\u5efa\u6a21\u5230\u540e\u5904\u7406\u7684\u5b8c\u6574CFD\u5de5\u4f5c\u6d41\uff0c\u5e76\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u63d0\u5347\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "motivation": "CFD\u4eff\u771f\u914d\u7f6e\u9700\u8981\u6df1\u539a\u7684\u7269\u7406\u5efa\u6a21\u548c\u6570\u503c\u65b9\u6cd5\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5bf9\u975e\u4e13\u5bb6\u6784\u6210\u95e8\u69db\uff1b\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u79d1\u5b66\u4efb\u52a1\u81ea\u52a8\u5316\u65b9\u9762\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5c06\u5176\u5e94\u7528\u4e8e\u7aef\u5230\u7aefCFD\u6d41\u7a0b\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u8be5\u6846\u67b6\u91c7\u7528\u5fae\u8c03\u540e\u7684LLM\u5c06\u7528\u6237\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u76f4\u63a5\u8f6c\u5316\u4e3a\u53ef\u6267\u884cCFD\u8bbe\u7f6e\uff0c\u5e76\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u96c6\u6210\u4eff\u771f\u6267\u884c\u3001\u81ea\u52a8\u7ea0\u9519\u548c\u7ed3\u679c\u5206\u6790\uff1b\u540e\u5904\u7406\u9636\u6bb5\u5229\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u5b9e\u73b0LLM\u4e0e\u5916\u90e8\u5de5\u5177\u7684\u89e3\u8026\uff0c\u652f\u6301\u7edf\u4e00\u63a5\u53e3\u8c03\u7528\u591a\u79cd\u4e13\u7528\u540e\u5904\u7406\u529f\u80fd\u3002", "result": "\u5728NACA 0012\u548c\u4e09\u6bb5\u5f0f30P-30N\u7ffc\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCFD-copilot\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\u9886\u57df\u5b9a\u5236\u4e0eMCP\u7ed3\u5408\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c06\u9886\u57df\u4e13\u7528\u5fae\u8c03\u4e0eMCP\u76f8\u7ed3\u5408\uff0c\u80fd\u663e\u8457\u63d0\u5347LLM\u5728\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\u5982CFD\u4e2d\u7684\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u4e3a\u975e\u4e13\u5bb6\u7528\u6237\u63d0\u4f9b\u9ad8\u6548\u3001\u53ef\u9760\u7684\u4eff\u771f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08005", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08005", "abs": "https://arxiv.org/abs/2512.08005", "authors": ["Stepan Vanecek", "Matthew Turner", "Manisha Gajbe", "Matthew Wolf", "Martin Schulz"], "title": "Modeling the Potential of Message-Free Communication via CXL.mem", "comment": "14 pages, including References, 10 figures, to be published in SCA/HPCAsia 2026: Supercomputing Asia and International Conference on High Performance Computing in Asia Pacific Region (SCA/HPCAsia 2026)", "summary": "Heterogeneous memory technologies are increasingly important instruments in addressing the memory wall in HPC systems. While most are deployed in single node setups, CXL.mem is a technology that implements memories that can be attached to multiple nodes simultaneously, enabling shared memory pooling. This opens new possibilities, particularly for efficient inter-node communication.\n  In this paper, we present a novel performance evaluation toolchain combined with an extended performance model for message-based communication, which can be used to predict potential performance benefits from using CXL.mem for data exchange. Our approach analyzes data access patterns of MPI applications: it analyzes on-node accesses to/from MPI buffers, as well as cross-node MPI traffic to gather a full understanding of the impact of memory performance. We combine this data in an extended performance model to predict which data transfers could benefit from direct CXL.mem implementations as compared to traditional MPI messages. Our model works on a per-MPI call granularity, allowing the identification and later optimizations of those MPI invocations in the code with the highest potential for speedup by using CXL.mem.\n  For our toolchain, we extend the memory trace sampling tool Mitos and use it to extract data access behavior. In the post-processing step, the raw data is automatically analyzed to provide performance models for each individual MPI call. We validate the models on two sample applications -- a 2D heat transfer miniapp and the HPCG benchmark -- and use them to demonstrate their support for targeted optimizations by integrating CXL.mem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8bc4\u4f30CXL.mem\u5728MPI\u901a\u4fe1\u4e2d\u6027\u80fd\u6f5c\u529b\u7684\u65b0\u5de5\u5177\u94fe\u548c\u6269\u5c55\u6027\u80fd\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790MPI\u5e94\u7528\u7684\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\uff0c\u9884\u6d4b\u54ea\u4e9b\u6570\u636e\u4f20\u8f93\u53ef\u901a\u8fc7CXL.mem\u83b7\u5f97\u6bd4\u4f20\u7edfMPI\u6d88\u606f\u66f4\u9ad8\u7684\u6027\u80fd\uff0c\u5e76\u5728\u4e24\u4e2a\u5e94\u7528\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u5f02\u6784\u5185\u5b58\u6280\u672f\u7684\u53d1\u5c55\uff0cCXL.mem\u652f\u6301\u591a\u8282\u70b9\u5171\u4eab\u5185\u5b58\u6c60\uff0c\u4e3a\u9ad8\u6548\u8de8\u8282\u70b9\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002\u7136\u800c\uff0c\u5c1a\u7f3a\u4e4f\u6709\u6548\u5de5\u5177\u6765\u8bc4\u4f30\u5176\u5728\u5b9e\u9645MPI\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u6536\u76ca\u3002", "method": "\u4f5c\u8005\u6269\u5c55\u4e86\u5185\u5b58\u8ffd\u8e2a\u91c7\u6837\u5de5\u5177Mitos\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6027\u80fd\u8bc4\u4f30\u5de5\u5177\u94fe\uff0c\u53ef\u5206\u6790MPI\u5e94\u7528\u7684\u7247\u4e0a\u7f13\u51b2\u533a\u8bbf\u95ee\u548c\u8de8\u8282\u70b9\u901a\u4fe1\u6d41\u91cf\uff0c\u5e76\u57fa\u4e8e\u6bcf\u4e2aMPI\u8c03\u7528\u7c92\u5ea6\u5efa\u7acb\u6269\u5c55\u6027\u80fd\u6a21\u578b\uff0c\u4ee5\u9884\u6d4bCXL.mem\u5e26\u6765\u7684\u6f5c\u5728\u52a0\u901f\u6548\u679c\u3002", "result": "\u57282D\u70ed\u4f20\u5bfcminiapp\u548cHPCG\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u8be5\u6a21\u578b\u6307\u5bfc\u9488\u5bf9CXL.mem\u7684\u4f18\u5316\u3002", "conclusion": "\u8be5\u5de5\u5177\u94fe\u548c\u6027\u80fd\u6a21\u578b\u80fd\u6709\u6548\u8bc6\u522bMPI\u7a0b\u5e8f\u4e2d\u9002\u5408\u91c7\u7528CXL.mem\u8fdb\u884c\u4f18\u5316\u7684\u901a\u4fe1\u64cd\u4f5c\uff0c\u4e3a\u672a\u6765\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u4e2dCXL.mem\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5206\u6790\u4e0e\u4f18\u5316\u624b\u6bb5\u3002"}}
{"id": "2512.08526", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.08526", "abs": "https://arxiv.org/abs/2512.08526", "authors": ["Shunit Agmon", "Jonathan Gal", "Amir Gilad", "Ester Livshits", "Or Mutay", "Brit Youngmann", "Benny Kimelfeld"], "title": "Analyzing Deviations from Monotonic Trends through Database Repair", "comment": null, "summary": "Datasets often exhibit violations of expected monotonic trends - for example, higher education level correlating with higher average salary, newer homes being more expensive, or diabetes prevalence increasing with age. We address the problem of quantifying how far a dataset deviates from such trends. To this end, we introduce Aggregate Order Dependencies (AODs), an aggregation-centric extension of the previously studied order dependencies. An AOD specifies that the aggregated value of a target attribute (e.g., mean salary) should monotonically increase or decrease with the grouping attribute (e.g., education level).\n  We formulate the AOD repair problem as finding the smallest set of tuples to delete from a table so that the given AOD is satisfied. We analyze the computational complexity of this problem and propose a general algorithmic template for solving it. We instantiate the template for common aggregation functions, introduce optimization techniques that substantially improve the runtime of the template instances, and develop efficient heuristic alternatives. Our experimental study, carried out on both real-world and synthetic datasets, demonstrates the practical efficiency of the algorithms and provides insight into the performance of the heuristics. We also present case studies that uncover and explain unexpected AOD violations using our framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u805a\u5408\u5e8f\u4f9d\u8d56\uff08AOD\uff09\u6765\u91cf\u5316\u6570\u636e\u96c6\u4e2d\u8fdd\u53cd\u9884\u671f\u5355\u8c03\u8d8b\u52bf\u7684\u7a0b\u5ea6\uff0c\u5e76\u7814\u7a76\u4e86\u901a\u8fc7\u5220\u9664\u6700\u5c11\u5143\u7ec4\u4f7f\u6570\u636e\u6ee1\u8db3AOD\u7684\u4fee\u590d\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u901a\u7528\u7b97\u6cd5\u6846\u67b6\u3001\u4f18\u5316\u7b56\u7565\u4e0e\u9ad8\u6548\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u5b9e\u6570\u636e\u96c6\u4e2d\u5e38\u51fa\u73b0\u8fdd\u80cc\u9884\u671f\u5355\u8c03\u8d8b\u52bf\u7684\u73b0\u8c61\uff08\u5982\u6559\u80b2\u6c34\u5e73\u8d8a\u9ad8\u5e73\u5747\u85aa\u8d44\u53cd\u800c\u8d8a\u4f4e\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5ea6\u91cf\u548c\u4fee\u590d\u6b64\u7c7b\u504f\u5dee\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u523b\u753b\u805a\u5408\u503c\u4e0e\u5206\u7ec4\u5c5e\u6027\u4e4b\u95f4\u5355\u8c03\u5173\u7cfb\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u3002", "method": "\u5f15\u5165\u805a\u5408\u5e8f\u4f9d\u8d56\uff08AOD\uff09\u6982\u5ff5\uff0c\u5c06AOD\u4fee\u590d\u95ee\u9898\u5efa\u6a21\u4e3a\u6700\u5c0f\u5143\u7ec4\u5220\u9664\u95ee\u9898\uff1b\u63d0\u51fa\u901a\u7528\u7b97\u6cd5\u6a21\u677f\uff0c\u5e76\u9488\u5bf9\u5e38\u7528\u805a\u5408\u51fd\u6570\u8fdb\u884c\u5b9e\u4f8b\u5316\uff1b\u7ed3\u5408\u4f18\u5316\u6280\u672f\u548c\u542f\u53d1\u5f0f\u7b56\u7565\u63d0\u5347\u6548\u7387\u3002", "result": "\u5728\u771f\u5b9e\u4e0e\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u5177\u6709\u826f\u597d\u7684\u5b9e\u9645\u6548\u7387\uff0c\u542f\u53d1\u5f0f\u65b9\u6cd5\u8868\u73b0\u63a5\u8fd1\u6700\u4f18\u89e3\uff1b\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u53d1\u73b0\u548c\u89e3\u91ca\u5f02\u5e38AOD\u8fdd\u53cd\u65b9\u9762\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u805a\u5408\u5e8f\u4f9d\u8d56\uff08AOD\uff09\u4e3a\u91cf\u5316\u548c\u4fee\u590d\u6570\u636e\u4e2d\u8fdd\u53cd\u5355\u8c03\u8d8b\u52bf\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u4f18\u5316\u7b56\u7565\u5728\u5b9e\u8df5\u4e2d\u9ad8\u6548\u53ef\u884c\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6570\u636e\u8d28\u91cf\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2512.07921", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07921", "abs": "https://arxiv.org/abs/2512.07921", "authors": ["Zongwei Li", "Zhonghang Li", "Zirui Guo", "Xubin Ren", "Chao Huang"], "title": "DeepCode: Open Agentic Coding", "comment": "for source code, please see https://github.com/HKUDS/DeepCode", "summary": "Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face significant challenges in achieving high-fidelity document-to-codebase synthesis--such as scientific papers to code--primarily due to a fundamental conflict between information overload and the context bottlenecks of LLMs. In this work, we introduce DeepCode, a fully autonomous framework that fundamentally addresses this challenge through principled information-flow management. By treating repository synthesis as a channel optimization problem, DeepCode seamlessly orchestrates four information operations to maximize task-relevant signals under finite context budgets: source compression via blueprint distillation, structured indexing using stateful code memory, conditional knowledge injection via retrieval-augmented generation, and closed-loop error correction. Extensive evaluations on the PaperBench benchmark demonstrate that DeepCode achieves state-of-the-art performance, decisively outperforming leading commercial agents such as Cursor and Claude Code, and crucially, surpassing PhD-level human experts from top institutes on key reproduction metrics. By systematically transforming paper specifications into production-grade implementations comparable to human expert quality, this work establishes new foundations for autonomous scientific reproduction that can accelerate research evaluation and discovery.", "AI": {"tldr": "DeepCode \u662f\u4e00\u4e2a\u5168\u81ea\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u4fe1\u606f\u6d41\u7ba1\u7406\uff0c\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u9650\u5236\u4e0b\u9ad8\u6548\u5730\u5c06\u79d1\u7814\u8bba\u6587\u8f6c\u5316\u4e3a\u9ad8\u8d28\u91cf\u4ee3\u7801\u5e93\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5546\u4e1a\u7f16\u7801\u667a\u80fd\u4f53\u548c\u4eba\u7c7b\u4e13\u5bb6\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c06\u79d1\u7814\u8bba\u6587\u7b49\u590d\u6742\u6587\u6863\u9ad8\u4fdd\u771f\u5730\u8f6c\u5316\u4e3a\u5b8c\u6574\u4ee3\u7801\u5e93\u65f6\u9762\u4e34\u4fe1\u606f\u8fc7\u8f7d\u4e0e\u4e0a\u4e0b\u6587\u74f6\u9888\u4e4b\u95f4\u7684\u6839\u672c\u77db\u76fe\u3002", "method": "DeepCode \u5c06\u4ee3\u7801\u5e93\u5408\u6210\u89c6\u4e3a\u4fe1\u9053\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u56db\u79cd\u4fe1\u606f\u64cd\u4f5c\u534f\u540c\u5de5\u4f5c\uff1a\u84dd\u56fe\u84b8\u998f\u5b9e\u73b0\u6e90\u538b\u7f29\u3001\u57fa\u4e8e\u72b6\u6001\u5316\u4ee3\u7801\u8bb0\u5fc6\u7684\u7ed3\u6784\u5316\u7d22\u5f15\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5b9e\u73b0\u6761\u4ef6\u77e5\u8bc6\u6ce8\u5165\uff0c\u4ee5\u53ca\u95ed\u73af\u9519\u8bef\u4fee\u6b63\u3002", "result": "\u5728 PaperBench \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepCode \u5728\u5173\u952e\u590d\u73b0\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a Cursor \u548c Claude Code \u7b49\u4e3b\u6d41\u5546\u4e1a\u667a\u80fd\u4f53\uff0c\u5e76\u4f18\u4e8e\u9876\u5c16\u673a\u6784\u7684\u535a\u58eb\u7ea7\u4eba\u7c7b\u4e13\u5bb6\u3002", "conclusion": "DeepCode \u4e3a\u81ea\u4e3b\u79d1\u5b66\u590d\u73b0\u5960\u5b9a\u4e86\u65b0\u57fa\u7840\uff0c\u80fd\u7cfb\u7edf\u6027\u5730\u5c06\u8bba\u6587\u89c4\u8303\u8f6c\u5316\u4e3a\u5ab2\u7f8e\u4eba\u7c7b\u4e13\u5bb6\u7684\u751f\u4ea7\u7ea7\u4ee3\u7801\uff0c\u4ece\u800c\u52a0\u901f\u79d1\u7814\u8bc4\u4f30\u4e0e\u53d1\u73b0\u3002"}}
{"id": "2512.08067", "categories": ["cs.DC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.08067", "abs": "https://arxiv.org/abs/2512.08067", "authors": ["Qingyang Hu", "Yucheng Huang", "Manshi Yang"], "title": "CapsuleFS A Multi-credential DataCapsule Filesystem", "comment": null, "summary": "CapsuleFS (CFS) is the first filesystem to integrate multi-credential functionality within a POSIX-compliant framework, utilizing DataCapsule as the storage provider. This innovative system is established based on the Global Data Plane in the area of edge computing. Our comprehensive design and implementation of CFS successfully fulfill the objective of providing a multi-credential Common Access API. The architecture of CFS is methodically segmented into three integral components: Firstly, the DataCapsule server, tasked with the storage, dissemination, and replication of DataCapsules on the edge. Secondly, the middleware, a crucial element running in a Trusted Execution Environment responsible for the enforcement and management of write permissions and requests. Finally, the client component, which manifests as a POSIX-compliant filesystem, is adaptable and operational across many architectures. Experimental evaluations of CFS reveal that, while its read and write performances are comparatively modest, it upholds a high degree of functional correctness. This attribute distinctly positions CFS as a viable candidate for application in real-world software development scenarios. The paper also delineates potential future enhancements, aimed at augmenting the practicality of CFS in the landscape of software development.", "AI": {"tldr": "CapsuleFS\uff08CFS\uff09\u662f\u9996\u4e2a\u5728 POSIX \u517c\u5bb9\u6846\u67b6\u4e2d\u96c6\u6210\u591a\u51ed\u8bc1\u529f\u80fd\u7684\u6587\u4ef6\u7cfb\u7edf\uff0c\u57fa\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u5168\u5c40\u6570\u636e\u5e73\u9762\uff0c\u5229\u7528 DataCapsule \u4f5c\u4e3a\u5b58\u50a8\u63d0\u4f9b\u8005\u3002\u5176\u67b6\u6784\u5305\u62ec DataCapsule \u670d\u52a1\u5668\u3001\u53ef\u4fe1\u6267\u884c\u73af\u5883\u4e2d\u7684\u4e2d\u95f4\u4ef6\u548c POSIX \u517c\u5bb9\u5ba2\u6237\u7aef\u3002\u5b9e\u9a8c\u8868\u660e CFS \u529f\u80fd\u6b63\u786e\u6027\u9ad8\uff0c\u867d\u8bfb\u5199\u6027\u80fd\u4e00\u822c\uff0c\u4f46\u9002\u7528\u4e8e\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u6587\u4ef6\u7cfb\u7edf\u7f3a\u4e4f\u5728 POSIX \u6846\u67b6\u4e0b\u652f\u6301\u591a\u51ed\u8bc1\u8bbf\u95ee\u7684\u80fd\u529b\uff0c\u800c\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u5bf9\u5b89\u5168\u3001\u7075\u6d3b\u7684\u6570\u636e\u8bbf\u95ee\u673a\u5236\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u578b\u6587\u4ef6\u7cfb\u7edf\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0 CapsuleFS\uff08CFS\uff09\uff0c\u5176\u67b6\u6784\u5305\u542b\u4e09\u90e8\u5206\uff1a1\uff09DataCapsule \u670d\u52a1\u5668\uff0c\u8d1f\u8d23\u5728\u8fb9\u7f18\u5b58\u50a8\u3001\u5206\u53d1\u548c\u590d\u5236 DataCapsule\uff1b2\uff09\u8fd0\u884c\u4e8e\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEE\uff09\u7684\u4e2d\u95f4\u4ef6\uff0c\u7528\u4e8e\u7ba1\u7406\u5199\u6743\u9650\u548c\u8bf7\u6c42\uff1b3\uff09POSIX \u517c\u5bb9\u7684\u5ba2\u6237\u7aef\uff0c\u652f\u6301\u591a\u79cd\u786c\u4ef6\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a CFS \u5728\u4fdd\u6301\u9ad8\u529f\u80fd\u6b63\u786e\u6027\u7684\u540c\u65f6\uff0c\u8bfb\u5199\u6027\u80fd\u76f8\u5bf9\u8f83\u4f4e\uff0c\u4f46\u4ecd\u8db3\u4ee5\u652f\u6301\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u573a\u666f\u7684\u5e94\u7528\u3002", "conclusion": "CapsuleFS \u6210\u529f\u5b9e\u73b0\u4e86\u591a\u51ed\u8bc1 POSIX \u6587\u4ef6\u7cfb\u7edf\u7684\u539f\u578b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u63d0\u5347\u5176\u5b9e\u7528\u6027\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2512.08425", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.08425", "abs": "https://arxiv.org/abs/2512.08425", "authors": ["Sajjad Arzemanzadeh", "Karol Miller", "Tim Rosenow", "Sjoerd B. Vos", "Adam Wittek"], "title": "Mechanical behaviour of brain-skull interface (meninges) under shear loading through experiment and finite element modelling: Preliminary results", "comment": "Computational Biomechanics for Medicine (CBM) XX - accepted", "summary": "The brain-skull interface (meninges) plays a critical role in governing brain motion during head impacts, yet computational models often simplify this interface using idealized contact conditions due to limited experimental data. This study presents an improved protocol combining experimental testing and computational modelling to determine the mechanical properties of the brain-skull interface under shear loading. Brain tissue and brain-skull complex samples were extracted from sheep cadaver heads and subjected to shear loading. Magnetic resonance imaging (MRI) was used to obtain accurate 3D geometries of the samples, which were then used to create computational grids (meshes) for simulation of the experiments using finite element (FE) models to determine subject-specific properties of the brain tissue and brain-skull interface. A second-order Ogden hyperelastic model was used for the brain tissue, and a cohesive layer was employed to model the brain-skull interface. Our results indicate that a cohesive layer captures the force-displacement and damage initiation of the brain-skull interface. The calibrated cohesive properties showed consistent patterns across samples, with maximum normal tractions ranging from 2.8-3.4 kPa and maximum tangential tractions from 1.8-2.1 kPa. This framework provides a foundation for improving the biofidelity of computational head models used in injury prediction and neurosurgical planning by replacing arbitrary boundary conditions with formulations derived from experimental data on brain-skull interface (meninges) biomechanical behaviour.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u5b9e\u9a8c\u4e0e\u6709\u9650\u5143\u5efa\u6a21\uff0c\u91cf\u5316\u4e86\u8111-\u9885\u9aa8\u754c\u9762\uff08\u8111\u819c\uff09\u5728\u526a\u5207\u8f7d\u8377\u4e0b\u7684\u529b\u5b66\u7279\u6027\uff0c\u63d0\u51fa\u4f7f\u7528\u5185\u805a\u5c42\u6a21\u578b\u66f4\u771f\u5b9e\u5730\u6a21\u62df\u8be5\u754c\u9762\u884c\u4e3a\uff0c\u4ece\u800c\u63d0\u5347\u5934\u90e8\u8ba1\u7b97\u6a21\u578b\u7684\u751f\u7269\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u6a21\u578b\u5e38\u56e0\u7f3a\u4e4f\u5b9e\u9a8c\u6570\u636e\u800c\u5bf9\u8111-\u9885\u9aa8\u754c\u9762\u91c7\u7528\u7b80\u5316\u7684\u7406\u60f3\u63a5\u89e6\u6761\u4ef6\uff0c\u96be\u4ee5\u51c6\u786e\u53cd\u6620\u5176\u5728\u5934\u90e8\u51b2\u51fb\u4e2d\u7684\u529b\u5b66\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u57fa\u4e8e\u5b9e\u9a8c\u6570\u636e\u5efa\u7acb\u66f4\u771f\u5b9e\u7684\u754c\u9762\u6a21\u578b\u3002", "method": "\u4ece\u7f8a\u5c38\u5934\u4e2d\u63d0\u53d6\u8111\u7ec4\u7ec7\u548c\u8111-\u9885\u9aa8\u590d\u5408\u6837\u672c\uff0c\u8fdb\u884c\u526a\u5207\u52a0\u8f7d\u5b9e\u9a8c\uff1b\u5229\u7528MRI\u83b7\u53d6\u6837\u672c\u4e09\u7ef4\u51e0\u4f55\u7ed3\u6784\uff0c\u6784\u5efa\u6709\u9650\u5143\u6a21\u578b\uff1b\u8111\u7ec4\u7ec7\u91c7\u7528\u4e8c\u9636Ogden\u8d85\u5f39\u6027\u6a21\u578b\uff0c\u754c\u9762\u91c7\u7528\u5185\u805a\u5c42\u6a21\u578b\u8fdb\u884c\u6a21\u62df\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6821\u51c6\u754c\u9762\u53c2\u6570\u3002", "result": "\u5185\u805a\u5c42\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349\u8111-\u9885\u9aa8\u754c\u9762\u7684\u529b-\u4f4d\u79fb\u54cd\u5e94\u548c\u635f\u4f24\u8d77\u59cb\u884c\u4e3a\uff1b\u6821\u51c6\u540e\u7684\u754c\u9762\u53c2\u6570\u5728\u6837\u672c\u95f4\u5177\u6709\u4e00\u81f4\u6027\uff0c\u6cd5\u5411\u6700\u5927\u7275\u5f15\u529b\u4e3a2.8\u20133.4 kPa\uff0c\u5207\u5411\u6700\u5927\u7275\u5f15\u529b\u4e3a1.8\u20132.1 kPa\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b9e\u9a8c\u6570\u636e\u7684\u8111-\u9885\u9aa8\u754c\u9762\u5efa\u6a21\u6846\u67b6\uff0c\u53ef\u66ff\u4ee3\u4f20\u7edf\u4efb\u610f\u8fb9\u754c\u6761\u4ef6\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u5934\u90e8\u6a21\u578b\u5728\u8111\u635f\u4f24\u9884\u6d4b\u548c\u795e\u7ecf\u5916\u79d1\u89c4\u5212\u4e2d\u7684\u751f\u7269\u771f\u5b9e\u6027\u3002"}}
{"id": "2512.08679", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.08679", "abs": "https://arxiv.org/abs/2512.08679", "authors": ["Tal Blau", "Brit Youngmann", "Anna Fariha", "Yuval Moskovitch"], "title": "Causal Explanations for Disparate Trends: Where and Why?", "comment": null, "summary": "During data analysis, we are often perplexed by certain disparities observed between two groups of interest within a dataset. To better understand an observed disparity, we need explanations that can pinpoint the data regions where the disparity is most pronounced, along with its causes, i.e., factors that alleviate or exacerbate the disparity. This task is complex and tedious, particularly for large and high-dimensional datasets, demanding an automatic system for discovering explanations (data regions and causes) of an observed disparity. It is critical that explanations for disparities are not only interpretable but also actionable-enabling users to make informed, data-driven decisions. This requires explanations to go beyond surface-level correlations and instead capture causal relationships. We introduce ExDis, a framework for discovering causal Explanations for Disparities between two groups of interest. ExDis identifies data regions (subpopulations) where disparities are most pronounced (or reversed), and associates specific factors that causally contribute to the disparity within each identified data region. We formally define the ExDis framework and the associated optimization problem, analyze its complexity, and develop an efficient algorithm to solve the problem. Through extensive experiments over three real-world datasets, we demonstrate that ExDis generates meaningful causal explanations, outperforms prior methods, and scales effectively to handle large, high-dimensional datasets.", "AI": {"tldr": "ExDis \u662f\u4e00\u4e2a\u7528\u4e8e\u53d1\u73b0\u4e24\u7ec4\u95f4\u5dee\u5f02\u7684\u56e0\u679c\u89e3\u91ca\u7684\u65b0\u6846\u67b6\uff0c\u80fd\u8bc6\u522b\u5dee\u5f02\u6700\u663e\u8457\u7684\u5b50\u7fa4\u4f53\u53ca\u5176\u56e0\u679c\u56e0\u7d20\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5728\u6570\u636e\u5206\u6790\u4e2d\uff0c\u7406\u89e3\u4e24\u7ec4\u4e4b\u95f4\u7684\u5dee\u5f02\u9700\u8981\u53ef\u89e3\u91ca\u4e14\u53ef\u64cd\u4f5c\u7684\u56e0\u679c\u89e3\u91ca\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u9ad8\u7ef4\u5927\u6570\u636e\u96c6\u4e2d\u81ea\u52a8\u53d1\u73b0\u6b64\u7c7b\u89e3\u91ca\u3002", "method": "\u63d0\u51fa ExDis \u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u5b9a\u4e49\u5dee\u5f02\u56e0\u679c\u89e3\u91ca\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5206\u6790\u5176\u590d\u6742\u6027\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u6c42\u89e3\uff0c\u4ee5\u8bc6\u522b\u5dee\u5f02\u663e\u8457\u7684\u5b50\u7fa4\u4f53\u53ca\u5176\u4e2d\u7684\u56e0\u679c\u56e0\u7d20\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cExDis \u80fd\u751f\u6210\u6709\u610f\u4e49\u7684\u56e0\u679c\u89e3\u91ca\uff0c\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5df2\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u6709\u6548\u6269\u5c55\u5230\u5927\u89c4\u6a21\u9ad8\u7ef4\u6570\u636e\u3002", "conclusion": "ExDis \u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u3001\u53ef\u64cd\u4f5c\u4e14\u9ad8\u6548\u7684\u56e0\u679c\u89e3\u91ca\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u7528\u6237\u57fa\u4e8e\u6570\u636e\u505a\u51fa\u660e\u667a\u51b3\u7b56\uff0c\u9002\u7528\u4e8e\u590d\u6742\u9ad8\u7ef4\u573a\u666f\u4e0b\u7684\u5dee\u5f02\u5206\u6790\u3002"}}
{"id": "2512.07983", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07983", "abs": "https://arxiv.org/abs/2512.07983", "authors": ["Nan Jia", "Anita Raja", "Raffi Khatchadourian"], "title": "An Empirical Framework for Evaluating Semantic Preservation Using Hugging Face", "comment": "Accepted to Hawaii International Conference on System Sciences (HICSS) 2026", "summary": "As machine learning (ML) becomes an integral part of high-autonomy systems, it is critical to ensure the trustworthiness of learning-enabled software systems (LESS). Yet, the nondeterministic and run-time-defined semantics of ML complicate traditional software refactoring. We define semantic preservation in LESS as the property that optimizations of intelligent components do not alter the system's overall functional behavior. This paper introduces an empirical framework to evaluate semantic preservation in LESS by mining model evolution data from HuggingFace. We extract commit histories, $\\textit{Model Cards}$, and performance metrics from a large number of models. To establish baselines, we conducted case studies in three domains, tracing performance changes across versions. Our analysis demonstrates how $\\textit{semantic drift}$ can be detected via evaluation metrics across commits and reveals common refactoring patterns based on commit message analysis. Although API constraints limited the possibility of estimating a full-scale threshold, our pipeline offers a foundation for defining community-accepted boundaries for semantic preservation. Our contributions include: (1) a large-scale dataset of ML model evolution, curated from 1.7 million Hugging Face entries via a reproducible pipeline using the native HF hub API, (2) a practical pipeline for the evaluation of semantic preservation for a subset of 536 models and 4000+ metrics and (3) empirical case studies illustrating semantic drift in practice. Together, these contributions advance the foundations for more maintainable and trustworthy ML systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eHuggingFace\u6570\u636e\u7684\u5b9e\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5b66\u4e60\u578b\u8f6f\u4ef6\u7cfb\u7edf\uff08LESS\uff09\u4e2d\u667a\u80fd\u7ec4\u4ef6\u4f18\u5316\u662f\u5426\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u6a21\u578b\u6f14\u5316\u6570\u636e\u548c\u6848\u4f8b\u7814\u7a76\u63ed\u793a\u8bed\u4e49\u6f02\u79fb\u73b0\u8c61\u53ca\u5e38\u89c1\u91cd\u6784\u6a21\u5f0f\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5728\u9ad8\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5b66\u4e60\u578b\u8f6f\u4ef6\u7cfb\u7edf\u7684\u53ef\u4fe1\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff1b\u7136\u800c\uff0c\u673a\u5668\u5b66\u4e60\u7684\u975e\u786e\u5b9a\u6027\u548c\u8fd0\u884c\u65f6\u5b9a\u4e49\u8bed\u4e49\u4f7f\u5f97\u4f20\u7edf\u8f6f\u4ef6\u91cd\u6784\u65b9\u6cd5\u96be\u4ee5\u9002\u7528\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u4fdd\u969c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "method": "\u4eceHuggingFace\u5e73\u53f0\u91c7\u96c6170\u4e07\u6761\u6a21\u578b\u8bb0\u5f55\uff0c\u6784\u5efa\u53ef\u590d\u73b0\u7684\u6570\u636e\u7ba1\u9053\uff0c\u63d0\u53d6\u63d0\u4ea4\u5386\u53f2\u3001\u6a21\u578b\u5361\u7247\u548c\u6027\u80fd\u6307\u6807\uff1b\u9488\u5bf9536\u4e2a\u6a21\u578b\u548c4000\u591a\u4e2a\u6307\u6807\u5efa\u7acb\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\u5206\u6790\u7248\u672c\u95f4\u7684\u6027\u80fd\u53d8\u5316\u548c\u63d0\u4ea4\u4fe1\u606f\uff0c\u4ee5\u8bc6\u522b\u8bed\u4e49\u6f02\u79fb\u548c\u91cd\u6784\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u6210\u529f\u68c0\u6d4b\u5230\u8de8\u63d0\u4ea4\u7684\u8bed\u4e49\u6f02\u79fb\u73b0\u8c61\uff0c\u8bc6\u522b\u51fa\u5e38\u89c1\u7684\u91cd\u6784\u6a21\u5f0f\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21ML\u6a21\u578b\u6f14\u5316\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u5b9e\u7528\u6d41\u7a0b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5b9a\u4e49\u793e\u533a\u8ba4\u53ef\u7684\u8bed\u4e49\u4fdd\u6301\u8fb9\u754c\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u4e0e\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2512.08764", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.08764", "abs": "https://arxiv.org/abs/2512.08764", "authors": ["Nicolas Reche", "Elvys Linhares-Pontes", "Juan-Manuel Torres-Moreno"], "title": "Financial News Summarization: Can extractive methods still offer a true alternative to LLMs?", "comment": "8 pages, 5 tables", "summary": "Financial markets change rapidly due to news, economic shifts, and geopolitical events. Quick reactions are vital for investors to avoid losses or capture short-term gains. As a result, concise financial news summaries are critical for decision-making. With over 50,000 financial articles published daily, automation in summarization is necessary. This study evaluates a range of summarization methods, from simple extractive techniques to advanced large language models (LLMs), using the FinLLMs Challenge dataset. LLMs generated more coherent and informative summaries, but they are resource-intensive and prone to hallucinations, which can introduce significant errors into financial summaries. In contrast, extractive methods perform well on short, well-structured texts and offer a more efficient alternative for this type of article. The best ROUGE results come from fine-tuned LLM model like FT-Mistral-7B, although our data corpus has limited reliability, which calls for cautious interpretation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cd\u91d1\u878d\u65b0\u95fb\u6458\u8981\u65b9\u6cd5\uff0c\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u7684\u6458\u8981\u66f4\u8fde\u8d2f\u3001\u4fe1\u606f\u66f4\u4e30\u5bcc\uff0c\u4f46\u5b58\u5728\u8d44\u6e90\u6d88\u8017\u5927\u548c\u5e7b\u89c9\u95ee\u9898\uff1b\u800c\u62bd\u53d6\u5f0f\u65b9\u6cd5\u5728\u77ed\u6587\u672c\u4e0a\u8868\u73b0\u826f\u597d\u4e14\u66f4\u9ad8\u6548\uff1b\u5fae\u8c03\u540e\u7684FT-Mistral-7B\u6a21\u578b\u53d6\u5f97\u6700\u4f73ROUGE\u5206\u6570\uff0c\u4f46\u6570\u636e\u53ef\u9760\u6027\u6709\u9650\u3002", "motivation": "\u91d1\u878d\u65b0\u95fb\u6570\u91cf\u5e9e\u5927\u4e14\u5e02\u573a\u53d8\u5316\u8fc5\u901f\uff0c\u6295\u8d44\u8005\u9700\u8981\u5feb\u901f\u83b7\u53d6\u51c6\u786e\u7b80\u6d01\u7684\u6458\u8981\u4ee5\u652f\u6301\u51b3\u7b56\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u8bc4\u4f30\u5e76\u6bd4\u8f83\u4e0d\u540c\u81ea\u52a8\u5316\u6458\u8981\u65b9\u6cd5\u7684\u6548\u679c\u3002", "method": "\u4f7f\u7528FinLLMs Challenge\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u4ece\u7b80\u5355\u62bd\u53d6\u5f0f\u65b9\u6cd5\u5230\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7b49\u591a\u79cd\u6458\u8981\u6280\u672f\u7684\u6027\u80fd\u3002", "result": "LLMs\u751f\u6210\u7684\u6458\u8981\u66f4\u5177\u8fde\u8d2f\u6027\u548c\u4fe1\u606f\u91cf\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6613\u4ea7\u751f\u5e7b\u89c9\uff1b\u62bd\u53d6\u5f0f\u65b9\u6cd5\u5728\u77ed\u6587\u672c\u4e0a\u8868\u73b0\u826f\u597d\u4e14\u6548\u7387\u66f4\u9ad8\uff1b\u5fae\u8c03\u540e\u7684FT-Mistral-7B\u6a21\u578b\u83b7\u5f97\u6700\u9ad8ROUGE\u5206\u6570\u3002", "conclusion": "\u5c3d\u7ba1\u5fae\u8c03LLM\u5728\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u53ef\u9760\u6027\u6709\u9650\u53caLLM\u6f5c\u5728\u98ce\u9669\uff0c\u5728\u91d1\u878d\u6458\u8981\u4efb\u52a1\u4e2d\u4ecd\u9700\u8c28\u614e\u9009\u62e9\u65b9\u6cd5\uff0c\u62bd\u53d6\u5f0f\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u9ad8\u6548\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.00002", "categories": ["cs.SE", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.00002", "abs": "https://arxiv.org/abs/2510.00002", "authors": ["Dong Liu"], "title": "Formally and Empirically Verified Methodologies for Scalable Hierarchical Full-Stack Systems", "comment": "Significant revision: refined paper structure, updated FDR 4.2.7 machine-checked CSP models, strengthened LTL-based correctness verification, and incorporated a detailed description of the enterprise-grade experimental environment", "summary": "This paper introduces Primary Breadth-First Development (PBFD) and Primary Depth-First Development (PDFD)-formally and empirically verified methodologies for scalable, industrial-grade full-stack software engineering. Both approaches enforce structural and behavioral correctness through graph-theoretic modeling, bridging formal methods and real-world practice. PBFD and PDFD model software development as layered directed graphs with unified state machines, verified using Communicating Sequential Processes (CSP) and Linear Temporal Logic (LTL). This guarantees bounded-refinement termination, deadlock freedom, and structural completeness. To manage hierarchical data at scale, we present the Three-Level Encapsulation (TLE)-a novel bitmask-based encoding scheme. TLE operations are verified via CSP failures-divergences refinement, ensuring constant-time updates and compact storage that underpin PBFD's robust performance. PBFD demonstrates exceptional industrial viability through eight years of enterprise deployment with zero critical failures, achieving approximately 20x faster develop-ment than Salesforce OmniScript, 7-8x faster query performance, and 11.7x storage reduction compared to conventional relational models. These results are established through longitudinal observational studies, quasi-experimental runtime comparisons, and controlled schema-level experiments. Open-source Minimum Viable Product implementations validate key behavioral properties, including bounded refinement and constant-time bitmask operations, un-der reproducible conditions. All implementations, formal specifications, and non-proprietary datasets are publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u53ef\u6269\u5c55\u7684\u5de5\u4e1a\u7ea7\u5168\u6808\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\u2014\u2014\u4e3b\u5e7f\u5ea6\u4f18\u5148\u5f00\u53d1\uff08PBFD\uff09\u548c\u4e3b\u6df1\u5ea6\u4f18\u5148\u5f00\u53d1\uff08PDFD\uff09\uff0c\u7ed3\u5408\u56fe\u8bba\u5efa\u6a21\u4e0e\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u786e\u4fdd\u7ed3\u6784\u4e0e\u884c\u4e3a\u6b63\u786e\u6027\uff1b\u540c\u65f6\u5f15\u5165\u4e09\u5c42\u5c01\u88c5\uff08TLE\uff09\u4f4d\u63a9\u7801\u7f16\u7801\u65b9\u6848\uff0c\u5b9e\u73b0\u9ad8\u6548\u5b58\u50a8\u4e0e\u66f4\u65b0\u3002PBFD\u5728\u516b\u5e74\u4f01\u4e1a\u90e8\u7f72\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u76f8\u8f83\u73b0\u6709\u6280\u672f\u663e\u8457\u63d0\u5347\u5f00\u53d1\u901f\u5ea6\u3001\u67e5\u8be2\u6027\u80fd\u5e76\u5927\u5e45\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\u5728\u5de5\u4e1a\u7ea7\u5168\u6808\u5f00\u53d1\u4e2d\u96be\u4ee5\u517c\u987e\u53ef\u6269\u5c55\u6027\u3001\u6b63\u786e\u6027\u4e0e\u6027\u80fd\uff0c\u7f3a\u4e4f\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u6709\u6548\u878d\u5165\u5b9e\u8df5\u7684\u7cfb\u7edf\u6027\u6846\u67b6\u3002", "method": "\u5c06\u8f6f\u4ef6\u5f00\u53d1\u5efa\u6a21\u4e3a\u5e26\u7edf\u4e00\u72b6\u6001\u673a\u7684\u5206\u5c42\u6709\u5411\u56fe\uff0c\u5229\u7528\u901a\u4fe1\u987a\u5e8f\u8fdb\u7a0b\uff08CSP\uff09\u548c\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff08LTL\uff09\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff1b\u63d0\u51fa\u4e09\u5c42\u5c01\u88c5\uff08TLE\uff09\u4f4d\u63a9\u7801\u7f16\u7801\u65b9\u6848\uff0c\u5e76\u901a\u8fc7CSP\u5931\u6548-\u53d1\u6563\u7cbe\u5316\u9a8c\u8bc1\u5176\u64cd\u4f5c\u3002", "result": "PBFD\u5728\u516b\u5e74\u4f01\u4e1a\u5e94\u7528\u4e2d\u5b9e\u73b0\u96f6\u5173\u952e\u6545\u969c\uff0c\u5f00\u53d1\u901f\u5ea6\u6bd4Salesforce OmniScript\u5feb\u7ea620\u500d\uff0c\u67e5\u8be2\u6027\u80fd\u63d0\u53477-8\u500d\uff0c\u5b58\u50a8\u5360\u7528\u51cf\u5c1111.7\u500d\uff1b\u5f00\u6e90MVP\u9a8c\u8bc1\u4e86\u6709\u754c\u7cbe\u5316\u548c\u5e38\u6570\u65f6\u95f4\u4f4d\u63a9\u7801\u64cd\u4f5c\u7b49\u5173\u952e\u6027\u8d28\u3002", "conclusion": "PBFD\u548cPDFD\u901a\u8fc7\u56fe\u8bba\u5efa\u6a21\u4e0e\u5f62\u5f0f\u5316\u65b9\u6cd5\u7684\u878d\u5408\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u517c\u5177\u6b63\u786e\u6027\u3001\u53ef\u6269\u5c55\u6027\u4e0e\u9ad8\u6027\u80fd\u7684\u53ef\u884c\u8def\u5f84\uff0cTLE\u7f16\u7801\u8fdb\u4e00\u6b65\u652f\u6491\u4e86\u5176\u9ad8\u6548\u5b9e\u73b0\uff0c\u5b9e\u8bc1\u7ed3\u679c\u4e0e\u5f00\u6e90\u8d44\u6e90\u652f\u6301\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2512.07990", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07990", "abs": "https://arxiv.org/abs/2512.07990", "authors": ["Thanh Nguyen", "Chaima Boufaied", "Ronnie de Souza Santos"], "title": "A Gray Literature Study on Fairness Requirements in AI-enabled Software Engineering", "comment": null, "summary": "Today, with the growing obsession with applying Artificial Intelligence (AI), particularly Machine Learning (ML), to software across various contexts, much of the focus has been on the effectiveness of AI models, often measured through common metrics such as F1- score, while fairness receives relatively little attention. This paper presents a review of existing gray literature, examining fairness requirements in AI context, with a focus on how they are defined across various application domains, managed throughout the Software Development Life Cycle (SDLC), and the causes, as well as the corresponding consequences of their violation by AI models. Our gray literature investigation shows various definitions of fairness requirements in AI systems, commonly emphasizing non-discrimination and equal treatment across different demographic and social attributes. Fairness requirement management practices vary across the SDLC, particularly in model training and bias mitigation, fairness monitoring and evaluation, and data handling practices. Fairness requirement violations are frequently linked, but not limited, to data representation bias, algorithmic and model design bias, human judgment, and evaluation and transparency gaps. The corresponding consequences include harm in a broad sense, encompassing specific professional and societal impacts as key examples, stereotype reinforcement, data and privacy risks, and loss of trust and legitimacy in AI-supported decisions. These findings emphasize the need for consistent frameworks and practices to integrate fairness into AI software, paying as much attention to fairness as to effectiveness.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u7070\u8272\u6587\u732e\u4e2d\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u516c\u5e73\u6027\u9700\u6c42\u7684\u5b9a\u4e49\u3001\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u7ba1\u7406\u65b9\u5f0f\u3001\u8fdd\u53cd\u539f\u56e0\u53ca\u5176\u540e\u679c\uff0c\u5f3a\u8c03\u9700\u5c06\u516c\u5e73\u6027\u4e0e\u6709\u6548\u6027\u540c\u7b49\u91cd\u89c6\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\u5728\u5404\u7c7b\u8f6f\u4ef6\u5e94\u7528\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u7814\u7a76\u591a\u805a\u7126\u4e8e\u6a21\u578b\u6709\u6548\u6027\uff08\u5982F1\u5206\u6570\uff09\uff0c\u800c\u5bf9\u516c\u5e73\u6027\u5173\u6ce8\u4e0d\u8db3\u3002\u4e3a\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u516c\u5e73\u6027\u9700\u6c42\u7684\u76f8\u5173\u5b9e\u8df5\u4e0e\u6311\u6218\u3002", "method": "\u901a\u8fc7\u56de\u987e\u73b0\u6709\u7070\u8272\u6587\u732e\uff0c\u5206\u6790AI\u7cfb\u7edf\u4e2d\u516c\u5e73\u6027\u9700\u6c42\u7684\u5b9a\u4e49\u3001\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\uff08SDLC\uff09\u5404\u9636\u6bb5\u7684\u7ba1\u7406\u5b9e\u8df5\u3001\u8fdd\u53cd\u516c\u5e73\u6027\u8981\u6c42\u7684\u539f\u56e0\u53ca\u76f8\u5e94\u540e\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u516c\u5e73\u6027\u9700\u6c42\u901a\u5e38\u5f3a\u8c03\u5728\u4eba\u53e3\u7edf\u8ba1\u548c\u793e\u4f1a\u5c5e\u6027\u4e0a\u7684\u975e\u6b67\u89c6\u4e0e\u5e73\u7b49\u5bf9\u5f85\uff1b\u5176\u7ba1\u7406\u5b9e\u8df5\u5728SDLC\u4e2d\u5dee\u5f02\u8f83\u5927\uff0c\u5c24\u5176\u4f53\u73b0\u5728\u6a21\u578b\u8bad\u7ec3\u3001\u504f\u89c1\u7f13\u89e3\u3001\u516c\u5e73\u6027\u76d1\u63a7\u4e0e\u8bc4\u4f30\u53ca\u6570\u636e\u5904\u7406\u65b9\u9762\uff1b\u8fdd\u53cd\u539f\u56e0\u4e3b\u8981\u5305\u62ec\u6570\u636e\u4ee3\u8868\u6027\u504f\u5dee\u3001\u7b97\u6cd5\u4e0e\u6a21\u578b\u8bbe\u8ba1\u504f\u5dee\u3001\u4eba\u4e3a\u5224\u65ad\u4ee5\u53ca\u8bc4\u4f30\u4e0e\u900f\u660e\u5ea6\u7f3a\u5931\uff1b\u540e\u679c\u6db5\u76d6\u5e7f\u6cdb\u4f24\u5bb3\uff0c\u5982\u804c\u4e1a\u4e0e\u793e\u4f1a\u5f71\u54cd\u3001\u523b\u677f\u5370\u8c61\u5f3a\u5316\u3001\u6570\u636e\u9690\u79c1\u98ce\u9669\u53ca\u5bf9AI\u51b3\u7b56\u4fe1\u4efb\u7684\u4e27\u5931\u3002", "conclusion": "\u5e94\u5efa\u7acb\u4e00\u81f4\u7684\u6846\u67b6\u548c\u5b9e\u8df5\uff0c\u5c06\u516c\u5e73\u6027\u7cfb\u7edf\u6027\u5730\u878d\u5165AI\u8f6f\u4ef6\u5f00\u53d1\u5168\u8fc7\u7a0b\uff0c\u5e76\u7ed9\u4e88\u5176\u4e0e\u6709\u6548\u6027\u540c\u7b49\u7684\u5173\u6ce8\u3002"}}
{"id": "2512.08288", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08288", "abs": "https://arxiv.org/abs/2512.08288", "authors": ["Chinmaya Kumar Dehury", "Lauri Lov\u00e9n", "Praveen Kumar Donta", "Ilir Murturi", "Schahram Dustdar"], "title": "Synergizing Monetization, Orchestration, and Semantics in Computing Continuum", "comment": "Currently submitted to IEEE Computers", "summary": "Industry demands are growing for hyper-distributed applications that span from the cloud to the edge in domains such as smart manufacturing, transportation, and agriculture. Yet today's solutions struggle to meet these demands due to inherent limitations in scalability, interoperability, and trust. In this article, we introduce HERMES (Heterogeneous Computing Continuum with Resource Monetization, Orchestration, and Semantic) - a novel framework designed to transform connectivity and data utilization across the computing continuum. HERMES establishes an open, seamless, and secure environment where resources, from cloud servers to tiny edge devices, can be orchestrated intelligently, data and services can be monetized in a distributed marketplace, and knowledge is shared through semantic interoperability. By bridging these key facets, HERMES lays a foundation for a new generation of distributed applications that are more efficient, trustworthy, and autonomous.", "AI": {"tldr": "HERMES is a novel framework that enables intelligent orchestration, monetization, and semantic interoperability across cloud-to-edge resources to support next-generation hyper-distributed applications.", "motivation": "Current solutions fail to meet the growing industry demands for hyper-distributed applications due to limitations in scalability, interoperability, and trust across cloud-to-edge environments.", "method": "The paper proposes HERMES\u2014a framework integrating resource orchestration, distributed data/service monetization, and semantic interoperability to create an open, seamless, and secure computing continuum.", "result": "HERMES enables efficient, trustworthy, and autonomous distributed applications by unifying heterogeneous resources and enabling intelligent coordination and knowledge sharing.", "conclusion": "HERMES provides a foundational architecture for future hyper-distributed systems that overcome current limitations in scalability, interoperability, and trust."}}
{"id": "2512.08032", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.08032", "abs": "https://arxiv.org/abs/2512.08032", "authors": ["Arghavan Sanei", "Chaima Amiri", "Atefeh Shokrizadeh", "Jinghui Cheng"], "title": "What Pulls the Strings? Understanding the Characteristics and Role of Argumentation in Open-Source Software Usability Discussions", "comment": "22 pages, 6 figures", "summary": "The usability of open-source software (OSS) is important but frequently overlooked in favor of technical and functional complexity. Argumentation can be a pivotal device for diverse stakeholders in OSS usability discussions to express opinions and persuade others. However, the characteristics of argument discourse in those discussions remain unknown, resulting in difficulties in providing effective support for discussion participants. We address this through a comprehensive analysis of argument discourse and quality in five OSS projects. Our results indicated that usability discussions are predominantly argument-driven, although their qualities vary. Issue comments exhibit lower-quality arguments than the issue posts, suggesting a shortage of collective intelligence about usability in OSS communities. Moreover, argument discourse and quality have various impacts on the subsequent behavior of participants. Overall, this research offers insights to help OSS stakeholders build more effective arguments and eventually improve OSS usability. These insights can also inform studies about other distributed collaborative communities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u4e94\u4e2a\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u5173\u4e8e\u53ef\u7528\u6027\u7684\u8ba8\u8bba\uff0c\u53d1\u73b0\u8fd9\u4e9b\u8ba8\u8bba\u4e3b\u8981\u7531\u8bba\u8bc1\u9a71\u52a8\uff0c\u4f46\u8bba\u8bc1\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\uff0c\u4e14\u5bf9\u53c2\u4e0e\u8005\u540e\u7eed\u884c\u4e3a\u6709\u4e0d\u540c\u5f71\u54cd\uff0c\u4ece\u800c\u4e3a\u63d0\u5347\u5f00\u6e90\u8f6f\u4ef6\u53ef\u7528\u6027\u53ca\u652f\u6301\u534f\u4f5c\u793e\u533a\u63d0\u4f9b\u6d1e\u89c1\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\uff08OSS\uff09\u7684\u53ef\u7528\u6027\u5e38\u88ab\u5ffd\u89c6\uff0c\u800c\u8bba\u8bc1\u5728\u5229\u76ca\u76f8\u5173\u8005\u8ba8\u8bba\u53ef\u7528\u6027\u65f6\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u7c7b\u8bba\u8bc1\u8bdd\u8bed\u7279\u5f81\u7684\u7406\u89e3\uff0c\u96be\u4ee5\u6709\u6548\u652f\u6301\u8ba8\u8bba\u53c2\u4e0e\u8005\u3002", "method": "\u5bf9\u4e94\u4e2a\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u53ef\u7528\u6027\u8ba8\u8bba\u8fdb\u884c\u8bba\u8bc1\u8bdd\u8bed\u53ca\u5176\u8d28\u91cf\u7684\u5168\u9762\u5206\u6790\u3002", "result": "\u53ef\u7528\u6027\u8ba8\u8bba\u4e3b\u8981\u7531\u8bba\u8bc1\u9a71\u52a8\uff0c\u4f46\u8d28\u91cf\u4e0d\u4e00\uff1b\u95ee\u9898\u8bc4\u8bba\u4e2d\u7684\u8bba\u8bc1\u8d28\u91cf\u4f4e\u4e8e\u95ee\u9898\u5e16\uff0c\u8868\u660e\u793e\u533a\u5728\u53ef\u7528\u6027\u65b9\u9762\u7f3a\u4e4f\u96c6\u4f53\u667a\u6167\uff1b\u8bba\u8bc1\u8bdd\u8bed\u548c\u8d28\u91cf\u5bf9\u53c2\u4e0e\u8005\u540e\u7eed\u884c\u4e3a\u6709\u4e0d\u540c\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u4e86\u6784\u5efa\u66f4\u6709\u6548\u8bba\u8bc1\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u53ef\u7528\u6027\uff0c\u5e76\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u5206\u5e03\u5f0f\u534f\u4f5c\u793e\u533a\u7684\u7814\u7a76\u3002"}}
{"id": "2512.08321", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08321", "abs": "https://arxiv.org/abs/2512.08321", "authors": ["Yuki Uchino", "Qianxiang Ma", "Toshiyuki Imamura", "Katsuhisa Ozaki", "Patrick Lars Gutsche"], "title": "Emulation of Complex Matrix Multiplication based on the Chinese Remainder Theorem", "comment": "11 pages, 13 figures", "summary": "Modern computing architectures feature low-precision matrix multiplication units that achieve substantially higher throughput than their high-precision counterparts. Motivated by this architectural trend, the emulation of high-precision matrix multiplication using low-precision hardware has attracted significant interest in the high-performance computing community. Ozaki, Uchino, and Imamura introduced the Ozaki-II scheme as a general framework for emulating matrix multiplication. Building on this framework, Uchino, Ozaki, and Imamura developed high-performance and power-efficient techniques for emulating single- and double-precision real matrix multiplication on INT8 matrix engines. Extending this line of research, the present study proposes high-performance emulation methods for single- and double-precision complex matrix multiplication on INT8 matrix engines, based on the Ozaki-II scheme. On an NVIDIA B200 GPU, the proposed methods achieve 4.0x--5.6x and 4.4x--6.5x speedups over the native single- and double-precision complex matrix multiplication routines from cuBLAS, respectively, for sufficiently large problem sizes. When lower accuracy than that of the standard routine is acceptable, the proposed methods can operate at even higher speed. Conversely, with only a modest increase in computation time, they can also deliver higher accuracy than the standard routines. These properties suggest that the proposed approach has the potential to serve as a default algorithm across a wide range of applications.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eOzaki-II\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u5728INT8\u77e9\u9635\u8ba1\u7b97\u5355\u5143\u4e0a\u9ad8\u6548\u6a21\u62df\u5355\u7cbe\u5ea6\u548c\u53cc\u7cbe\u5ea6\u590d\u6570\u77e9\u9635\u4e58\u6cd5\u7684\u65b9\u6cd5\uff0c\u5728NVIDIA B200 GPU\u4e0a\u76f8\u6bd4cuBLAS\u539f\u751f\u5b9e\u73b0\u83b7\u5f974.0\u20136.5\u500d\u52a0\u901f\uff0c\u5e76\u5177\u5907\u7075\u6d3b\u7684\u7cbe\u5ea6-\u6027\u80fd\u6743\u8861\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u67b6\u6784\u4e2d\u4f4e\u7cbe\u5ea6\u77e9\u9635\u4e58\u6cd5\u5355\u5143\u5177\u6709\u66f4\u9ad8\u541e\u5410\u91cf\uff0c\u56e0\u6b64\u5229\u7528\u4f4e\u7cbe\u5ea6\u786c\u4ef6\u9ad8\u6548\u6a21\u62df\u9ad8\u7cbe\u5ea6\uff08\u5c24\u5176\u662f\u590d\u6570\uff09\u77e9\u9635\u4e58\u6cd5\u6210\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u7684\u91cd\u8981\u7814\u7a76\u65b9\u5411\u3002", "method": "\u57fa\u4e8eOzaki-II\u65b9\u6848\uff0c\u8bbe\u8ba1\u9002\u7528\u4e8eINT8\u77e9\u9635\u5f15\u64ce\u7684\u5355\u7cbe\u5ea6\u4e0e\u53cc\u7cbe\u5ea6\u590d\u6570\u77e9\u9635\u4e58\u6cd5\u7684\u9ad8\u6027\u80fd\u91cf\u5316\u6a21\u62df\u65b9\u6cd5\u3002", "result": "\u5728NVIDIA B200 GPU\u4e0a\uff0c\u5bf9\u8db3\u591f\u5927\u7684\u95ee\u9898\u89c4\u6a21\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4cuBLAS\u539f\u751f\u590d\u6570\u77e9\u9635\u4e58\u6cd5\u5206\u522b\u5b9e\u73b04.0\u20135.6\u500d\uff08\u5355\u7cbe\u5ea6\uff09\u548c4.4\u20136.5\u500d\uff08\u53cc\u7cbe\u5ea6\uff09\u52a0\u901f\uff1b\u540c\u65f6\u652f\u6301\u5728\u7565\u4f4e\u6216\u66f4\u9ad8\u7cbe\u5ea6\u4e0b\u8fdb\u4e00\u6b65\u4f18\u5316\u6027\u80fd\u6216\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u7cbe\u5ea6\u4e4b\u95f4\u5177\u6709\u826f\u597d\u7684\u53ef\u8c03\u6027\uff0c\u6709\u671b\u6210\u4e3a\u591a\u79cd\u5e94\u7528\u573a\u666f\u4e0b\u7684\u9ed8\u8ba4\u590d\u6570\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u3002"}}
{"id": "2512.08341", "categories": ["cs.NI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.08341", "abs": "https://arxiv.org/abs/2512.08341", "authors": ["Thai Duong Nguyen", "Ngoc-Tan Nguyen", "Thanh-Dao Nguyen", "Nguyen Van Huynh", "Dinh-Hieu Tran", "Symeon Chatzinotas"], "title": "Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks", "comment": "IEEE ICC 2026", "summary": "The deployment of Unmanned Aerial Vehicle (UAV) swarms as dynamic communication relays is critical for next-generation tactical networks. However, operating in contested environments requires solving a complex trade-off, including maximizing system throughput while ensuring collision avoidance and resilience against adversarial jamming. Existing heuristic-based approaches often struggle to find effective solutions due to the dynamic and multi-objective nature of this problem. This paper formulates this challenge as a cooperative Multi-Agent Reinforcement Learning (MARL) problem, solved using the Centralized Training with Decentralized Execution (CTDE) framework. Our approach employs a centralized critic that uses global state information to guide decentralized actors which operate using only local observations. Simulation results show that our proposed framework significantly outperforms heuristic baselines, increasing the total system throughput by approximately 50% while simultaneously achieving a near-zero collision rate. A key finding is that the agents develop an emergent anti-jamming strategy without explicit programming. They learn to intelligently position themselves to balance the trade-off between mitigating interference from jammers and maintaining effective communication links with ground users.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u7fa4\u534f\u540c\u901a\u4fe1\u4e2d\u7ee7\u65b9\u6cd5\uff0c\u5728\u5bf9\u6297\u5e72\u6270\u548c\u907f\u969c\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf\u3002", "motivation": "\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u90e8\u7f72\u65e0\u4eba\u673a\u7fa4\u4f5c\u4e3a\u52a8\u6001\u901a\u4fe1\u4e2d\u7ee7\u9700\u517c\u987e\u541e\u5410\u91cf\u3001\u907f\u969c\u4e0e\u6297\u5e72\u6270\uff0c\u800c\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e00\u591a\u76ee\u6807\u52a8\u6001\u95ee\u9898\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u5408\u4f5c\u578b\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u4efb\u52a1\uff0c\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u5206\u6563\u6267\u884c\uff08CTDE\uff09\u6846\u67b6\uff0c\u5229\u7528\u96c6\u4e2d\u5f0f\u8bc4\u8bba\u5bb6\u6307\u5bfc\u4ec5\u4f9d\u8d56\u5c40\u90e8\u89c2\u6d4b\u7684\u5206\u6563\u5f0f\u6267\u884c\u5668\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u8f83\u542f\u53d1\u5f0f\u57fa\u7ebf\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf\u7ea650%\uff0c\u540c\u65f6\u5b9e\u73b0\u8fd1\u4e4e\u96f6\u78b0\u649e\u7387\uff0c\u5e76\u81ea\u53d1\u5f62\u6210\u6297\u5e72\u6270\u7b56\u7565\u3002", "conclusion": "\u8be5MARL\u6846\u67b6\u80fd\u6709\u6548\u534f\u8c03\u65e0\u4eba\u673a\u7fa4\u5728\u590d\u6742\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u901a\u4fe1\u4e2d\u7ee7\u4efb\u52a1\uff0c\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u4e0e\u81ea\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2512.08213", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08213", "abs": "https://arxiv.org/abs/2512.08213", "authors": ["Md Nazmul Haque", "Elizabeth Lin", "Lawrence Arkoh", "Biruk Tadesse", "Bowen Xu"], "title": "Secure or Suspect? Investigating Package Hallucinations of Shell Command in Original and Quantized LLMs", "comment": null, "summary": "Large Language Models for code (LLMs4Code) are increasingly used to generate software artifacts, including library and package recommendations in languages such as Go. However, recent evidence shows that LLMs frequently hallucinate package names or generate dependencies containing known security vulnerabilities, posing significant risks to developers and downstream software supply chains. At the same time, quantization has become a widely adopted technique to reduce inference cost and enable deployment of LLMs on resource-constrained environments. Despite its popularity, little is known about how quantization affects the correctness and security of LLM-generated software dependencies while generating shell commands for package installation.\n  In this work, we conduct the first systematic empirical study of the impact of quantization on package hallucination and vulnerability risks in LLM-generated Go packages. We evaluate five Qwen model sizes under full-precision, 8-bit, and 4-bit quantization across three datasets (SO, MBPP, and paraphrase). Our results show that quantization substantially increases the package hallucination rate (PHR), with 4-bit models exhibiting the most severe degradation. We further find that even among the correctly generated packages, the vulnerability presence rate (VPR) rises as precision decreases, indicating elevated security risk in lower-precision models. Finally, our analysis of hallucinated outputs reveals that most fabricated packages resemble realistic URL-based Go module paths, such as most commonly malformed or non-existent GitHub and golang.org repositories, highlighting a systematic pattern in how LLMs hallucinate dependencies. Overall, our findings provide actionable insights into the reliability and security implications of deploying quantized LLMs for code generation and dependency recommendation.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u91cf\u5316\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210Go\u4f9d\u8d56\u9879\u65f6\u7684\u5305\u5e7b\u89c9\u548c\u5b89\u5168\u6f0f\u6d1e\u98ce\u9669\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4f4e\u7cbe\u5ea6\u91cf\u5316\uff08\u5c24\u5176\u662f4-bit\uff09\u663e\u8457\u589e\u52a0\u4e86\u5e7b\u89c9\u7387\u548c\u6f0f\u6d1e\u5b58\u5728\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u4ee3\u7801\u4f9d\u8d56\u63a8\u8350\u65f6\u5b58\u5728\u5e7b\u89c9\u548c\u5f15\u5165\u5df2\u77e5\u5b89\u5168\u6f0f\u6d1e\u7684\u98ce\u9669\uff0c\u800c\u91cf\u5316\u867d\u88ab\u5e7f\u6cdb\u7528\u4e8e\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u4f46\u5176\u5bf9\u4f9d\u8d56\u9879\u6b63\u786e\u6027\u4e0e\u5b89\u5168\u6027\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5728\u5168\u7cbe\u5ea6\u30018-bit\u548c4-bit\u4e09\u79cd\u91cf\u5316\u8bbe\u7f6e\u4e0b\uff0c\u8bc4\u4f30\u4e94\u79cd\u89c4\u6a21\u7684Qwen\u6a21\u578b\u5728\u4e09\u4e2a\u6570\u636e\u96c6\uff08SO\u3001MBPP\u548cparaphrase\uff09\u4e0a\u751f\u6210Go\u5305\u7684\u8868\u73b0\uff0c\u5206\u6790\u5305\u5e7b\u89c9\u7387\uff08PHR\uff09\u548c\u6f0f\u6d1e\u5b58\u5728\u7387\uff08VPR\uff09\u7684\u53d8\u5316\u3002", "result": "\u91cf\u5316\u663e\u8457\u63d0\u9ad8\u4e86\u5305\u5e7b\u89c9\u7387\uff0c4-bit\u6a21\u578b\u9000\u5316\u6700\u4e25\u91cd\uff1b\u5373\u4f7f\u5728\u6b63\u786e\u751f\u6210\u7684\u5305\u4e2d\uff0c\u968f\u7740\u7cbe\u5ea6\u964d\u4f4e\uff0c\u6f0f\u6d1e\u5b58\u5728\u7387\u4e5f\u4e0a\u5347\uff1b\u5e7b\u89c9\u8f93\u51fa\u591a\u4e3a\u7c7b\u4f3c\u771f\u5b9eURL\u7684\u4f2a\u9020Go\u6a21\u5757\u8def\u5f84\uff08\u5982\u65e0\u6548GitHub\u6216golang.org\u4ed3\u5e93\uff09\u3002", "conclusion": "\u90e8\u7f72\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u548c\u4f9d\u8d56\u63a8\u8350\u7684\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u9700\u8b66\u60d5\u5176\u5728\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u5c24\u5176\u5728\u4f4e\u7cbe\u5ea6\u573a\u666f\u4e0b\u3002"}}
{"id": "2512.08365", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08365", "abs": "https://arxiv.org/abs/2512.08365", "authors": ["Yi Pan", "Wenbo Qian", "Dedong Xie", "Ruiyan Hu", "Yigong Hu", "Baris Kasikci"], "title": "Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging", "comment": "12 pages, 10 fi", "summary": "The training and deployment of machine learning (ML) models have become extremely energy-intensive. While existing optimization efforts focus primarily on hardware energy efficiency, a significant but overlooked source of inefficiency is software energy waste caused by poor software design. This often includes redundant or poorly designed operations that consume more energy without improving performance. These inefficiencies arise in widely used ML frameworks and applications, yet developers often lack the visibility and tools to detect and diagnose them.\n  We propose differential energy debugging, a novel approach that leverages the observation that competing ML systems often implement similar functionality with vastly different energy consumption. Building on this insight, we design and implement Magneton, an energy profiler that compares energy consumption between similar ML systems at the operator level and automatically pinpoints code regions and configuration choices responsible for excessive energy use. Applied to 9 popular ML systems spanning LLM inference, general ML frameworks, and image generation, Magneton detects and diagnoses 16 known cases of software energy inefficiency and further discovers 8 previously unknown cases, 7 of which have been confirmed by developers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5dee\u5206\u80fd\u8017\u8c03\u8bd5\u201d\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86\u540d\u4e3aMagneton\u7684\u80fd\u8017\u5206\u6790\u5de5\u5177\uff0c\u901a\u8fc7\u5728\u7b97\u5b50\u7ea7\u522b\u6bd4\u8f83\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u95f4\u7684\u80fd\u8017\u5dee\u5f02\uff0c\u81ea\u52a8\u5b9a\u4f4d\u5bfc\u81f4\u80fd\u8017\u8fc7\u9ad8\u7684\u4ee3\u7801\u533a\u57df\u548c\u914d\u7f6e\u9009\u62e9\uff0c\u57289\u4e2a\u4e3b\u6d41ML\u7cfb\u7edf\u4e2d\u6210\u529f\u8bc6\u522b\u51fa16\u4e2a\u5df2\u77e5\u548c8\u4e2a\u672a\u77e5\u7684\u8f6f\u4ef6\u80fd\u8017\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u90e8\u7f72\u80fd\u8017\u6781\u9ad8\uff0c\u73b0\u6709\u4f18\u5316\u4e3b\u8981\u805a\u7126\u4e8e\u786c\u4ef6\u80fd\u6548\uff0c\u800c\u5ffd\u89c6\u4e86\u7531\u8f6f\u4ef6\u8bbe\u8ba1\u4e0d\u826f\uff08\u5982\u5197\u4f59\u6216\u4f4e\u6548\u64cd\u4f5c\uff09\u5f15\u8d77\u7684\u80fd\u8017\u6d6a\u8d39\u3002\u5f00\u53d1\u8005\u7f3a\u4e4f\u6709\u6548\u5de5\u5177\u6765\u68c0\u6d4b\u548c\u8bca\u65ad\u6b64\u7c7b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5dee\u5206\u80fd\u8017\u8c03\u8bd5\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0Magneton\u80fd\u8017\u5206\u6790\u5668\uff0c\u901a\u8fc7\u5728\u7b97\u5b50\u7ea7\u522b\u5bf9\u6bd4\u529f\u80fd\u76f8\u4f3c\u4f46\u80fd\u8017\u5dee\u5f02\u663e\u8457\u7684ML\u7cfb\u7edf\uff0c\u81ea\u52a8\u8bc6\u522b\u9ad8\u80fd\u8017\u7684\u4ee3\u7801\u533a\u57df\u548c\u914d\u7f6e\u3002", "result": "\u57289\u4e2a\u6d41\u884c\u7684ML\u7cfb\u7edf\uff08\u6db5\u76d6\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u3001\u901a\u7528ML\u6846\u67b6\u548c\u56fe\u50cf\u751f\u6210\uff09\u4e2d\uff0cMagneton\u6210\u529f\u68c0\u6d4b\u5e76\u8bca\u65ad\u4e8616\u4e2a\u5df2\u77e5\u7684\u8f6f\u4ef6\u80fd\u8017\u4f4e\u6548\u6848\u4f8b\uff0c\u5e76\u65b0\u53d1\u73b0\u4e868\u4e2a\u6b64\u524d\u672a\u77e5\u7684\u95ee\u9898\uff0c\u5176\u4e2d7\u4e2a\u5df2\u83b7\u5f00\u53d1\u8005\u786e\u8ba4\u3002", "conclusion": "\u8f6f\u4ef6\u5c42\u9762\u7684\u80fd\u8017\u6d6a\u8d39\u662fML\u7cfb\u7edf\u4e2d\u4e00\u4e2a\u88ab\u5ffd\u89c6\u4f46\u91cd\u8981\u7684\u95ee\u9898\uff1b\u901a\u8fc7\u5dee\u5206\u80fd\u8017\u8c03\u8bd5\u548cMagneton\u5de5\u5177\uff0c\u53ef\u6709\u6548\u8bc6\u522b\u5e76\u4fee\u590d\u6b64\u7c7b\u95ee\u9898\uff0c\u4e3a\u63d0\u5347ML\u7cfb\u7edf\u6574\u4f53\u80fd\u6548\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.08245", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08245", "abs": "https://arxiv.org/abs/2512.08245", "authors": ["Julien Cardinal", "Imen Benzarti", "Ghizlane El boussaidi", "Christophe Pere"], "title": "Migrating QAOA from Qiskit 1.x to 2.x: An experience report", "comment": null, "summary": "Migrating quantum algorithms across evolving frameworks introduces subtle behavioral changes that affect accuracy and reproducibility. This paper reports our experience converting the Quantum Approximate Optimization Algorithm (QAOA) from Qiskit Algorithms with Qiskit 1.x (v1 primitives) to a custom implementation using Qiskit 2.x (v2 primitives). Despite identical circuits, optimizers, and Hamiltonians, the new version produced drastically different results. A systematic analysis revealed the root cause: the sampling budget -- the number of circuit executions (shots) per iteration. The library's implicit use of unlimited shots yielded dense probability distributions, whereas the v2 default of 10 000 shots captured only 23% of the state space. Increasing shots to 250 000 restored library-level accuracy. This study highlights how hidden parameters at the quantum--classical interaction level can dominate hybrid algorithm performance and provides actionable recommendations for developers and framework designers to ensure reproducible results in quantum software migration.", "AI": {"tldr": "\u5728\u5c06QAOA\u4eceQiskit 1.x\u8fc1\u79fb\u52302.x\u65f6\uff0c\u5c3d\u7ba1\u7535\u8def\u3001\u4f18\u5316\u5668\u548c\u54c8\u5bc6\u987f\u91cf\u76f8\u540c\uff0c\u7ed3\u679c\u5374\u663e\u8457\u4e0d\u540c\uff1b\u6839\u672c\u539f\u56e0\u5728\u4e8e\u91c7\u6837\u9884\u7b97\uff08shots\uff09\u7684\u9ed8\u8ba4\u503c\u53d8\u5316\uff0c\u589e\u52a0shots\u81f3250,000\u53ef\u6062\u590d\u51c6\u786e\u6027\u3002", "motivation": "\u91cf\u5b50\u7b97\u6cd5\u5728\u4e0d\u540c\u6846\u67b6\u7248\u672c\u95f4\u8fc1\u79fb\u65f6\u53ef\u80fd\u51fa\u73b0\u884c\u4e3a\u5dee\u5f02\uff0c\u5f71\u54cd\u7ed3\u679c\u7684\u51c6\u786e\u6027\u548c\u53ef\u590d\u73b0\u6027\uff0c\u4e9f\u9700\u8bc6\u522b\u5e76\u89e3\u51b3\u6b64\u7c7b\u9690\u85cf\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u5206\u6790QAOA\u5728Qiskit 1.x\u4e0e2.x\u4e4b\u95f4\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u7ed3\u679c\u5dee\u5f02\uff0c\u91cd\u70b9\u6392\u67e5\u91c7\u6837\u6b21\u6570\uff08shots\uff09\u7b49\u9690\u5f0f\u53c2\u6570\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u8c03\u6574shots\u6570\u91cf\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0Qiskit 2.x\u9ed8\u8ba4\u768410,000\u6b21\u91c7\u6837\u4ec5\u8986\u76d623%\u7684\u72b6\u6001\u7a7a\u95f4\uff0c\u800c\u5c06\u91c7\u6837\u6570\u63d0\u5347\u81f3250,000\u540e\u53ef\u6062\u590d\u4e0e\u65e7\u7248\u5e93\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u91cf\u5b50-\u7ecf\u5178\u4ea4\u4e92\u5c42\u4e2d\u7684\u9690\u85cf\u53c2\u6570\uff08\u5982\u91c7\u6837\u9884\u7b97\uff09\u5bf9\u6df7\u5408\u91cf\u5b50\u7b97\u6cd5\u6027\u80fd\u5177\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u5f00\u53d1\u8005\u548c\u6846\u67b6\u8bbe\u8ba1\u8005\u5e94\u663e\u5f0f\u63a7\u5236\u6b64\u7c7b\u53c2\u6570\u4ee5\u786e\u4fdd\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u7684\u7ed3\u679c\u53ef\u590d\u73b0\u3002"}}
{"id": "2512.08563", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08563", "abs": "https://arxiv.org/abs/2512.08563", "authors": ["Taras Skazhenik", "Nikolai Korobenikov", "Andrei Churbanov", "Anton Malakhov", "Vitaly Aksenov"], "title": "Basic Lock Algorithms in Lightweight Thread Environments", "comment": null, "summary": "Traditionally, multithreaded data structures have been designed for access by the threads of Operating Systems (OS). However, implementations for access by programmable alternatives known as lightweight threads (also referred to as asynchronous calls or coroutines) have not been thoroughly studied. The main advantage of lightweight threads is their significantly lower overhead during launch and context switching. However, this comes at a cost: to achieve proper parallelism, context switches must be manually invoked in the code; without these switches, new lightweight threads will never be executed.\n  In this paper, we focus on the simplest multithreaded data structure: a mutex (also known as a lock). We demonstrate that original implementations for OS threads cannot be used effectively in this new context due to the potential for deadlocks. Furthermore, correctness is not the only concern. In certain languages, such as C++, there are various lightweight thread libraries, each with different implementations and interfaces, which necessitate distinct lock implementations.\n  In this work, we present a modification of TTAS and MCS locks for the use from lightweight threads and demonstrate that the two context switch mechanisms of lightweight threads, yielding and sleeping, are crucial. However, the performance of TTAS and MCS may differ significantly depending on the settings. If one wants to have a lock that works well for any library, we suggest using the cohort lock, which strikes a balance between MCS and TTAS by utilizing several MCS queues with a common TTAS.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9002\u7528\u4e8e\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\uff08\u5982\u534f\u7a0b\uff09\u7684\u4e92\u65a5\u9501\u8bbe\u8ba1\uff0c\u6307\u51fa\u4f20\u7edf\u9762\u5411\u64cd\u4f5c\u7cfb\u7edf\u7ebf\u7a0b\u7684\u9501\u5728\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u73af\u5883\u4e0b\u53ef\u80fd\u5f15\u53d1\u6b7b\u9501\uff0c\u5e76\u63d0\u51fa\u9488\u5bf9TTAS\u548cMCS\u9501\u7684\u4fee\u6539\u65b9\u6848\uff1b\u540c\u65f6\u5efa\u8bae\u5728\u8de8\u5e93\u517c\u5bb9\u6027\u8981\u6c42\u9ad8\u65f6\u4f7f\u7528\u7ed3\u5408\u4e24\u8005\u4f18\u70b9\u7684Cohort\u9501\u3002", "motivation": "\u4f20\u7edf\u591a\u7ebf\u7a0b\u6570\u636e\u7ed3\u6784\u4e3b\u8981\u9762\u5411\u64cd\u4f5c\u7cfb\u7edf\u7ebf\u7a0b\u8bbe\u8ba1\uff0c\u800c\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\uff08\u5982\u534f\u7a0b\uff09\u867d\u5177\u6709\u66f4\u4f4e\u7684\u542f\u52a8\u4e0e\u4e0a\u4e0b\u6587\u5207\u6362\u5f00\u9500\uff0c\u4f46\u9700\u624b\u52a8\u63d2\u5165\u4e0a\u4e0b\u6587\u5207\u6362\u70b9\u4ee5\u5b9e\u73b0\u5e76\u884c\u3002\u73b0\u6709\u9762\u5411OS\u7ebf\u7a0b\u7684\u4e92\u65a5\u9501\u5728\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u73af\u5883\u4e2d\u53ef\u80fd\u4ea7\u751f\u6b7b\u9501\uff0c\u4e14\u4e0d\u540c\u8bed\u8a00/\u5e93\u5bf9\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u7684\u5b9e\u73b0\u5dee\u5f02\u5bfc\u81f4\u9501\u5b9e\u73b0\u96be\u4ee5\u901a\u7528\u3002", "method": "\u4f5c\u8005\u5bf9\u7ecf\u5178\u7684TTAS\u548cMCS\u4e92\u65a5\u9501\u8fdb\u884c\u4fee\u6539\uff0c\u4f7f\u5176\u9002\u914d\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u7684\u4e24\u79cd\u4e0a\u4e0b\u6587\u5207\u6362\u673a\u5236\uff08yielding\u548csleeping\uff09\uff0c\u5e76\u5206\u6790\u5176\u5728\u4e0d\u540c\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u5e93\u4e0b\u7684\u884c\u4e3a\u4e0e\u6027\u80fd\u8868\u73b0\uff1b\u540c\u65f6\u5f15\u5165Cohort\u9501\u4f5c\u4e3a\u517c\u987e\u517c\u5bb9\u6027\u4e0e\u6027\u80fd\u7684\u6298\u4e2d\u65b9\u6848\u3002", "result": "\u4fee\u6539\u540e\u7684TTAS\u548cMCS\u9501\u53ef\u5728\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u73af\u5883\u4e0b\u907f\u514d\u6b7b\u9501\u5e76\u6b63\u786e\u8fd0\u884c\uff0c\u4f46\u5176\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u5177\u4f53\u8fd0\u884c\u73af\u5883\u548c\u7ebf\u7a0b\u5e93\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0cCohort\u9501\u901a\u8fc7\u7ed3\u5408\u591a\u4e2aMCS\u961f\u5217\u4e0e\u5171\u4eabTTAS\uff0c\u5728\u4e0d\u540c\u5e93\u4e2d\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "conclusion": "\u9762\u5411\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u7684\u4e92\u65a5\u9501\u8bbe\u8ba1\u9700\u8003\u8651\u5176\u72ec\u7279\u7684\u534f\u4f5c\u5f0f\u8c03\u5ea6\u7279\u6027\uff1b\u4e3a\u5b9e\u73b0\u8de8\u5e93\u901a\u7528\u6027\uff0c\u63a8\u8350\u91c7\u7528Cohort\u9501\u7ed3\u6784\uff0c\u5b83\u5728\u6027\u80fd\u4e0e\u517c\u5bb9\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2512.08416", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08416", "abs": "https://arxiv.org/abs/2512.08416", "authors": ["Fanambinantsoa Philibert Andriniriniaimalaza", "Nour Murad", "Randriamaitso Telesphore", "Bilal Habachi", "Randriatefison Nirilalaina", "Manasina Ruffin", "Andrianirina Charles Bernard", "Ravelo Blaise"], "title": "Improvement and Stabilization of Output Voltages in a Vertical Tidal Turbine Using Intelligent Control Strategies", "comment": null, "summary": "This article investigates on the improvement and stabilization of alternating current (AC) and direct current (DC) output voltages in a Permanent Magnet Synchronous Generator (PMSG) driven by a vertical-axis tidal turbine using advanced control strategies. The research integrates artificial intelligence (AI)-based techniques to enhance voltage stability and efficiency. Initially, the Maximum Power Point Tracking (MPPT) approach based on Tip Speed Ratio (TSR) and Artificial Neural Network (ANN) Fuzzy logic controllers is explored. To further optimize the performance, Particle Swarm Optimization (PSO) and a hybrid ANN-PSO methodology are implemented. These strategies aim to refine the reference rotational speed of the turbine while minimizing deviations from optimal power extraction conditions. The simulation results of a tidal turbine operating at a water flow velocity of 1.5 m/s demonstrate that the PSO-based control approach significantly enhances the voltage stability compared to conventional MPPT-TSR and ANN-Fuzzy controllers. The hybrid ANN-PSO technique improves the voltage regulation by dynamically adapting to system variations and providing real-time reference speed adjustments. This research highlights the AI-based hybrid optimization benefit to stabilize the output voltage of tidal energy systems, thereby increasing reliability and efficiency in renewable energy applications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u63a7\u5236\u7b56\u7565\uff0c\u7528\u4e8e\u63d0\u5347\u548c\u7a33\u5b9a\u5782\u76f4\u8f74\u6f6e\u6d41\u80fd\u6c38\u78c1\u540c\u6b65\u53d1\u7535\u673a\uff08PMSG\uff09\u7cfb\u7edf\u7684\u4ea4\u76f4\u6d41\u8f93\u51fa\u7535\u538b\uff0c\u901a\u8fc7TSR\u3001ANN-Fuzzy\u3001PSO\u53ca\u6df7\u5408ANN-PSO\u65b9\u6cd5\u4f18\u5316\u6700\u5927\u529f\u7387\u70b9\u8ddf\u8e2a\uff0c\u5176\u4e2d\u6df7\u5408ANN-PSO\u65b9\u6cd5\u57281.5 m/s\u6d41\u901f\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u7535\u538b\u7a33\u5b9a\u6027\u4e0e\u8c03\u8282\u6027\u80fd\u3002", "motivation": "\u63d0\u9ad8\u7531\u5782\u76f4\u8f74\u6f6e\u6d41\u6da1\u8f6e\u9a71\u52a8\u7684PMSG\u7cfb\u7edf\u8f93\u51fa\u7535\u538b\u7684\u7a33\u5b9a\u6027\u4e0e\u6548\u7387\uff0c\u89e3\u51b3\u4f20\u7edfMPPT\u65b9\u6cd5\u5728\u52a8\u6001\u6d77\u6d0b\u73af\u5883\u4e2d\u9002\u5e94\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408TSR\u3001ANN-Fuzzy\u63a7\u5236\u5668\u3001\u7c92\u5b50\u7fa4\u4f18\u5316\uff08PSO\uff09\u4ee5\u53ca\u6df7\u5408ANN-PSO\u65b9\u6cd5\uff0c\u52a8\u6001\u4f18\u5316\u6da1\u8f6e\u53c2\u8003\u8f6c\u901f\u4ee5\u5b9e\u73b0\u66f4\u4f18\u7684\u6700\u5927\u529f\u7387\u70b9\u8ddf\u8e2a\u548c\u7535\u538b\u8c03\u8282\u3002", "result": "\u57281.5 m/s\u6c34\u6d41\u901f\u5ea6\u4e0b\u7684\u4eff\u771f\u8868\u660e\uff0cPSO\u63a7\u5236\u4f18\u4e8e\u4f20\u7edfMPPT-TSR\u548cANN-Fuzzy\u65b9\u6cd5\uff1b\u6df7\u5408ANN-PSO\u6280\u672f\u80fd\u5b9e\u65f6\u8c03\u6574\u53c2\u8003\u8f6c\u901f\uff0c\u663e\u8457\u6539\u5584\u7535\u538b\u7a33\u5b9a\u6027\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u6df7\u5408\u4f18\u5316\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u6f6e\u6d41\u80fd\u53d1\u7535\u7cfb\u7edf\u7684\u7535\u538b\u7a33\u5b9a\u6027\u4e0e\u8fd0\u884c\u6548\u7387\uff0c\u4e3a\u53ef\u518d\u751f\u80fd\u6e90\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2512.08266", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08266", "abs": "https://arxiv.org/abs/2512.08266", "authors": ["Zhensu Sun", "Chengran Yang", "Xiaoning Du", "Zhou Yang", "Li Li", "David Lo"], "title": "Token Sugar: Making Source Code Sweeter for LLMs through Token-Efficient Shorthand", "comment": "Accepted by ASE'25", "summary": "Large language models (LLMs) have shown exceptional performance in code generation and understanding tasks, yet their high computational costs hinder broader adoption. One important factor is the inherent verbosity of programming languages, such as unnecessary formatting elements and lengthy boilerplate code. This leads to inflated token counts in both input and generated outputs, which increases inference costs and slows down the generation process. Prior work improves this through simplifying programming language grammar, reducing token usage across both code understanding and generation tasks. However, it is confined to syntactic transformations, leaving significant opportunities for token reduction unrealized at the semantic level.\n  In this work, we propose Token Sugar, a concept that replaces frequent and verbose code patterns with reversible, token-efficient shorthand in the source code. To realize this concept in practice, we designed a systematic solution that mines high-frequency, token-heavy patterns from a code corpus, maps each to a unique shorthand, and integrates them into LLM pretraining via code transformation. With this solution, we obtain 799 (code pattern, shorthand) pairs, which can reduce up to 15.1% token count in the source code and is complementary to existing syntax-focused methods. We further trained three widely used LLMs on Token Sugar-augmented data. Experimental results show that these models not only achieve significant token savings (up to 11.2% reduction) during generation but also maintain near-identical Pass@1 scores compared to baselines trained on unprocessed code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faToken Sugar\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6e90\u4ee3\u7801\u4e2d\u9ad8\u9891\u4e14\u5197\u957f\u7684\u4ee3\u7801\u6a21\u5f0f\u66ff\u6362\u4e3a\u53ef\u9006\u7684\u7b80\u6d01\u7b80\u5199\u5f62\u5f0f\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e2d\u7684token\u4f7f\u7528\u91cf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f16\u7a0b\u8bed\u8a00\u7684\u5197\u957f\u6027\uff08\u5982\u683c\u5f0f\u5143\u7d20\u548c\u6837\u677f\u4ee3\u7801\uff09\u5bfc\u81f4\u8f93\u5165\u548c\u8f93\u51fatoken\u6570\u91cf\u81a8\u80c0\uff0c\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u5173\u6ce8\u8bed\u6cd5\u5c42\u9762\u7684\u7b80\u5316\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u8bed\u4e49\u5c42\u9762\u7684token\u538b\u7f29\u673a\u4f1a\u3002", "method": "\u63d0\u51faToken Sugar\u6982\u5ff5\uff1a\u4ece\u4ee3\u7801\u8bed\u6599\u5e93\u4e2d\u6316\u6398\u9ad8\u9891\u3001\u9ad8token\u6d88\u8017\u7684\u4ee3\u7801\u6a21\u5f0f\uff0c\u4e3a\u6bcf\u4e2a\u6a21\u5f0f\u5206\u914d\u552f\u4e00\u7b80\u5199\uff0c\u5e76\u901a\u8fc7\u4ee3\u7801\u8f6c\u6362\u5c06\u5176\u6574\u5408\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u3002", "result": "\u83b7\u5f97\u4e86799\u4e2a\uff08\u4ee3\u7801\u6a21\u5f0f\uff0c\u7b80\u5199\uff09\u5bf9\uff0c\u6700\u591a\u53ef\u51cf\u5c11\u6e90\u4ee3\u780115.1%\u7684token\u6570\u91cf\uff1b\u5728\u4e09\u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528Token Sugar\u589e\u5f3a\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u751f\u6210\u65f6\u6700\u591a\u51cf\u5c1111.2%\u7684token\uff0c\u540c\u65f6Pass@1\u5206\u6570\u4e0e\u57fa\u7ebf\u51e0\u4e4e\u4e00\u81f4\u3002", "conclusion": "Token Sugar\u662f\u4e00\u79cd\u6709\u6548\u4e14\u4e92\u8865\u7684token\u538b\u7f29\u65b9\u6cd5\uff0c\u80fd\u5728\u4e0d\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4ee3\u7801\u65f6\u7684token\u5f00\u9500\u3002"}}
{"id": "2512.08698", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08698", "abs": "https://arxiv.org/abs/2512.08698", "authors": ["Ilya Kokorin", "Evgeny Chernatskiy", "Vitaly Aksenov"], "title": "Model-based Testing of Practical Distributed Systems in Actor Model", "comment": "16 pages", "summary": "Designing and implementing distributed systems correctly can be quite challenging. Although these systems are often accompanied by formal specifications that are verified using model-checking techniques, a gap still exists between the implementation and its formal specification: there is no guarantee that the implementation is free of bugs.\n  To bridge this gap, we can use model-based testing. Specifically, if the model of the system can be interpreted as a finite-state automaton, we can generate an exhaustive test suite for the implementation that covers all possible states and transitions.\n  In this paper, we discuss how to efficiently generate such a test suite for distributed systems written in the actor model. Importantly, our approach does not require any modifications to the code or interfering with the distributed system execution environment. As an example, we verified an implementation of a replication algorithm based on Viewstamped Replication, which is used in a real-world system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u4fee\u6539\u4ee3\u7801\u6216\u5e72\u6270\u8fd0\u884c\u73af\u5883\u7684\u6a21\u578b\u9a71\u52a8\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e3a\u57fa\u4e8eActor\u6a21\u578b\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u81ea\u52a8\u751f\u6210\u8986\u76d6\u5168\u90e8\u72b6\u6001\u4e0e\u8f6c\u79fb\u7684\u5b8c\u5907\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5e76\u4ee5Viewstamped Replication\u590d\u5236\u7b97\u6cd5\u5b9e\u73b0\u4e3a\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u5c3d\u7ba1\u5206\u5e03\u5f0f\u7cfb\u7edf\u5e38\u914d\u6709\u7ecf\u6a21\u578b\u68c0\u6d4b\u9a8c\u8bc1\u7684\u5f62\u5f0f\u5316\u89c4\u7ea6\uff0c\u4f46\u5176\u5b9e\u73b0\u4ecd\u53ef\u80fd\u5305\u542b\u672a\u88ab\u53d1\u73b0\u7684\u7f3a\u9677\uff0c\u7f3a\u4e4f\u4e0e\u89c4\u7ea6\u7684\u4e00\u81f4\u6027\u4fdd\u8bc1\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5f25\u5408\u5f62\u5f0f\u5316\u6a21\u578b\u4e0e\u5b9e\u9645\u5b9e\u73b0\u4e4b\u95f4\u5dee\u8ddd\u7684\u6709\u6548\u9a8c\u8bc1\u624b\u6bb5\u3002", "method": "\u5c06\u7cfb\u7edf\u6a21\u578b\u89c6\u4e3a\u6709\u9650\u72b6\u6001\u81ea\u52a8\u673a\uff0c\u91c7\u7528\u6a21\u578b\u9a71\u52a8\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u4e3a\u57fa\u4e8eActor\u6a21\u578b\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u81ea\u52a8\u751f\u6210\u7a77\u5c3d\u5f0f\u6d4b\u8bd5\u5957\u4ef6\uff0c\u4e14\u65e0\u9700\u4fee\u6539\u6e90\u4ee3\u7801\u6216\u5e72\u9884\u5176\u6267\u884c\u73af\u5883\u3002", "result": "\u6210\u529f\u4e3a\u4e00\u4e2a\u57fa\u4e8eViewstamped Replication\u7684\u771f\u5b9e\u590d\u5236\u7b97\u6cd5\u5b9e\u73b0\u751f\u6210\u4e86\u8986\u76d6\u6240\u6709\u72b6\u6001\u548c\u8f6c\u79fb\u7684\u6d4b\u8bd5\u5957\u4ef6\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u4e0e\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4fb5\u5165\u7cfb\u7edf\u5b9e\u73b0\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u5f25\u5408\u5206\u5e03\u5f0f\u7cfb\u7edf\u5f62\u5f0f\u5316\u89c4\u7ea6\u4e0e\u5b9e\u9645\u4ee3\u7801\u4e4b\u95f4\u7684\u9a8c\u8bc1\u9e3f\u6c9f\uff0c\u63d0\u5347\u5b9e\u73b0\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2512.08626", "categories": ["cs.NI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08626", "abs": "https://arxiv.org/abs/2512.08626", "authors": ["Agrim Bari", "Gustavo de Veciana", "Yuqi Zhou"], "title": "Inferring Causal Relationships to Improve Caching for Clients with Correlated Requests: Applications to VR", "comment": null, "summary": "Efficient edge caching reduces latency and alleviates backhaul congestion in modern networks. Traditional caching policies, such as Least Recently Used (LRU) and Least Frequently Used (LFU), perform well under specific request patterns. LRU excels in workloads with strong temporal locality, while LFU is effective when content popularity remains static. However, real-world client requests often exhibit correlations due to shared contexts and coordinated activities. This is particularly evident in Virtual Reality (VR) environments, where groups of clients navigate shared virtual spaces, leading to correlated content requests.\n  In this paper, we introduce the \\textit{grouped client request model}, a generalization of the Independent Reference Model that explicitly captures different types of request correlations. Our theoretical analysis of LRU under this model reveals that the optimal causal caching policy depends on cache size: LFU is optimal for small to moderate caches, while LRU outperforms it for larger caches. To address the limitations of existing policies, we propose Least Following and Recently Used (LFRU), a novel online caching policy that dynamically infers and adapts to causal relationships in client requests to optimize evictions. LFRU prioritizes objects likely to be requested based on inferred dependencies, achieving near-optimal performance compared to the offline optimal Belady policy in structured correlation settings.\n  We develop VR based datasets to evaluate caching policies under realistic correlated requests. Our results show that LFRU consistently performs at least as well as LRU and LFU, outperforming LRU by up to 2.9x and LFU by up to1.9x in certain settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f13\u5b58\u7b56\u7565LFRU\uff0c\u901a\u8fc7\u6355\u6349\u5ba2\u6237\u7aef\u8bf7\u6c42\u95f4\u7684\u56e0\u679c\u5173\u8054\uff0c\u5728VR\u7b49\u5177\u6709\u5f3a\u8bf7\u6c42\u76f8\u5173\u6027\u7684\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edfLRU\u548cLFU\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u7f13\u5b58\u7b56\u7565\uff08\u5982LRU\u3001LFU\uff09\u5728\u5904\u7406\u5177\u6709\u4e0a\u4e0b\u6587\u5171\u4eab\u6216\u534f\u540c\u884c\u4e3a\u5bfc\u81f4\u7684\u8bf7\u6c42\u76f8\u5173\u6027\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u5728\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u7b49\u573a\u666f\u4e2d\uff0c\u5ba2\u6237\u7aef\u8bf7\u6c42\u9ad8\u5ea6\u76f8\u5173\uff0c\u4e9f\u9700\u80fd\u9002\u5e94\u6b64\u7c7b\u76f8\u5173\u6027\u7684\u65b0\u578b\u7f13\u5b58\u673a\u5236\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u201c\u5206\u7ec4\u5ba2\u6237\u7aef\u8bf7\u6c42\u6a21\u578b\u201d\u4ee5\u523b\u753b\u8bf7\u6c42\u76f8\u5173\u6027\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba1\u4e86\u65b0\u578b\u5728\u7ebf\u7f13\u5b58\u7b56\u7565LFRU\uff0c\u8be5\u7b56\u7565\u901a\u8fc7\u52a8\u6001\u63a8\u65ad\u8bf7\u6c42\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u6765\u4f18\u5316\u7f13\u5b58\u66ff\u6362\u51b3\u7b56\u3002", "result": "\u5728\u57fa\u4e8eVR\u6784\u5efa\u7684\u771f\u5b9e\u76f8\u5173\u8bf7\u6c42\u6570\u636e\u96c6\u4e0a\uff0cLFRU\u59cb\u7ec8\u4e0d\u52a3\u4e8eLRU\u548cLFU\uff0c\u5728\u67d0\u4e9b\u8bbe\u7f6e\u4e0b\u6027\u80fd\u6bd4LRU\u63d0\u5347\u9ad8\u8fbe2.9\u500d\uff0c\u6bd4LFU\u63d0\u5347\u8fbe1.9\u500d\u3002", "conclusion": "LFRU\u80fd\u591f\u6709\u6548\u9002\u5e94\u5177\u6709\u7ed3\u6784\u5316\u76f8\u5173\u6027\u7684\u8bf7\u6c42\u6a21\u5f0f\uff0c\u5728\u8fb9\u7f18\u7f13\u5b58\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u79bb\u7ebf\u6700\u4f18\u7b56\u7565\uff08Belady\uff09\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7ecf\u5178\u7f13\u5b58\u7b97\u6cd5\u3002"}}
{"id": "2512.08277", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08277", "abs": "https://arxiv.org/abs/2512.08277", "authors": ["Yihan Liao", "Jacky Keung", "Zhenyu Mao", "Jingyu Zhang", "Jialong Li"], "title": "FedLAD: A Modular and Adaptive Testbed for Federated Log Anomaly Detection", "comment": "Accepted Artifact at ACSOS 2025", "summary": "Log-based anomaly detection (LAD) is critical for ensuring the reliability of large-scale distributed systems. However, most existing LAD approaches assume centralized training, which is often impractical due to privacy constraints and the decentralized nature of system logs. While federated learning (FL) offers a promising alternative, there is a lack of dedicated testbeds tailored to the needs of LAD in federated settings. To address this, we present FedLAD, a unified platform for training and evaluating LAD models under FL constraints. FedLAD supports plug-and-play integration of diverse LAD models, benchmark datasets, and aggregation strategies, while offering runtime support for validation logging (self-monitoring), parameter tuning (self-configuration), and adaptive strategy control (self-adaptation). By enabling reproducible and scalable experimentation, FedLAD bridges the gap between FL frameworks and LAD requirements, providing a solid foundation for future research. Project code is publicly available at: https://github.com/AA-cityu/FedLAD.", "AI": {"tldr": "\u63d0\u51fa\u4e86FedLAD\uff0c\u4e00\u4e2a\u9762\u5411\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff08LAD\uff09\u7684\u8054\u90a6\u5b66\u4e60\u7edf\u4e00\u5e73\u53f0\uff0c\u652f\u6301\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u805a\u5408\u7b56\u7565\u7684\u5373\u63d2\u5373\u7528\uff0c\u5e76\u63d0\u4f9b\u81ea\u76d1\u63a7\u3001\u81ea\u914d\u7f6e\u4e0e\u81ea\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LAD\u65b9\u6cd5\u591a\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u8bad\u7ec3\uff0c\u5728\u9690\u79c1\u9650\u5236\u548c\u65e5\u5fd7\u5206\u6563\u7684\u5b9e\u9645\u573a\u666f\u4e2d\u96be\u4ee5\u5e94\u7528\uff1b\u540c\u65f6\u7f3a\u4e4f\u4e13\u4e3a\u8054\u90a6LAD\u8bbe\u8ba1\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u6784\u5efaFedLAD\u5e73\u53f0\uff0c\u6574\u5408\u591a\u79cdLAD\u6a21\u578b\u3001\u57fa\u51c6\u6570\u636e\u96c6\u548c\u805a\u5408\u7b56\u7565\uff0c\u652f\u6301\u8fd0\u884c\u65f6\u7684\u9a8c\u8bc1\u65e5\u5fd7\u8bb0\u5f55\u3001\u53c2\u6570\u8c03\u4f18\u548c\u81ea\u9002\u5e94\u7b56\u7565\u63a7\u5236\u3002", "result": "FedLAD\u5b9e\u73b0\u4e86\u53ef\u590d\u73b0\u3001\u53ef\u6269\u5c55\u7684\u8054\u90a6LAD\u5b9e\u9a8c\u73af\u5883\uff0c\u5f25\u5408\u4e86\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e0eLAD\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "FedLAD\u4e3a\u8054\u90a6\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2512.08725", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08725", "abs": "https://arxiv.org/abs/2512.08725", "authors": ["Giulio Attenni", "Youssef Moawad", "Novella Bartolini", "Lauritz Thamsen"], "title": "Spatio-Temporal Shifting to Reduce Carbon, Water, and Land-Use Footprints of Cloud Workloads", "comment": "This is a pre-print of our paper currently under review", "summary": "In this paper, we investigate the potential of spatial and temporal cloud workload shifting to reduce carbon, water, and land-use footprints. Specifically, we perform a simulation study using real-world data from multiple cloud providers (AWS and Azure) and workload traces for different applications (big data analytics and FaaS). Our simulation results indicate that spatial shifting can substantially lower carbon, water, and land use footprints, with observed reductions ranging from 20% to 85%, depending on the scenario and optimization criteria. Temporal shifting also decreases the footprint, though to a lesser extent. When applied together, the two strategies yield the greatest overall reduction, driven mainly by spatial shifting with temporal adjustments providing an additional, incremental benefit. Sensitivity analysis demonstrates that such shifting is robust to prediction errors in grid mix data and to variations across different seasons.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u53d1\u73b0\uff0c\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0a\u7684\u4e91\u5de5\u4f5c\u8d1f\u8f7d\u8fc1\u79fb\u53ef\u663e\u8457\u964d\u4f4e\u78b3\u3001\u6c34\u548c\u571f\u5730\u4f7f\u7528\u8db3\u8ff9\uff0c\u5176\u4e2d\u7a7a\u95f4\u8fc1\u79fb\u6548\u679c\u5c24\u4e3a\u7a81\u51fa\uff0c\u4e8c\u8005\u7ed3\u5408\u53ef\u5b9e\u73b0\u6700\u5927\u51cf\u6392\u6548\u76ca\u3002", "motivation": "\u4e3a\u51cf\u5c11\u4e91\u8ba1\u7b97\u5bf9\u73af\u5883\u7684\u5f71\u54cd\uff08\u5305\u62ec\u78b3\u6392\u653e\u3001\u6c34\u8d44\u6e90\u6d88\u8017\u548c\u571f\u5730\u5360\u7528\uff09\uff0c\u63a2\u7d22\u5229\u7528\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u5de5\u4f5c\u8d1f\u8f7d\u8fc1\u79fb\u7b56\u7565\u6765\u4f18\u5316\u8d44\u6e90\u8c03\u5ea6\u3002", "method": "\u57fa\u4e8e\u6765\u81eaAWS\u548cAzure\u7684\u771f\u5b9e\u6570\u636e\u4ee5\u53ca\u4e0d\u540c\u7c7b\u578b\u5e94\u7528\uff08\u5927\u6570\u636e\u5206\u6790\u548cFaaS\uff09\u7684\u5de5\u4f5c\u8d1f\u8f7d\u8f68\u8ff9\uff0c\u5f00\u5c55\u6a21\u62df\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u7a7a\u95f4\u4e0e\u65f6\u95f4\u8fc1\u79fb\u7b56\u7565\u5728\u4e0d\u540c\u573a\u666f\u548c\u4f18\u5316\u76ee\u6807\u4e0b\u7684\u73af\u5883\u6548\u76ca\uff0c\u5e76\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u7a7a\u95f4\u8fc1\u79fb\u53ef\u5c06\u78b3\u3001\u6c34\u548c\u571f\u5730\u4f7f\u7528\u8db3\u8ff9\u964d\u4f4e20%\u81f385%\uff1b\u65f6\u95f4\u8fc1\u79fb\u4e5f\u6709\u4e00\u5b9a\u6548\u679c\u4f46\u8f83\u5f31\uff1b\u4e24\u8005\u7ed3\u5408\u6548\u679c\u6700\u4f73\u3002\u7b56\u7565\u5bf9\u7535\u7f51\u7ed3\u6784\u9884\u6d4b\u8bef\u5dee\u548c\u5b63\u8282\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u7a7a\u95f4\u4e0e\u65f6\u95f4\u5de5\u4f5c\u8d1f\u8f7d\u8fc1\u79fb\u662f\u6709\u6548\u4e14\u7a33\u5065\u7684\u7eff\u8272\u4e91\u8ba1\u7b97\u7b56\u7565\uff0c\u5c24\u5176\u4ee5\u7a7a\u95f4\u8fc1\u79fb\u4e3a\u4e3b\u5bfc\uff0c\u53ef\u663e\u8457\u51cf\u5c11\u4e91\u670d\u52a1\u7684\u73af\u5883\u8db3\u8ff9\u3002"}}
{"id": "2512.08461", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08461", "abs": "https://arxiv.org/abs/2512.08461", "authors": ["Nicolas Matton", "Anthony Simonofski", "Marie-Ange Remiche", "Beno\u00eet Vanderose"], "title": "Measuring Agile Agreement: Development and Validation of the Manifesto and Principle Scales", "comment": "12 pages, 1 figure, 2 appendix, preprint", "summary": "While the importance of human factors in agile software development is widely acknowledged, the measurement of an individual's \"agile agreement\" remains an ill-defined and challenging area. A key limitation in existing research is the failure to distinguish between agreement with the abstract, high-level values of the Agile Manifesto and agreement with the concrete, day-to-day practices derived from the 12 Principles. This paper addresses this methodological gap by presenting the design and validation of two distinct instruments: the novel Manifesto Agreement Scale (MAS), and the Principle Agreement Scale (PAS), which is a systematic adaptation and refinement of a prior instrument.\n  We detail the systematic process of item creation and selection, survey design, and validation. The results demonstrate that both scales possess important internal consistency and construct validity. A convergence and divergence analysis, including Proportional Odds Logistic Regression, a Bland-Altman plot, and an Intraclass Correlation Coefficient (ICC), reveals that while the two scales are moderately correlated, they are not interchangeable and capture distinct dimensions of agile agreement. The primary contribution of this work is a pair of publicly available instruments, validated within a specific demographic of Belgian IT professionals. These scales represent a critical initial step toward facilitating a more nuanced measurement of agile agreement, distinguishing agile agreement across various levels of perception and aiding in a more refined interpretation of person-agile fit.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u4e24\u4e2a\u7528\u4e8e\u6d4b\u91cf\u4e2a\u4f53\u5bf9\u654f\u6377\u5ba3\u8a00\u4ef7\u503c\u89c2\uff08MAS\uff09\u548c12\u9879\u539f\u5219\u5b9e\u8df5\uff08PAS\uff09\u8ba4\u540c\u5ea6\u7684\u91cf\u8868\uff0c\u8bc1\u660e\u4e8c\u8005\u867d\u4e2d\u5ea6\u76f8\u5173\u4f46\u4e0d\u53ef\u4e92\u6362\uff0c\u4e3a\u66f4\u7ec6\u81f4\u5730\u8bc4\u4f30\u201c\u4eba-\u654f\u6377\u201d\u5339\u914d\u63d0\u4f9b\u4e86\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u80fd\u533a\u5206\u4e2a\u4f53\u5bf9\u654f\u6377\u5ba3\u8a00\u62bd\u8c61\u4ef7\u503c\u89c2\u4e0e\u5177\u4f53\u65e5\u5e38\u5b9e\u8df5\u7684\u8ba4\u540c\uff0c\u5bfc\u81f4\u201c\u654f\u6377\u8ba4\u540c\u201d\u96be\u4ee5\u51c6\u786e\u6d4b\u91cf\u3002\u4f5c\u8005\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u65b9\u6cd5\u8bba\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6761\u76ee\u521b\u5efa\u4e0e\u7b5b\u9009\u3001\u95ee\u5377\u8bbe\u8ba1\u53ca\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u6784\u5efa\u4e86Manifesto Agreement Scale (MAS) \u548c Principle Agreement Scale (PAS) \u4e24\u4e2a\u91cf\u8868\uff0c\u5e76\u91c7\u7528\u5185\u90e8\u4e00\u81f4\u6027\u68c0\u9a8c\u3001\u5efa\u6784\u6548\u5ea6\u5206\u6790\u4ee5\u53ca\u5305\u62ec\u6bd4\u4f8b\u4f18\u52bf\u903b\u8f91\u56de\u5f52\u3001Bland-Altman\u56fe\u548c\u7ec4\u5185\u76f8\u5173\u7cfb\u6570\uff08ICC\uff09\u5728\u5185\u7684\u6536\u655b\u4e0e\u533a\u5206\u6548\u5ea6\u5206\u6790\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u4e24\u4e2a\u91cf\u8868\u5747\u5c55\u73b0\u51fa\u826f\u597d\u7684\u5185\u90e8\u4e00\u81f4\u6027\u548c\u5efa\u6784\u6548\u5ea6\uff1b\u6536\u655b\u4e0e\u533a\u5206\u5206\u6790\u8868\u660e\u5b83\u4eec\u4e2d\u5ea6\u76f8\u5173\u4f46\u6d4b\u91cf\u7684\u662f\u654f\u6377\u8ba4\u540c\u7684\u4e0d\u540c\u7ef4\u5ea6\uff0c\u4e0d\u53ef\u4e92\u6362\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e24\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u3001\u5728\u6bd4\u5229\u65f6IT\u4ece\u4e1a\u8005\u7fa4\u4f53\u4e2d\u9a8c\u8bc1\u8fc7\u7684\u91cf\u8868\uff0c\u4e3a\u672a\u6765\u66f4\u7cbe\u7ec6\u5730\u533a\u5206\u4e0d\u540c\u5c42\u9762\u7684\u654f\u6377\u8ba4\u540c\u548c\u7406\u89e3\u4e2a\u4f53\u4e0e\u654f\u6377\u65b9\u6cd5\u7684\u9002\u914d\u6027\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.08472", "categories": ["cs.SE", "cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.08472", "abs": "https://arxiv.org/abs/2512.08472", "authors": ["Kai Marquardt", "Robert Hanak", "Anne Koziolek", "Lucia Happe"], "title": "Measuring Computer Science Enthusiasm: A Questionnaire-Based Analysis of Age and Gender Effects on Students' Interest", "comment": "20 pages, 10 figures, Springer Nature Scientific Reports in review", "summary": "This study offers new insights into students' interest in computer science (CS) education by disentangling the distinct effects of age and gender across a diverse adolescent sample. Grounded in the person-object theory of interest (POI), we conceptualize enthusiasm as a short-term, activating expression of interest that combines positive affect, perceived relevance, and intention to re-engage. Experiencing such enthusiasm can temporarily shift CS attitudes and strengthen future engagement intentions, making it a valuable lens for evaluating brief outreach activities. To capture these dynamics, we developed a theoretically grounded questionnaire for pre-post assessment of the enthusiasm potential of CS interventions. Using data from more than 400 students participating in online CS courses, we examined age- and gender-related patterns in enthusiasm. The findings challenge the prevailing belief that early exposure is the primary pathway to sustained interest in CS. Instead, we identify a marked decline in enthusiasm during early adolescence, particularly among girls, alongside substantial variability in interest trajectories across age groups. Crucially, our analyses reveal that age is a more decisive factor than gender in shaping interest development and uncover key developmental breakpoints. Despite starting with lower baseline attitudes, older students showed the largest positive changes following the intervention, suggesting that well-designed short activities can effectively re-activate interest even at later ages. Overall, the study highlights the need for a dynamic, age-sensitive framework for CS education in which instructional strategies are aligned with developmental trajectories.", "AI": {"tldr": "\u672c\u7814\u7a76\u57fa\u4e8e\u5174\u8da3\u7684\u4eba-\u7269\u7406\u8bba\uff0c\u901a\u8fc7\u5f00\u53d1\u95ee\u5377\u8bc4\u4f30\u8ba1\u7b97\u673a\u79d1\u5b66\uff08CS\uff09\u5e72\u9884\u6d3b\u52a8\u6fc0\u53d1\u70ed\u60c5\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u5e74\u9f84\u6bd4\u6027\u522b\u5bf9\u9752\u5c11\u5e74CS\u5174\u8da3\u53d1\u5c55\u5f71\u54cd\u66f4\u5927\uff0c\u65e9\u671f\u5e72\u9884\u5e76\u975e\u552f\u4e00\u6709\u6548\u8def\u5f84\uff0c\u9488\u5bf9\u4e0d\u540c\u5e74\u9f84\u6bb5\u8bbe\u8ba1\u52a8\u6001\u6559\u5b66\u7b56\u7565\u66f4\u4e3a\u5173\u952e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5f3a\u8c03\u65e9\u671f\u63a5\u89e6\u5bf9\u57f9\u517bCS\u5174\u8da3\u7684\u91cd\u8981\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u5e74\u9f84\u4e0e\u6027\u522b\u5728\u5174\u8da3\u53d1\u5c55\u4e2d\u7684\u72ec\u7acb\u4f5c\u7528\u3002\u4f5c\u8005\u65e8\u5728\u5398\u6e05\u4e8c\u8005\u5bf9\u9752\u5c11\u5e74CS\u5174\u8da3\uff08\u7279\u522b\u662f\u77ed\u671f\u70ed\u60c5\uff09\u7684\u5f71\u54cd\uff0c\u4ee5\u4f18\u5316CS\u6559\u80b2\u5e72\u9884\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u4eba-\u7269\u5174\u8da3\u7406\u8bba\u6784\u5efa\u201c\u70ed\u60c5\u201d\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1\u524d\u540e\u6d4b\u95ee\u5377\uff1b\u6536\u96c6400\u4f59\u540d\u53c2\u4e0e\u5728\u7ebfCS\u8bfe\u7a0b\u7684\u9752\u5c11\u5e74\u6570\u636e\uff0c\u5206\u6790\u5e74\u9f84\u4e0e\u6027\u522b\u5bf9\u70ed\u60c5\u53d8\u5316\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u65e9\u671f\u9752\u6625\u671f\uff08\u5c24\u5176\u5973\u751f\uff09\u70ed\u60c5\u663e\u8457\u4e0b\u964d\uff1b2\uff09\u5e74\u9f84\u6bd4\u6027\u522b\u66f4\u80fd\u9884\u6d4b\u5174\u8da3\u53d8\u5316\uff1b3\uff09\u5b58\u5728\u5173\u952e\u7684\u53d1\u5c55\u8f6c\u6298\u70b9\uff1b4\uff09\u5e74\u957f\u5b66\u751f\u867d\u521d\u59cb\u6001\u5ea6\u8f83\u4f4e\uff0c\u4f46\u5e72\u9884\u540e\u70ed\u60c5\u63d0\u5347\u6700\u660e\u663e\u3002", "conclusion": "CS\u6559\u80b2\u5e94\u91c7\u7528\u52a8\u6001\u3001\u5e74\u9f84\u654f\u611f\u7684\u6846\u67b6\uff0c\u4f9d\u636e\u53d1\u5c55\u9636\u6bb5\u8c03\u6574\u6559\u5b66\u7b56\u7565\uff0c\u800c\u975e\u4ec5\u805a\u7126\u65e9\u671f\u5e72\u9884\uff1b\u77ed\u671f\u9ad8\u8d28\u91cf\u6d3b\u52a8\u53ef\u5728\u8f83\u665a\u9636\u6bb5\u6709\u6548\u91cd\u71c3\u5b66\u751f\u5174\u8da3\u3002"}}
{"id": "2512.08551", "categories": ["cs.SE", "cs.CY", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.08551", "abs": "https://arxiv.org/abs/2512.08551", "authors": ["Kai Marquardt", "Mona Schulz", "Anne Koziolek", "Lucia Happe"], "title": "Gamification with Purpose: What Learners Prefer to Motivate Their Learning", "comment": "31 pages, 10 figures, Springer EAIT in review", "summary": "This study investigates learners' preferences for game design elements (GDEs) in educational contexts to inform the development of purpose-driven gamification strategies. It emphasizes a learner-centered approach that aligns gamification design with pedagogical goals, while mitigating risks such as the erosion of intrinsic motivation. A systematic literature review was conducted to identify ten widely discussed GDEs. Visual prototypes representing each element were developed, and a best-worst scaling (BWS) survey with 125 participants was administered to elicit preference rankings. Qualitative feedback was also collected to uncover motivational drivers. Learners consistently preferred GDEs that support learning processes directly-most notably progress bars, concept maps, immediate feedback, and achievements. Qualitative analysis revealed six recurring motivational themes, including visible progress, content relevance, and constructive feedback. The findings suggest that learners value gamification elements that are meaningfully integrated with educational content and support intrinsic motivation. Purpose-aligned gamification should prioritize tools that visualize learning progress and provide actionable feedback, rather than relying solely on extrinsic incentives.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u548c\u6700\u4f73-\u6700\u5dee\u91cf\u8868\u8c03\u67e5\uff0c\u8bc6\u522b\u5b66\u4e60\u8005\u5728\u6559\u80b2\u73af\u5883\u4e2d\u5bf9\u6e38\u620f\u5316\u8bbe\u8ba1\u5143\u7d20\u7684\u504f\u597d\uff0c\u53d1\u73b0\u5b66\u4e60\u8005\u66f4\u9752\u7750\u80fd\u76f4\u63a5\u652f\u6301\u5b66\u4e60\u8fc7\u7a0b\uff08\u5982\u8fdb\u5ea6\u6761\u3001\u6982\u5ff5\u56fe\u3001\u5373\u65f6\u53cd\u9988\u548c\u6210\u5c31\uff09\u4e14\u4e0e\u6559\u5b66\u5185\u5bb9\u6df1\u5ea6\u878d\u5408\u7684\u5143\u7d20\u3002", "motivation": "\u4e3a\u5236\u5b9a\u4ee5\u76ee\u6807\u4e3a\u5bfc\u5411\u7684\u6e38\u620f\u5316\u7b56\u7565\uff0c\u9700\u4e86\u89e3\u5b66\u4e60\u8005\u5bf9\u6e38\u620f\u8bbe\u8ba1\u5143\u7d20\u7684\u771f\u5b9e\u504f\u597d\uff0c\u907f\u514d\u56e0\u4e0d\u5f53\u4f7f\u7528\u5916\u5728\u6fc0\u52b1\u800c\u524a\u5f31\u5185\u5728\u52a8\u673a\uff0c\u4ece\u800c\u5b9e\u73b0\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u3001\u4e0e\u6559\u5b66\u76ee\u6807\u4e00\u81f4\u7684\u6e38\u620f\u5316\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u8bc6\u522b\u51fa\u5341\u4e2a\u5e38\u7528\u6e38\u620f\u8bbe\u8ba1\u5143\u7d20\uff0c\u4e3a\u5176\u5236\u4f5c\u89c6\u89c9\u539f\u578b\uff0c\u5e76\u901a\u8fc7\u5305\u542b125\u540d\u53c2\u4e0e\u8005\u7684\u6700\u4f73-\u6700\u5dee\u91cf\u8868\uff08BWS\uff09\u8c03\u67e5\u83b7\u53d6\u504f\u597d\u6392\u5e8f\uff0c\u540c\u65f6\u6536\u96c6\u8d28\u6027\u53cd\u9988\u4ee5\u63ed\u793a\u52a8\u673a\u9a71\u52a8\u56e0\u7d20\u3002", "result": "\u5b66\u4e60\u8005\u6700\u504f\u597d\u76f4\u63a5\u652f\u6301\u5b66\u4e60\u8fc7\u7a0b\u7684\u6e38\u620f\u5143\u7d20\uff0c\u5305\u62ec\u8fdb\u5ea6\u6761\u3001\u6982\u5ff5\u56fe\u3001\u5373\u65f6\u53cd\u9988\u548c\u6210\u5c31\uff1b\u8d28\u6027\u5206\u6790\u63d0\u70bc\u51fa\u516d\u4e2a\u52a8\u673a\u4e3b\u9898\uff1a\u53ef\u89c1\u7684\u8fdb\u5c55\u3001\u5185\u5bb9\u76f8\u5173\u6027\u3001\u5efa\u8bbe\u6027\u53cd\u9988\u7b49\u3002", "conclusion": "\u6709\u6548\u7684\u6559\u80b2\u6e38\u620f\u5316\u5e94\u4f18\u5148\u9009\u62e9\u4e0e\u5b66\u4e60\u5185\u5bb9\u6df1\u5ea6\u878d\u5408\u3001\u80fd\u53ef\u89c6\u5316\u5b66\u4e60\u8fdb\u7a0b\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u53cd\u9988\u7684\u5143\u7d20\uff0c\u4ee5\u652f\u6301\u5185\u5728\u52a8\u673a\uff0c\u800c\u975e\u4f9d\u8d56\u5355\u7eaf\u7684\u5916\u5728\u5956\u52b1\u3002"}}
{"id": "2512.08657", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08657", "abs": "https://arxiv.org/abs/2512.08657", "authors": ["Renato Cordeiro Ferreira", "Aditya Dhinavahi", "Rowanne Trapmann", "Willem-Jan van den Heuvel"], "title": "Reusability in MLOps: Leveraging Ports and Adapters to Build a Microservices Architecture for the Maritime Domain", "comment": "7 pages, 3 figures (3 diagrams), submitted to ICSA 2026", "summary": "ML-Enabled Systems (MLES) are inherently complex since they require multiple components to achieve their business goal. This experience report showcases the software architecture reusability techniques applied while building Ocean Guard, an MLES for anomaly detection in the maritime domain. In particular, it highlights the challenges and lessons learned to reuse the Ports and Adapters pattern to support building multiple microservices from a single codebase. This experience report hopes to inspire software engineers, machine learning engineers, and data scientists to apply the Hexagonal Architecture pattern to build their MLES.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u540d\u4e3aOcean Guard\u7684\u6d77\u4e8b\u5f02\u5e38\u68c0\u6d4bML\u7cfb\u7edf\uff0c\u63a2\u8ba8\u4e86\u5728\u5355\u4e00\u4ee3\u7801\u5e93\u4e2d\u590d\u7528Ports and Adapters\uff08\u516d\u8fb9\u5f62\u67b6\u6784\uff09\u6a21\u5f0f\u6765\u652f\u6301\u591a\u4e2a\u5fae\u670d\u52a1\u7684\u7ecf\u9a8c\u3001\u6311\u6218\u4e0e\u542f\u793a\u3002", "motivation": "ML\u7cfb\u7edf\u7ed3\u6784\u590d\u6742\uff0c\u9700\u591a\u7ec4\u4ef6\u534f\u540c\uff1b\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u590d\u7528\u8f6f\u4ef6\u67b6\u6784\u63d0\u5347\u5f00\u53d1\u6548\u7387\u4e0e\u7cfb\u7edf\u53ef\u7ef4\u62a4\u6027\uff0c\u5e76\u63a8\u5e7f\u516d\u8fb9\u5f62\u67b6\u6784\u5728ML\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528Ports and Adapters\uff08\u5373Hexagonal Architecture\uff09\u6a21\u5f0f\uff0c\u5728\u5355\u4e00\u4ee3\u7801\u5e93\u4e2d\u6784\u5efa\u591a\u4e2a\u5fae\u670d\u52a1\uff0c\u5b9e\u73b0\u8f6f\u4ef6\u67b6\u6784\u7684\u590d\u7528\u3002", "result": "\u6210\u529f\u5728Ocean Guard\u9879\u76ee\u4e2d\u590d\u7528\u67b6\u6784\uff0c\u8bc6\u522b\u51fa\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u6311\u6218\u5e76\u603b\u7ed3\u4e86\u5b9e\u7528\u7ecf\u9a8c\u3002", "conclusion": "\u516d\u8fb9\u5f62\u67b6\u6784\u80fd\u6709\u6548\u652f\u6301ML\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u4e0e\u590d\u7528\uff0c\u503c\u5f97ML\u5de5\u7a0b\u5e08\u548c\u8f6f\u4ef6\u5f00\u53d1\u8005\u501f\u9274\u3002"}}
{"id": "2512.08706", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08706", "abs": "https://arxiv.org/abs/2512.08706", "authors": ["Leon Kogler", "Maximilian Ehrhart", "Benedikt Dornauer", "Eduard Paul Enoiu"], "title": "RESTifAI: LLM-Based Workflow for Reusable REST API Testing", "comment": "Accepted for ICSE 2026 Demonstration track", "summary": "With this paper, we introduce RESTifAI, an LLM-driven approach for generating reusable, CI/CD ready REST API tests, following the happy-path approach. Unlike existing tools that often focus primarily on internal server errors, RESTifAI systematically constructs valid test scenarios (happy paths) and derives negative cases to verify both intended functionality (2xx responses) and robustness against invalid inputs or business-rule violations (4xx responses). The results indicate that RESTifAI performs on par with the latest LLM tools, i.e., AutoRestTest and LogiAgent, while addressing limitations related to reusability, oracle complexity, and integration. To support this, we provide common comparative results and demonstrate the tool's applicability in industrial services. For tool demonstration, please refer to https://www.youtube.com/watch?v=2vtQo0T0Lo4. RESTifAI is publicly available at https://github.com/casablancahotelsoftware/RESTifAI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RESTifAI\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u751f\u6210\u53ef\u91cd\u7528\u3001CI/CD\u5c31\u7eea\u7684REST API\u201c\u6b63\u5411\u8def\u5f84\u201d\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b9\u6cd5\uff0c\u5e76\u80fd\u8fdb\u4e00\u6b65\u63a8\u5bfc\u51fa\u8d1f\u5411\u6d4b\u8bd5\u7528\u4f8b\u4ee5\u9a8c\u8bc1\u7cfb\u7edf\u5065\u58ee\u6027\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u591a\u5173\u6ce8\u5185\u90e8\u670d\u52a1\u5668\u9519\u8bef\uff0c\u7f3a\u4e4f\u5bf9\u6709\u6548\u4e1a\u52a1\u573a\u666f\uff08happy path\uff09\u7684\u7cfb\u7edf\u6027\u6d4b\u8bd5\u652f\u6301\uff0c\u4e14\u5728\u53ef\u91cd\u7528\u6027\u3001\u65ad\u8a00\u590d\u6742\u6027\u548c\u96c6\u6210\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6784\u5efa\u7b26\u5408\u4e1a\u52a1\u903b\u8f91\u7684\u6b63\u5411\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u4ece\u4e2d\u884d\u751f\u51fa\u7528\u4e8e\u9a8c\u8bc14xx\u54cd\u5e94\u7684\u8d1f\u5411\u6d4b\u8bd5\uff0c\u751f\u6210\u7684\u6d4b\u8bd5\u53ef\u76f4\u63a5\u7528\u4e8eCI/CD\u6d41\u7a0b\u3002", "result": "RESTifAI\u5728\u6027\u80fd\u4e0a\u4e0e\u5f53\u524d\u5148\u8fdb\u5de5\u5177\uff08\u5982AutoRestTest\u548cLogiAgent\uff09\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u53ef\u91cd\u7528\u6027\u3001\u65ad\u8a00\u751f\u6210\u548c\u5de5\u4e1a\u96c6\u6210\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u5df2\u5728\u5b9e\u9645\u5de5\u4e1a\u670d\u52a1\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "RESTifAI\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u7528\u4e14\u53ef\u96c6\u6210\u7684API\u6d4b\u8bd5\u751f\u6210\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86REST API\u6d4b\u8bd5\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u8d28\u91cf\u4fdd\u969c\u80fd\u529b\u3002"}}
{"id": "2512.08810", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08810", "abs": "https://arxiv.org/abs/2512.08810", "authors": ["Viola Campos", "Robin Kuschnereit", "Adrian Ulges"], "title": "Multicalibration for LLM-based Code Generation", "comment": "Accepted at AI-SQE 2026 (The 1st International Workshop on AI for Software Quality Evaluation: Judgment, Metrics, Benchmarks, and Beyond)", "summary": "As AI-based code generation becomes widespread, researchers are investigating the calibration of code LLMs - ensuring their confidence scores faithfully represent the true likelihood of code correctness. To do so, we investigate multicalibration, which can capture additional factors about a coding problem, such as complexity, code length, or programming language used. We study four multicalibration approaches on three function synthesis benchmarks, using latest-generation code LLMs (Qwen3 Coder, GPT-OSS, DeepSeek-R1-Distill). Our results demonstrate that multicalibration can yield distinct improvements over both uncalibrated token likelihoods (+1.03 in skill score) and baseline calibrations (+0.37 in skill score). We study the influence of the aforementioned factors in ablations, and make our dataset (consisting of code generations, likelihoods, and correctness labels) available for future research on code LLM calibration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u6821\u51c6\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u5176\u7f6e\u4fe1\u5ea6\u5206\u6570\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u591a\u6821\u51c6\u4f18\u4e8e\u672a\u6821\u51c6\u548c\u57fa\u7ebf\u6821\u51c6\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eAI\u7684\u4ee3\u7801\u751f\u6210\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u4ee3\u7801\u5927\u6a21\u578b\u8f93\u51fa\u7684\u7f6e\u4fe1\u5ea6\u80fd\u771f\u5b9e\u53cd\u6620\u4ee3\u7801\u6b63\u786e\u6027\u7684\u6982\u7387\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6821\u51c6\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u7f16\u7a0b\u95ee\u9898\u7684\u591a\u79cd\u56e0\u7d20\uff08\u5982\u590d\u6742\u5ea6\u3001\u4ee3\u7801\u957f\u5ea6\u3001\u7f16\u7a0b\u8bed\u8a00\u7b49\uff09\uff0c\u56e0\u6b64\u4f5c\u8005\u5f15\u5165\u591a\u6821\u51c6\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5728\u4e09\u4e2a\u51fd\u6570\u5408\u6210\u57fa\u51c6\u4e0a\uff0c\u4f7f\u7528\u6700\u65b0\u7684\u4ee3\u7801\u5927\u6a21\u578b\uff08Qwen3 Coder\u3001GPT-OSS\u3001DeepSeek-R1-Distill\uff09\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u591a\u6821\u51c6\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u4e0d\u540c\u56e0\u7d20\u5bf9\u6821\u51c6\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u591a\u6821\u51c6\u65b9\u6cd5\u5728\u6280\u80fd\u5f97\u5206\u4e0a\u76f8\u6bd4\u672a\u6821\u51c6\u7684token\u4f3c\u7136\u63d0\u5347\u4e86+1.03\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6821\u51c6\u65b9\u6cd5\u63d0\u5347\u4e86+0.37\uff1b\u540c\u65f6\u4f5c\u8005\u516c\u5f00\u4e86\u5305\u542b\u4ee3\u7801\u751f\u6210\u3001\u4f3c\u7136\u503c\u548c\u6b63\u786e\u6027\u6807\u7b7e\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u591a\u6821\u51c6\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u5927\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7684\u53ef\u9760\u6027\uff0c\u4e14\u8003\u8651\u95ee\u9898\u76f8\u5173\u56e0\u7d20\u6709\u52a9\u4e8e\u66f4\u7cbe\u7ec6\u7684\u6821\u51c6\uff0c\u4e3a\u672a\u6765\u4ee3\u7801LLM\u6821\u51c6\u7814\u7a76\u63d0\u4f9b\u4e86\u6570\u636e\u57fa\u7840\u548c\u65b9\u6cd5\u53c2\u8003\u3002"}}
{"id": "2512.08867", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08867", "abs": "https://arxiv.org/abs/2512.08867", "authors": ["Jing Zhang", "Lianghong Guo", "Yanlin Wang", "Mingwei Liu", "Jiachi Chen", "Yuchi Ma", "Ensheng Shi", "Terry Yue Zhuo", "Hongyu Zhang", "Zibin Zheng"], "title": "SimpleDevQA: Benchmarking Large Language Models on Development Knowledge QA", "comment": null, "summary": "The Development Knowledge Question Answering (Dev Knowledge QA) task aims to provide natural language answers to knowledge-seeking questions during software development. To investigate its importance and to what extent it has been explored, we analyze real user-LLM dialogues from WildChat and find that: (1) The Dev Knowledge QA task accounts for 39.6% of interactions(highest among all tasks), revealing broad knowledge needs beyond code generation (32.3%). (2) Only 27.5% of real Dev Knowledge QA dialogues focus on code understanding, leaving out development knowledge-seeking. (3) Only 17.1% of real-world Dev Knowledge QA dialogues can be used for constructing a benchmark. Existing benchmarks have two primary limitations for evaluating the Dev Knowledge QA capability of LLMs. First, existing benchmarks offer a limited development knowledge scope, mainly focusing on code understanding and neglecting broader knowledge during development. Second, some benchmarks are not built from real user queries. To bridge this gap, we design a three-phase pipeline that transforms real-world dialogue into simple development knowledge-seeking QA pairs. Through this pipeline, we introduce SimpleDevQA, a multilingual benchmark derived from real user dialogues. It contains 2,740 QA pairs in three languages (English, Chinese, and Russian), and focuses on questions with unique, short, and verifiable answers for accurate and simple evaluation. Experiments show that: Code LLMs generally outperform general LLMs of similar scale; Knowledge injection with the Retrieval-Augmented Generation (RAG) strategy can boost LLM accuracy by 11.3% on average; LLMs show systematic overconfidence in Dev Knowledge QA, and the answering accuracy of LLMs shows a positive correlation with their stated confidence; Generally, LLMs with stronger code generation performance also exhibit stronger performance in Dev Knowledge QA.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u7814\u7a76\u4e86\u5f00\u53d1\u77e5\u8bc6\u95ee\u7b54\uff08Dev Knowledge QA\uff09\u4efb\u52a1\uff0c\u53d1\u73b0\u5176\u5728\u771f\u5b9e\u7528\u6237\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ea4\u4e92\u4e2d\u5360\u6bd4\u6700\u9ad8\uff0839.6%\uff09\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6570\u636e\u96c6\u8986\u76d6\u8303\u56f4\u6709\u9650\u4e14\u7f3a\u4e4f\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u5bf9\u8bdd\u7684\u591a\u8bed\u8a00\u57fa\u51c6SimpleDevQA\uff08\u542b2740\u4e2a\u95ee\u7b54\u5bf9\uff0c\u6db5\u76d6\u82f1\u3001\u4e2d\u3001\u4fc4\u4e09\u8bed\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\u4e86\u4ee3\u7801\u4e13\u7528LLM\u4f18\u4e8e\u901a\u7528LLM\u3001RAG\u7b56\u7565\u53ef\u63d0\u5347\u51c6\u786e\u738711.3%\u3001LLM\u5b58\u5728\u7cfb\u7edf\u6027\u8fc7\u5ea6\u81ea\u4fe1\u7b49\u5173\u952e\u53d1\u73b0\u3002", "motivation": "\u73b0\u6709\u5f00\u53d1\u77e5\u8bc6\u95ee\u7b54\u57fa\u51c6\u5b58\u5728\u4e24\u5927\u5c40\u9650\uff1a\u4e00\u662f\u77e5\u8bc6\u8303\u56f4\u72ed\u7a84\uff0c\u4e3b\u8981\u805a\u7126\u4ee3\u7801\u7406\u89e3\u800c\u5ffd\u7565\u66f4\u5e7f\u6cdb\u7684\u5f00\u53d1\u77e5\u8bc6\uff1b\u4e8c\u662f\u672a\u57fa\u4e8e\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u6784\u5efa\uff0c\u96be\u4ee5\u771f\u5b9e\u8bc4\u4f30LLM\u5728\u5b9e\u9645\u5f00\u53d1\u573a\u666f\u4e2d\u7684\u77e5\u8bc6\u95ee\u7b54\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e09\u9636\u6bb5\u6d41\u7a0b\uff0c\u5c06WildChat\u4e2d\u7684\u771f\u5b9e\u7528\u6237-LLM\u5bf9\u8bdd\u8f6c\u5316\u4e3a\u7b80\u6d01\u7684\u5f00\u53d1\u77e5\u8bc6\u95ee\u7b54\u5bf9\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u591a\u8bed\u8a00\u57fa\u51c6SimpleDevQA\u3002\u8be5\u57fa\u51c6\u5305\u542b2740\u4e2a\u5177\u6709\u552f\u4e00\u3001\u7b80\u77ed\u3001\u53ef\u9a8c\u8bc1\u7b54\u6848\u7684\u95ee\u9898\uff0c\u8986\u76d6\u82f1\u8bed\u3001\u4e2d\u6587\u548c\u4fc4\u8bed\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a(1) \u4ee3\u7801\u4e13\u7528LLM\u5728Dev Knowledge QA\u4efb\u52a1\u4e0a\u666e\u904d\u4f18\u4e8e\u540c\u89c4\u6a21\u901a\u7528LLM\uff1b(2) \u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7b56\u7565\u5e73\u5747\u63d0\u5347LLM\u51c6\u786e\u738711.3%\uff1b(3) LLM\u5728\u6b64\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u4e14\u5176\u56de\u7b54\u51c6\u786e\u7387\u4e0e\u5176\u81ea\u8ff0\u7f6e\u4fe1\u5ea6\u5448\u6b63\u76f8\u5173\uff1b(4) \u4ee3\u7801\u751f\u6210\u80fd\u529b\u5f3a\u7684LLM\u901a\u5e38\u5728Dev Knowledge QA\u4efb\u52a1\u4e2d\u4e5f\u8868\u73b0\u66f4\u5f3a\u3002", "conclusion": "Dev Knowledge QA\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u9ad8\u9891\u4e14\u91cd\u8981\u7684\u9700\u6c42\uff0c\u4f46\u957f\u671f\u88ab\u5ffd\u89c6\u3002\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u771f\u5b9e\u5bf9\u8bdd\u7684SimpleDevQA\u57fa\u51c6\uff0c\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u4e0e\u5c40\u9650\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u4f18\u5316\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.08910", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08910", "abs": "https://arxiv.org/abs/2512.08910", "authors": ["Nathan Cassee", "Robert Feldt"], "title": "Exploring the Garden of Forking Paths in Empirical Software Engineering Research: A Multiverse Analysis", "comment": "Submitte to TOSEM", "summary": "In empirical software engineering (SE) research, researchers have considerable freedom to decide how to process data, what operationalizations to use, and which statistical model to fit. Gelman and Loken refer to this freedom as leading to a \"garden of forking paths\". Although this freedom is often seen as an advantage, it also poses a threat to robustness and replicability: variations in analytical decisions, even when justifiable, can lead to divergent conclusions.\n  To better understand this risk, we conducted a so-called multiverse analysis on a published empirical SE paper. The paper we picked is a Mining Software Repositories study, as MSR studies commonly use non-trivial statistical models to analyze post-hoc, observational data. In the study, we identified nine pivotal analytical decisions-each with at least one equally defensible alternative and systematically reran all the 3,072 resulting analysis pipelines on the original dataset. Interestingly, only 6 of these universes (<0.2%) reproduced the published results; the overwhelming majority produced qualitatively different, and sometimes even opposite, findings.\n  This case study of a data analytical method commonly applied to empirical software engineering data reveals how methodological choices can exert a more profound influence on outcomes than is often acknowledged. We therefore advocate that SE researchers complement standard reporting with robustness checks across plausible analysis variants or, at least, explicitly justify each analytical decision. We propose a structured classification model to help classify and improve justification for methodological choices. Secondly, we show how the multiverse analysis is a practical tool in the methodological arsenal of SE researchers, one that can help produce more reliable, reproducible science.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u591a\u5b87\u5b99\u5206\u6790\uff08multiverse analysis\uff09\u5bf9\u4e00\u7bc7\u5df2\u53d1\u8868\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8bc1\u7814\u7a76\u8fdb\u884c\u590d\u73b0\uff0c\u53d1\u73b0\u4ec5\u6709\u4e0d\u52300.2%\u7684\u5206\u6790\u8def\u5f84\u80fd\u590d\u73b0\u539f\u59cb\u7ed3\u679c\uff0c\u8868\u660e\u5206\u6790\u51b3\u7b56\u5bf9\u7ed3\u8bba\u5f71\u54cd\u5de8\u5927\uff0c\u547c\u5401\u7814\u7a76\u8005\u52a0\u5f3a\u7a33\u5065\u6027\u68c0\u9a8c\u5e76\u63d0\u4f9b\u65b9\u6cd5\u9009\u62e9\u7684\u660e\u786e\u7406\u7531\u3002", "motivation": "\u5728\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\uff0c\u7814\u7a76\u8005\u5728\u6570\u636e\u5904\u7406\u3001\u64cd\u4f5c\u5316\u5b9a\u4e49\u548c\u7edf\u8ba1\u6a21\u578b\u9009\u62e9\u4e0a\u5177\u6709\u9ad8\u5ea6\u81ea\u7531\uff0c\u8fd9\u79cd\u201c\u5206\u53c9\u8def\u5f84\u82b1\u56ed\u201d\u867d\u5177\u7075\u6d3b\u6027\uff0c\u5374\u53ef\u80fd\u635f\u5bb3\u7814\u7a76\u7684\u7a33\u5065\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002\u4f5c\u8005\u65e8\u5728\u91cf\u5316\u8fd9\u79cd\u5206\u6790\u81ea\u7531\u5e26\u6765\u7684\u98ce\u9669\u3002", "method": "\u4f5c\u8005\u9009\u53d6\u4e00\u7bc7\u5178\u578b\u7684\u8f6f\u4ef6\u4ed3\u5e93\u6316\u6398\uff08MSR\uff09\u7814\u7a76\uff0c\u8bc6\u522b\u51fa9\u4e2a\u5173\u952e\u5206\u6790\u51b3\u7b56\u70b9\uff08\u6bcf\u4e2a\u81f3\u5c11\u6709\u4e00\u4e2a\u540c\u6837\u5408\u7406\u7684\u66ff\u4ee3\u65b9\u6848\uff09\uff0c\u7cfb\u7edf\u6784\u5efa\u5e76\u8fd0\u884c\u5168\u90e83,072\u79cd\u53ef\u80fd\u7684\u5206\u6790\u6d41\u7a0b\uff08\u5373\u201c\u591a\u5b87\u5b99\u201d\uff09\uff0c\u6bd4\u8f83\u5176\u7ed3\u679c\u4e0e\u539f\u59cb\u8bba\u6587\u7684\u4e00\u81f4\u6027\u3002", "result": "\u57283,072\u79cd\u5206\u6790\u8def\u5f84\u4e2d\uff0c\u4ec5\u67096\u79cd\uff08<0.2%\uff09\u590d\u73b0\u4e86\u539f\u59cb\u8bba\u6587\u7684\u7ed3\u679c\uff1b\u7edd\u5927\u591a\u6570\u8def\u5f84\u5f97\u51fa\u4e86\u5b9a\u6027\u4e0d\u540c\u751a\u81f3\u76f8\u53cd\u7684\u7ed3\u8bba\u3002", "conclusion": "\u5206\u6790\u51b3\u7b56\u5bf9\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7ed3\u679c\u7684\u5f71\u54cd\u8fdc\u8d85\u901a\u5e38\u8ba4\u77e5\u3002\u4f5c\u8005\u5efa\u8bae\u7814\u7a76\u8005\u5e94\u901a\u8fc7\u591a\u5b87\u5b99\u5206\u6790\u7b49\u7a33\u5065\u6027\u68c0\u9a8c\u6765\u8bc4\u4f30\u7ed3\u679c\u53ef\u9760\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u7ed3\u6784\u5316\u5206\u7c7b\u6a21\u578b\u4ee5\u5e2e\u52a9\u9610\u660e\u548c\u8bba\u8bc1\u65b9\u6cd5\u9009\u62e9\uff0c\u4ece\u800c\u63d0\u5347\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u4e0e\u79d1\u5b66\u6027\u3002"}}
