{"id": "2511.14786", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14786", "abs": "https://arxiv.org/abs/2511.14786", "authors": ["Sidney Shapiro"], "title": "Hybrid Quantum-Classical Machine Learning with PennyLane: A Comprehensive Guide for Computational Research", "comment": "35 pages", "summary": "Hybrid quantum-classical machine learning represents a frontier in computational research, combining the potential advantages of quantum computing with established classical optimization techniques. PennyLane provides a Python framework that seamlessly bridges quantum circuits and classical machine learning, enabling researchers to build, optimize, and deploy variational quantum algorithms. This paper introduces PennyLane as a versatile tool for quantum machine learning, optimization, and quantum chemistry applications. We demonstrate use cases including quantum kernel methods, variational quantum eigensolvers, portfolio optimization, and integration with classical ML frameworks such as PyTorch, TensorFlow, and JAX. Through concrete Python examples with widely used libraries such as scikit-learn, pandas, and matplotlib, we show how PennyLane facilitates efficient quantum circuit construction, automatic differentiation, and hybrid optimization workflows. By situating PennyLane within the broader context of quantum computing and machine learning, we highlight its role as a methodological building block for quantum-enhanced data science. Our goal is to provide researchers and practitioners with a concise reference that bridges foundational quantum computing concepts and applied machine learning practice, making PennyLane a default citation for hybrid quantum-classical workflows in Python-based research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PennyLane\u8fd9\u4e00Python\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u673a\u5668\u5b66\u4e60\uff0c\u652f\u6301\u91cf\u5b50\u6838\u65b9\u6cd5\u3001\u53d8\u5206\u91cf\u5b50\u672c\u5f81\u6c42\u89e3\u5668\u3001\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u7b49\u5e94\u7528\uff0c\u5e76\u4e0ePyTorch\u3001TensorFlow\u3001JAX\u7b49\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6846\u67b6\u65e0\u7f1d\u96c6\u6210\u3002", "motivation": "\u63a8\u52a8\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u3001\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u4ee5\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u6f5c\u529b\u4e0e\u7ecf\u5178\u4f18\u5316\u6280\u672f\uff0c\u4fc3\u8fdb\u91cf\u5b50\u589e\u5f3a\u6570\u636e\u79d1\u5b66\u7684\u5b9e\u8df5\u5e94\u7528\u3002", "method": "\u901a\u8fc7PennyLane\u6846\u67b6\u6784\u5efa\u548c\u4f18\u5316\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\uff0c\u5229\u7528\u5176\u81ea\u52a8\u5fae\u5206\u3001\u91cf\u5b50\u7535\u8def\u6784\u5efa\u53ca\u4e0e\u7ecf\u5178ML\u5e93\uff08\u5982scikit-learn\u3001pandas\u3001matplotlib\uff09\u7684\u96c6\u6210\u529f\u80fd\uff0c\u5b9e\u73b0\u6df7\u5408\u4f18\u5316\u5de5\u4f5c\u6d41\u3002", "result": "\u5c55\u793a\u4e86PennyLane\u5728\u591a\u4e2a\u9886\u57df\u7684\u5177\u4f53\u5e94\u7528\u6848\u4f8b\uff0c\u8bc1\u660e\u5176\u5728\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u3001\u4f18\u5316\u548c\u91cf\u5b50\u5316\u5b66\u4e2d\u7684\u5b9e\u7528\u6027\u4e0e\u7075\u6d3b\u6027\u3002", "conclusion": "PennyLane\u4f5c\u4e3a\u8fde\u63a5\u91cf\u5b50\u8ba1\u7b97\u4e0e\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7684\u6865\u6881\uff0c\u662f\u5b9e\u73b0\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u5de5\u4f5c\u6d41\u7684\u91cd\u8981\u65b9\u6cd5\u8bba\u5de5\u5177\uff0c\u9002\u5408\u6210\u4e3a\u76f8\u5173Python\u7814\u7a76\u7684\u6807\u51c6\u5f15\u7528\u3002"}}
{"id": "2511.14791", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14791", "abs": "https://arxiv.org/abs/2511.14791", "authors": ["Cyriana M. A. Roelofs", "Edison Guevara Bastidas", "Thomas Hugo", "Stefan Faulstich", "Anna Cadenbach"], "title": "Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data", "comment": "30 pages, 6 figures", "summary": "Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\n  The dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\n  Integrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u65e9\u671f\u68c0\u6d4b\u533a\u57df\u4f9b\u70ed\u6362\u70ed\u7ad9\u7684\u6545\u969c\uff0c\u5305\u542b\u516c\u5f00\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u6307\u6807\uff08\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u3001\u65e9\u671f\u6027\uff09\u3001\u57fa\u4e8eEnergyFaultDetector\u7684\u57fa\u7ebf\u7ed3\u679c\uff0c\u5e76\u652f\u6301\u4f7f\u7528ARCANA\u8fdb\u884c\u6839\u56e0\u5206\u6790\u3002", "motivation": "\u533a\u57df\u4f9b\u70ed\u6362\u70ed\u7ad9\u6545\u969c\u7684\u65e9\u671f\u68c0\u6d4b\u5bf9\u964d\u4f4e\u56de\u6c34\u6e29\u5ea6\u548c\u63d0\u5347\u7cfb\u7edf\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8be5\u9886\u57df\u7814\u7a76\u53d7\u9650\u4e8e\u7f3a\u4e4f\u516c\u5f00\u6807\u6ce8\u7684\u6570\u636e\u96c6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b93\u4e2a\u6362\u70ed\u7ad9\u8fd0\u884c\u65f6\u5e8f\u6570\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u7ed3\u5408Accuracy\u3001\u4e8b\u4ef6\u7ea7F-score\uff08\u03b2=0.5\uff09\u548cEarliness\u4e09\u9879\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5229\u7528\u5f00\u6e90Python\u6846\u67b6EnergyFaultDetector\u5b9e\u73b0\u57fa\u7ebf\u6a21\u578b\uff0c\u540c\u65f6\u96c6\u6210ARCANA\u5de5\u5177\u652f\u6301\u6839\u56e0\u5206\u6790\u3002", "result": "\u6a21\u578b\u5728\u6b63\u5e38\u884c\u4e3a\u8bc6\u522b\u4e0a\u51c6\u786e\u7387\u8fbe0.98\uff0c\u4e8b\u4ef6\u7ea7F-score\u8fbe0.83\uff0c\u80fd\u5728\u7528\u6237\u62a5\u4fee\u524d\u68c0\u6d4b\u523060%\u7684\u6545\u969c\uff0c\u5e73\u5747\u63d0\u524d3.9\u5929\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5f00\u6e90\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u6307\u6807\u3001\u4ee3\u7801\u4e0e\u57fa\u7ebf\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u4ee5\u6545\u969c\u4e3a\u4e2d\u5fc3\u4e14\u5177\u6709\u5b9e\u9645\u8fd0\u884c\u610f\u4e49\u7684\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u533a\u57df\u4f9b\u70ed\u6362\u70ed\u7ad9\u65e9\u671f\u6545\u969c\u68c0\u6d4b\u4e0e\u8bca\u65ad\u65b9\u6cd5\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.14794", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14794", "abs": "https://arxiv.org/abs/2511.14794", "authors": ["Camilo Chac\u00f3n Sartori", "Christian Blum"], "title": "irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution", "comment": null, "summary": "Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fairace-evo\uff0c\u4e00\u79cd\u7ed3\u5408\u81ea\u52a8\u53c2\u6570\u8c03\u4f18\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u4ee3\u7801\u6f14\u5316\u7684\u6846\u67b6\uff0c\u5728\u4f4e\u8ba1\u7b97\u548c\u7ecf\u6d4e\u6210\u672c\u4e0b\u663e\u8457\u63d0\u5347\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u7b97\u6cd5\u914d\u7f6e\u5de5\u5177\uff08\u5982irace\uff09\u4ec5\u4f18\u5316\u53c2\u6570\u800c\u65e0\u6cd5\u4fee\u6539\u7b97\u6cd5\u4ee3\u7801\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u7a7a\u95f4\uff1b\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u4ee3\u7801\u6f14\u5316\u80fd\u529b\uff0c\u8054\u5408\u63a2\u7d22\u53c2\u6570\u4e0e\u4ee3\u7801\u7a7a\u95f4\u4ee5\u6539\u8fdb\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "method": "\u5728irace\u57fa\u7840\u4e0a\u6269\u5c55\uff0c\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u6f14\u5316\uff0c\u652f\u6301\u591a\u8bed\u8a00\uff08\u5982C++\u3001Python\uff09\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u201cAlways-From-Original\u201d\u539f\u5219\u63a7\u5236\u6f14\u5316\u8fc7\u7a0b\uff0c\u5e76\u5728VSBPP\u95ee\u9898\u7684CMSA\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "irace-evo\u53d1\u73b0\u4e86\u4f18\u4e8e\u5f53\u524d\u6700\u4f18CMSA\u5b9e\u73b0\u7684\u65b0\u7b97\u6cd5\u53d8\u4f53\uff0c\u4e14\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6a21\u578b\uff08\u5982Claude Haiku 3.5\uff09\u603b\u6210\u672c\u4f4e\u4e8e2\u6b27\u5143\uff0c\u5c55\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u7ecf\u6d4e\u6027\u3002", "conclusion": "\u5c06\u81ea\u52a8\u914d\u7f6e\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4ee3\u7801\u6f14\u5316\u76f8\u7ed3\u5408\uff0c\u4e3a\u542f\u53d1\u5f0f\u8bbe\u8ba1\u548c\u5143\u542f\u53d1\u5f0f\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u4e14\u4f4e\u6210\u672c\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.14798", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.14798", "abs": "https://arxiv.org/abs/2511.14798", "authors": ["Ahmad Memon", "Abdallah Mohamed"], "title": "Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods", "comment": "10 pages, 5 figures. This version corresponds to the paper accepted for presentation at CASCON 2025", "summary": "Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.\n  This paper compares two AI-based grading techniques: \\textit{Direct}, where the AI model applies a rubric directly to student code, and \\textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.\n  Initial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7a0b\u4f5c\u4e1a\u81ea\u52a8\u8bc4\u5206\u65b9\u6cd5\uff1a\u76f4\u63a5\u5e94\u7528\u8bc4\u5206\u6807\u51c6\u7684\u201cDirect\u201d\u65b9\u6cd5\u548c\u901a\u8fc7\u5148\u4fee\u590d\u4ee3\u7801\u518d\u53cd\u63a8\u5206\u6570\u7684\u65b0\u578b\u201cReverse\u201d\u65b9\u6cd5\uff0c\u53d1\u73b0\u540e\u8005\u5728\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u65b9\u9762\u66f4\u5177\u4f18\u52bf\uff0c\u4f46\u4e24\u8005\u5747\u9700\u7cbe\u5fc3\u8bbe\u8ba1\u63d0\u793a\u8bcd\uff0c\u5e76\u63a2\u8ba8\u4e86\u4eba\u673a\u6df7\u5408\u8bc4\u5206\u7cfb\u7edf\u7684\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u7f16\u7a0b\u4f5c\u4e1a\u4eba\u5de5\u8bc4\u5206\u8017\u65f6\u4e14\u6613\u4e0d\u4e00\u81f4\uff0c\u800c\u73b0\u6709\u57fa\u4e8e\u5355\u5143\u6d4b\u8bd5\u7684\u81ea\u52a8\u8bc4\u5206\u591a\u4e3a\u4e8c\u5143\u901a\u8fc7/\u5931\u8d25\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u90e8\u5206\u5f97\u5206\u673a\u5236\uff1b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u5b9e\u73b0\u66f4\u5ba2\u89c2\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u8bc4\u5206\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002", "method": "\u63d0\u51fa\u5e76\u5bf9\u6bd4\u4e24\u79cdAI\u8bc4\u5206\u65b9\u6cd5\u2014\u2014Direct\uff08AI\u76f4\u63a5\u4f9d\u636e\u8bc4\u5206\u6807\u51c6\u8bc4\u5206\uff09\u4e0eReverse\uff08AI\u5148\u4fee\u590d\u5b66\u751f\u4ee3\u7801\uff0c\u518d\u6839\u636e\u4fee\u590d\u5185\u5bb9\u53cd\u63a8\u5206\u6570\uff09\uff1b\u5728\u539f\u59cb\u8bc4\u5206\u5c3a\u5ea6\u53ca\u5341\u500d\u6269\u5c55\u5c3a\u5ea6\u4e0b\uff0c\u5c06AI\u8bc4\u5206\u7ed3\u679c\u4e0e\u4eba\u7c7b\u52a9\u6559\u8bc4\u5206\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u5229\u7528Gemini Flash 2.0\u751f\u6210\u7684\u5408\u6210\u4ee3\u7801\u6d4b\u8bd5AI\u8bc4\u5206\u5668\u5728\u4e0d\u540c\u9519\u8bef\u7c7b\u578b\u548c\u96be\u5ea6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0cDirect\u65b9\u6cd5\u66f4\u5feb\u6377\u76f4\u63a5\uff0c\u800cReverse\u65b9\u6cd5\u901a\u8fc7\u5173\u6ce8\u4fee\u590d\u5de5\u4f5c\u91cf\u80fd\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u8bc4\u5206\uff1b\u4e24\u79cd\u65b9\u6cd5\u5747\u5bf9\u63d0\u793a\u5de5\u7a0b\u654f\u611f\uff0c\u5c24\u5176\u5728\u903b\u8f91\u9519\u8bef\u5904\u7406\u548c\u90e8\u5206\u5f97\u5206\u5206\u914d\u65b9\u9762\uff1b\u5408\u6210\u6570\u636e\u6709\u52a9\u4e8e\u63d0\u5347\u8bc4\u4f30\u8986\u76d6\u8303\u56f4\u3002", "conclusion": "Reverse\u65b9\u6cd5\u5728\u7ec6\u7c92\u5ea6\u8bc4\u5206\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u4e24\u79cdAI\u8bc4\u5206\u65b9\u6cd5\u90fd\u9700\u8981\u7cbe\u7ec6\u7684\u63d0\u793a\u8bbe\u8ba1\uff1b\u672a\u6765\u5e94\u63a2\u7d22\u7ed3\u5408\u4eba\u7c7b\u5224\u65ad\u4e0eAI\u6548\u7387\u7684\u6df7\u5408\u8bc4\u5206\u7cfb\u7edf\uff0c\u4ee5\u63d0\u5347\u8ba1\u7b97\u673a\u8bfe\u7a0b\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u3001\u6548\u7387\u4e0e\u516c\u5e73\u6027\u3002"}}
{"id": "2511.14762", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.14762", "abs": "https://arxiv.org/abs/2511.14762", "authors": ["Yongye Su", "Yucheng Zhang", "Zeru Shi", "Bruno Ribeiro", "Elisa Bertino"], "title": "Castle: Causal Cascade Updates in Relational Databases with Large Language Models", "comment": null, "summary": "This work introduces Castle, the first framework for schema-only cascade update generation using large language models (LLMs). Despite recent advances in LLMs for Text2SQL code generation, existing approaches focus primarily on SELECT queries, neglecting the challenges of SQL update operations and their ripple effects. Traditional CASCADE UPDATE constraints are static and unsuitable for modern, denormalized databases, which demand dynamic, context-aware updates. Castle enables natural language instructions to trigger multi-column, causally consistent SQL UPDATE statements, without revealing table content to the model. By framing UPDATE SQL generation as a divide-and-conquer task with LLMs' reasoning capacity, Castle can determine not only which columns must be directly updated, but also how those updates propagate through the schema, causing cascading updates -- all via nested queries and substructures that ensure data confidentiality. We evaluate it on real-world causal update scenarios, demonstrating its ability to produce accurate SQL updates, and thereby highlighting the reasoning ability of LLMs in automated DBMS.", "AI": {"tldr": "Castle \u662f\u9996\u4e2a\u4ec5\u57fa\u4e8e\u6570\u636e\u5e93\u6a21\u5f0f\u3001\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u7ea7\u8054\u66f4\u65b0 SQL \u7684\u6846\u67b6\uff0c\u652f\u6301\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u751f\u6210\u591a\u5217\u3001\u56e0\u679c\u4e00\u81f4\u7684 UPDATE \u8bed\u53e5\uff0c\u4e14\u65e0\u9700\u66b4\u9732\u8868\u5185\u5bb9\u3002", "motivation": "\u73b0\u6709 LLM \u5728 Text2SQL \u4e2d\u4e3b\u8981\u5173\u6ce8 SELECT \u67e5\u8be2\uff0c\u5ffd\u89c6\u4e86 SQL \u66f4\u65b0\u64cd\u4f5c\u53ca\u5176\u5728\u73b0\u4ee3\u53bb\u89c4\u8303\u5316\u6570\u636e\u5e93\u4e2d\u7684\u7ea7\u8054\u5f71\u54cd\uff1b\u4f20\u7edf CASCADE UPDATE \u7ea6\u675f\u9759\u6001\u4e14\u4e0d\u9002\u7528\uff0c\u9700\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u66f4\u65b0\u673a\u5236\u3002", "method": "\u5c06 UPDATE SQL \u751f\u6210\u5efa\u6a21\u4e3a\u5206\u800c\u6cbb\u4e4b\u4efb\u52a1\uff0c\u5229\u7528 LLM \u7684\u63a8\u7406\u80fd\u529b\u5224\u65ad\u9700\u76f4\u63a5\u66f4\u65b0\u7684\u5217\u53ca\u5176\u5728\u6a21\u5f0f\u4e2d\u7684\u4f20\u64ad\u8def\u5f84\uff0c\u901a\u8fc7\u5d4c\u5957\u67e5\u8be2\u548c\u5b50\u7ed3\u6784\u751f\u6210\u7ea7\u8054\u66f4\u65b0\u8bed\u53e5\uff0c\u540c\u65f6\u4fdd\u969c\u6570\u636e\u4fdd\u5bc6\u6027\u3002", "result": "\u5728\u771f\u5b9e\u56e0\u679c\u66f4\u65b0\u573a\u666f\u4e2d\u8bc4\u4f30\u8868\u660e\uff0cCastle \u80fd\u51c6\u786e\u751f\u6210\u7b26\u5408\u8bed\u4e49\u7684 SQL \u66f4\u65b0\u8bed\u53e5\uff0c\u9a8c\u8bc1\u4e86 LLM \u5728\u81ea\u52a8\u5316\u6570\u636e\u5e93\u7ba1\u7406\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "Castle \u6210\u529f\u5c55\u793a\u4e86 LLM \u5728\u590d\u6742 SQL \u66f4\u65b0\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u65e0\u5185\u5bb9\u6cc4\u9732\u7684\u52a8\u6001\u7ea7\u8054\u66f4\u65b0\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u62d3\u5c55\u4e86 LLM \u5728\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u8fb9\u754c\u3002"}}
{"id": "2511.14921", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.14921", "abs": "https://arxiv.org/abs/2511.14921", "authors": ["Mohamed Rouili", "Yang Xiao", "Sihang Liu", "Raouf Boutaba"], "title": "RAID: In-Network RA Signaling Storm Detection for 5G Open RAN", "comment": null, "summary": "The disaggregation and virtualization of 5G Open RAN (O-RAN) introduces new vulnerabilities in the control plane that can greatly impact the quality of service (QoS) of latency-sensitive 5G applications and services. One critical issue is Random Access (RA) signaling storms where, a burst of illegitimate or misbehaving user equipments (UEs) send Radio Resource Control (RRC) connection requests that rapidly saturate a Central Unit's (CU) processing pipeline. Such storms trigger widespread connection failures within the short contention resolution window defined by 3GPP. Existing detection and mitigation approaches based on near-real-time RAN Intelligent Controller (n-RT RIC) applications cannot guarantee a timely reaction to such attacks as RIC control loops incur tens to hundreds of milliseconds of latency due to the non-deterministic nature of their general purpose processor (GPP) based architectures. This paper presents RAID, an in-network RA signaling storm detection and mitigation system that leverages P4-programmable switch ASICs to enable real-time protection from malicious attacks. RAID embeds a lightweight Random Forest (RF) classifier into a programmable Tofino switch, enabling line-rate flow classification with deterministic microsecond-scale inference delay. By performing ML-based detection directly in the data plane, RAID catches and filters malicious RA requests before they reach and overwhelm the RRC. RAID achieves above 94% detection accuracy with a fixed per-flow inference delay on the order of 3.4 microseconds, effectively meeting strict O-RAN control-plane deadlines. These improvements are sustained across multiple traffic loads, making RAID a fast and scalable solution for the detection and mitigation of signaling storms in 5G O-RAN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRAID\u7cfb\u7edf\uff0c\u5229\u7528P4\u53ef\u7f16\u7a0b\u4ea4\u6362\u673aASIC\u5728\u6570\u636e\u5e73\u9762\u5d4c\u5165\u8f7b\u91cf\u7ea7\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u5bf95G O-RAN\u4e2d\u968f\u673a\u63a5\u5165\u4fe1\u4ee4\u98ce\u66b4\u7684\u5fae\u79d2\u7ea7\u5b9e\u65f6\u68c0\u6d4b\u4e0e\u8fc7\u6ee4\uff0c\u51c6\u786e\u7387\u8d8594%\uff0c\u6709\u6548\u4fdd\u969c\u63a7\u5236\u9762\u670d\u52a1\u8d28\u91cf\u3002", "motivation": "5G\u5f00\u653e\u65e0\u7ebf\u63a5\u5165\u7f51\uff08O-RAN\uff09\u7684\u89e3\u8026\u4e0e\u865a\u62df\u5316\u5f15\u5165\u4e86\u65b0\u7684\u63a7\u5236\u9762\u6f0f\u6d1e\uff0c\u5c24\u5176\u662f\u7531\u6076\u610f\u6216\u5f02\u5e38\u7528\u6237\u8bbe\u5907\u5f15\u53d1\u7684\u968f\u673a\u63a5\u5165\uff08RA\uff09\u4fe1\u4ee4\u98ce\u66b4\u4f1a\u8fc5\u901f\u8017\u5c3d\u4e2d\u592e\u5355\u5143\uff08CU\uff09\u5904\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u5927\u89c4\u6a21\u8fde\u63a5\u5931\u8d25\uff1b\u800c\u73b0\u6709\u57fa\u4e8e\u8fd1\u5b9e\u65f6RAN\u667a\u80fd\u63a7\u5236\u5668\uff08n-RT RIC\uff09\u7684\u68c0\u6d4b\u65b9\u6cd5\u56e0\u901a\u7528\u5904\u7406\u5668\u67b6\u6784\u7684\u975e\u786e\u5b9a\u6027\u5ef6\u8fdf\uff08\u6570\u5341\u81f3\u6570\u767e\u6beb\u79d2\uff09\uff0c\u65e0\u6cd5\u53ca\u65f6\u5e94\u5bf9\u3002", "method": "\u63d0\u51faRAID\u7cfb\u7edf\uff0c\u5c06\u8f7b\u91cf\u7ea7\u968f\u673a\u68ee\u6797\uff08RF\uff09\u5206\u7c7b\u5668\u5d4c\u5165\u53ef\u7f16\u7a0bTofino\u4ea4\u6362\u673a\u4e2d\uff0c\u5229\u7528P4\u53ef\u7f16\u7a0b\u4ea4\u6362\u673aASIC\u5728\u6570\u636e\u5e73\u9762\u76f4\u63a5\u8fdb\u884c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684RA\u8bf7\u6c42\u68c0\u6d4b\u4e0e\u8fc7\u6ee4\uff0c\u5b9e\u73b0\u7ebf\u901f\u6d41\u5206\u7c7b\u548c\u786e\u5b9a\u6027\u7684\u5fae\u79d2\u7ea7\u63a8\u7406\u5ef6\u8fdf\u3002", "result": "RAID\u5728\u591a\u79cd\u6d41\u91cf\u8d1f\u8f7d\u4e0b\u5747\u4fdd\u6301\u8d85\u8fc794%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u6bcf\u6d41\u63a8\u7406\u5ef6\u8fdf\u56fa\u5b9a\u7ea6\u4e3a3.4\u5fae\u79d2\uff0c\u6ee1\u8db3O-RAN\u63a7\u5236\u9762\u4e25\u683c\u7684\u65f6\u5ef6\u8981\u6c42\uff0c\u6709\u6548\u9632\u6b62\u6076\u610fRA\u8bf7\u6c42\u51b2\u51fbRRC\u3002", "conclusion": "RAID\u662f\u4e00\u79cd\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u57285G O-RAN\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u3001\u9ad8\u6548\u7684\u4fe1\u4ee4\u98ce\u66b4\u68c0\u6d4b\u4e0e\u7f13\u89e3\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eRIC\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.14879", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.14879", "abs": "https://arxiv.org/abs/2511.14879", "authors": ["Houssem-Eddine Gueziri", "Abicumaran Uthamacumaran", "Widad Safih", "Abdulrahman Almansouri", "Nour Abou Hamdan", "Jose A. Correa", "\u00c9tienne L\u00e9ger", "D. Louis Collins", "Rolando F. Del Maestro"], "title": "A High-Fidelity Neurosurgical Training Platform for Bimanual Procedures: A Feasibility Study", "comment": "14 pages, 9 figures", "summary": "Background. Bimanual psychomotor proficiency is fundamental to neurosurgical procedures, yet it remains difficult for trainees to acquire and for educators to objectively evaluate performance. In this study, we investigate the feasibility of a neurosurgical simulation platform that integrates an anatomically realistic brain model with surgical instrument tracking to support training and objective assessment of bimanual tasks in the context of subpial corticectomy. Methods. We developed and evaluated a neurosurgical simulation platform based on an ex-vivo calf brain model and a multi-camera tracking system capable of simultaneously capturing the motion of surgical instruments in both hands, including collection of real-time instrument trajectories and synchronized video recordings. These enabled extraction of motion-based, time-based, and bimanual coordination metrics. We conducted a case series involving 47 participants across four training levels: medical students, junior residents, senior residents, and neurosurgeons. Results. The tracking system successfully captured instrument motion during 81% of the periods when instruments were actively used throughout the simulation procedure. Several extracted metrics were able to significantly differentiate between levels of surgical expertise. In particular, instrument usage duration and custom-defined bimanual coordination metrics such as instrument tip separation distance and simultaneous usage time, show potential as features to identify participant expertise levels with different instruments. Conclusions. We demonstrated the feasibility of tracking surgical instruments during complex bimanual tasks in an ex-vivo brain simulation platform. The metrics developed provide a foundation for objective performance assessment and highlight the potential of motion analysis to improve neurosurgical training and evaluation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u79bb\u4f53\u725b\u8111\u6a21\u578b\u548c\u591a\u6444\u50cf\u5934\u8ffd\u8e2a\u7cfb\u7edf\u7684\u795e\u7ecf\u5916\u79d1\u6a21\u62df\u5e73\u53f0\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u5ba2\u89c2\u8bc4\u4f30\u53cc\u5668\u68b0\u76ae\u5c42\u5207\u9664\u672f\u4e2d\u7684\u53cc\u624b\u534f\u8c03\u80fd\u529b\uff0c\u5e76\u6210\u529f\u63d0\u53d6\u4e86\u53ef\u533a\u5206\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u5b66\u5458\u7684\u8fd0\u52a8\u6307\u6807\u3002", "motivation": "\u795e\u7ecf\u5916\u79d1\u624b\u672f\u4e2d\u53cc\u624b\u7cbe\u7ec6\u64cd\u4f5c\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u96be\u4ee5\u8bad\u7ec3\u4e14\u7f3a\u4e4f\u5ba2\u89c2\u8bc4\u4f30\u624b\u6bb5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u652f\u6301\u8bad\u7ec3\u5e76\u91cf\u5316\u8bc4\u4f30\u53cc\u624b\u64cd\u4f5c\u8868\u73b0\u7684\u6a21\u62df\u5e73\u53f0\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408\u79bb\u4f53\u725b\u8111\u6a21\u578b\u4e0e\u591a\u6444\u50cf\u5934\u4eea\u5668\u8ffd\u8e2a\u7cfb\u7edf\u7684\u795e\u7ecf\u5916\u79d1\u6a21\u62df\u5e73\u53f0\uff0c\u5b9e\u65f6\u8bb0\u5f55\u53cc\u624b\u624b\u672f\u5668\u68b0\u8f68\u8ff9\u53ca\u540c\u6b65\u89c6\u9891\uff0c\u4ece\u4e2d\u63d0\u53d6\u8fd0\u52a8\u3001\u65f6\u95f4\u53ca\u53cc\u624b\u534f\u8c03\u76f8\u5173\u6307\u6807\uff1b\u5bf947\u540d\u6db5\u76d6\u56db\u4e2a\u57f9\u8bad\u9636\u6bb5\uff08\u533b\u5b66\u751f\u3001\u4f4e\u5e74\u8d44\u4f4f\u9662\u533b\u5e08\u3001\u9ad8\u5e74\u8d44\u4f4f\u9662\u533b\u5e08\u548c\u795e\u7ecf\u5916\u79d1\u533b\u751f\uff09\u7684\u53c2\u4e0e\u8005\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u8ffd\u8e2a\u7cfb\u7edf\u572881%\u7684\u5668\u68b0\u4f7f\u7528\u65f6\u6bb5\u5185\u6210\u529f\u6355\u83b7\u8fd0\u52a8\u6570\u636e\uff1b\u591a\u4e2a\u6307\u6807\uff08\u5982\u5668\u68b0\u4f7f\u7528\u65f6\u957f\u3001\u5668\u68b0\u5c16\u7aef\u95f4\u8ddd\u3001\u540c\u65f6\u4f7f\u7528\u65f6\u95f4\u7b49\uff09\u80fd\u663e\u8457\u533a\u5206\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u53c2\u4e0e\u8005\u3002", "conclusion": "\u8be5\u5e73\u53f0\u5728\u590d\u6742\u53cc\u624b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5668\u68b0\u8ffd\u8e2a\u5177\u6709\u53ef\u884c\u6027\uff0c\u6240\u5f00\u53d1\u7684\u6307\u6807\u4e3a\u5ba2\u89c2\u8bc4\u4f30\u624b\u672f\u8868\u73b0\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u8fd0\u52a8\u5206\u6790\u5728\u63d0\u5347\u795e\u7ecf\u5916\u79d1\u57f9\u8bad\u4e0e\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.14990", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.14990", "abs": "https://arxiv.org/abs/2511.14990", "authors": ["Zhuolun Jiang", "Songyue Wang", "Xiaokun Pei", "Tianyue Lu", "Mingyu Chen"], "title": "CoroAMU: Unleashing Memory-Driven Coroutines through Latency-Aware Decoupled Operations", "comment": null, "summary": "Modern data-intensive applications face memory latency challenges exacerbated by disaggregated memory systems. Recent work shows that coroutines are promising in effectively interleaving tasks and hiding memory latency, but they struggle to balance latency-hiding efficiency with runtime overhead. We present CoroAMU, a hardware-software co-designed system for memory-centric coroutines. It introduces compiler procedures that optimize coroutine code generation, minimize context, and coalesce requests, paired with a simple interface. With hardware support of decoupled memory operations, we enhance the Asynchronous Memory Unit to further exploit dynamic coroutine schedulers by coroutine-specific memory operations and a novel memory-guided branch prediction mechanism. It is implemented with LLVM and open-source XiangShan RISC-V processor over the FPGA platform. Experiments demonstrate that the CoroAMU compiler achieves a 1.51x speedup over state-of-the-art coroutine methods on Intel server processors. When combined with optimized hardware of decoupled memory access, it delivers 3.39x and 4.87x average performance improvements over the baseline processor on FPGA-emulated disaggregated systems under 200ns and 800ns latency respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CoroAMU\uff0c\u4e00\u79cd\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u5185\u5b58\u4e2d\u5fc3\u5316\u534f\u7a0b\u7cfb\u7edf\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u4f18\u5316\u4e0e\u786c\u4ef6\u652f\u6301\uff08\u5982\u89e3\u8026\u5185\u5b58\u64cd\u4f5c\u548c\u65b0\u578b\u5185\u5b58\u5f15\u5bfc\u5206\u652f\u9884\u6d4b\uff09\uff0c\u5728FPGA\u5e73\u53f0\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u534f\u7a0b\u5728\u9ad8\u5ef6\u8fdf\u5206\u79bb\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u5728\u5206\u79bb\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u9762\u4e34\u4e25\u91cd\u7684\u5185\u5b58\u5ef6\u8fdf\u95ee\u9898\uff1b\u5c3d\u7ba1\u534f\u7a0b\u53ef\u6709\u6548\u9690\u85cf\u5ef6\u8fdf\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u5ef6\u8fdf\u9690\u85cf\u6548\u7387\u4e0e\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "method": "CoroAMU\u7ed3\u5408\u7f16\u8bd1\u5668\u4f18\u5316\uff08\u51cf\u5c11\u4e0a\u4e0b\u6587\u3001\u5408\u5e76\u8bf7\u6c42\uff09\u4e0e\u786c\u4ef6\u589e\u5f3a\uff08\u5f02\u6b65\u5185\u5b58\u5355\u5143\u3001\u534f\u7a0b\u4e13\u7528\u5185\u5b58\u64cd\u4f5c\u3001\u5185\u5b58\u5f15\u5bfc\u5206\u652f\u9884\u6d4b\uff09\uff0c\u5e76\u5728LLVM\u548c\u5f00\u6e90XiangShan RISC-V\u5904\u7406\u5668\u4e0a\u5b9e\u73b0\u3002", "result": "\u5728Intel\u670d\u52a1\u5668\u4e0a\uff0cCoroAMU\u7f16\u8bd1\u5668\u6bd4\u73b0\u6709\u534f\u7a0b\u65b9\u6cd5\u5feb1.51\u500d\uff1b\u5728FPGA\u6a21\u62df\u7684\u5206\u79bb\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\uff0c\u7ed3\u5408\u4f18\u5316\u786c\u4ef6\u540e\uff0c\u5728200ns\u548c800ns\u5ef6\u8fdf\u4e0b\u5206\u522b\u83b7\u5f973.39\u500d\u548c4.87\u500d\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CoroAMU\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u534f\u7a0b\u5728\u9ad8\u5ef6\u8fdf\u5185\u5b58\u73af\u5883\u4e0b\u7684\u6548\u7387\u4e0e\u5f00\u9500\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.14803", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14803", "abs": "https://arxiv.org/abs/2511.14803", "authors": ["Pranjal Gupta", "Karan Bhukar", "Harshit Kumar", "Seema Nagar", "Prateeti Mohapatra", "Debanjana Kar"], "title": "Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study", "comment": null, "summary": "IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65e5\u5fd7\u5206\u6790\u5de5\u5177\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5904\u7406\u548c\u8bca\u65adIT\u7cfb\u7edf\u65e5\u5fd7\uff0c\u5e76\u901a\u8fc7\u5728CPU\u4e0a\u9ad8\u6548\u8fd0\u884cLLM\u5b9e\u73b0\u5927\u89c4\u6a21\u65e5\u5fd7\u7684\u5feb\u901f\u5206\u6790\u3002\u8be5\u5de5\u5177\u81ea2024\u5e743\u6708\u4e0a\u7ebf\u4ee5\u6765\uff0c\u5df2\u8986\u76d670\u4e2a\u8f6f\u4ef6\u4ea7\u54c1\uff0c\u5904\u7406\u8d852000\u4e2a\u5de5\u5355\uff0c\u6bcf\u6708\u8282\u7701300\u591a\u4eba\u5de5\u65f6\u53ca\u7ea615,444\u7f8e\u5143\u4eba\u529b\u6210\u672c\u3002", "motivation": "IT\u73af\u5883\u4e2d\u65e5\u5fd7\u6570\u91cf\u5e9e\u5927\uff0c\u4eba\u5de5\u68c0\u67e5\u4e0d\u73b0\u5b9e\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u7684\u65e5\u5fd7\u5206\u6790\u624b\u6bb5\u4ee5\u63d0\u5347IT\u8f6f\u4ef6\u652f\u6301\u6548\u7387\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u65e5\u5fd7\u6570\u636e\u5904\u7406\u4e0e\u95ee\u9898\u8bca\u65ad\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u5728CPU\u4e0a\u9ad8\u6548\u8fd0\u884cLLM\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u5728\u4fdd\u8bc1\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\u5feb\u901f\u5904\u7406\u6d77\u91cf\u65e5\u5fd7\u3002", "result": "\u5de5\u5177\u5df2\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u8986\u76d670\u4e2a\u8f6f\u4ef6\u4ea7\u54c1\uff0c\u5904\u74062000\u591a\u4e2a\u5de5\u5355\uff0c\u6bcf\u6708\u8282\u7701300+\u4eba\u5de5\u65f6\u548c\u7ea615,444\u7f8e\u5143\u7684\u4eba\u529b\u6210\u672c\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u65e5\u5fd7\u5206\u6790\u5de5\u5177\u80fd\u663e\u8457\u63d0\u5347\u65e5\u5fd7\u5904\u7406\u6548\u7387\u548c\u95ee\u9898\u8bca\u65ad\u901f\u5ea6\uff0c\u5728\u5b9e\u9645\u751f\u4ea7\u4e2d\u5c55\u73b0\u51fa\u53ef\u89c2\u7684\u6210\u672c\u8282\u7ea6\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728IT\u652f\u6301\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.15090", "categories": ["cs.DB", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15090", "abs": "https://arxiv.org/abs/2511.15090", "authors": ["Wenhan Yu", "Wang Chen", "Guanqiang Qi", "Weikang Li", "Yang Li", "Lei Sha", "Deguo Xia", "Jizhou Huang"], "title": "BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer", "comment": "22 pages, 4 figures", "summary": "Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BBox DocVQA\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u57fa\u4e8e\u8fb9\u754c\u6846\u7684\u6587\u6863\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u65e8\u5728\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u548c\u8bc1\u636e\u5b9a\u4f4d\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u6784\u5efa\u6d41\u7a0b\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709DocVQA\u6570\u636e\u96c6\u591a\u5c40\u9650\u4e8e\u9875\u9762\u7ea7\u522b\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u7a7a\u95f4\u5b9a\u4f4d\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u540d\u4e3a\u201cSegment-Judge-and-Generate\u201d\u7684\u81ea\u52a8\u5316\u6784\u5efa\u6d41\u7a0b\uff1a\u7ed3\u5408\u533a\u57df\u5206\u5272\u6a21\u578b\u3001\u7528\u4e8e\u8bed\u4e49\u5224\u65ad\u7684VLM\u3001\u7528\u4e8e\u95ee\u7b54\u751f\u6210\u7684\u9ad8\u7ea7VLM\uff0c\u5e76\u8f85\u4ee5\u4eba\u5de5\u9a8c\u8bc1\uff1b\u6784\u5efa\u5305\u542b3.6K\u6587\u6863\u548c32K\u95ee\u7b54\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u95ee\u7b54\u5747\u6807\u6ce8\u660e\u786e\u8fb9\u754c\u6846\u3002", "result": "\u5728BBox DocVQA\u4e0a\u5bf9\u591a\u4e2a\u5148\u8fdbVLM\uff08\u5982GPT-5\u3001Qwen2.5-VL\u3001InternVL\uff09\u8fdb\u884c\u8bc4\u6d4b\uff0c\u53d1\u73b0\u5176\u5728\u7a7a\u95f4\u5b9a\u4f4d\u4e0e\u63a8\u7406\u51c6\u786e\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\uff1b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u8fb9\u754c\u6846\u5b9a\u4f4d\u4e0e\u7b54\u6848\u751f\u6210\u6027\u80fd\u3002", "conclusion": "BBox DocVQA\u6709\u6548\u589e\u5f3a\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u8bed\u4e49\u5bf9\u9f50\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5c06\u516c\u5f00\u4ee5\u63a8\u52a8\u53ef\u89e3\u91ca\u3001\u7a7a\u95f4\u5b9a\u4f4d\u7cbe\u51c6\u7684\u591a\u6a21\u6001\u7814\u7a76\u3002"}}
{"id": "2511.15245", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.15245", "abs": "https://arxiv.org/abs/2511.15245", "authors": ["Chuanlei Li", "Zhicheng Sun", "Jing Xin Yuu", "Xuechao Wang"], "title": "The Walls Have Ears: Unveiling Cross-Chain Sandwich Attacks in DeFi", "comment": null, "summary": "Cross-chain interoperability is a core component of modern blockchain infrastructure, enabling seamless asset transfers and composable applications across multiple blockchain ecosystems. However, the transparency of cross-chain messages can inadvertently expose sensitive transaction information, creating opportunities for adversaries to exploit value through manipulation or front-running strategies.\n  In this work, we investigate cross-chain sandwich attacks targeting liquidity pool-based cross-chain bridge protocols. We uncover a critical vulnerability where attackers can exploit events emitted on the source chain to learn transaction details on the destination chain before they appear in the destination chain mempool. This information advantage allows attackers to strategically place front-running and back-running transactions, ensuring that their front-running transactions always precede those of existing MEV bots monitoring the mempool of the destination chain. Moreover, current sandwich-attack defenses are ineffective against this new cross-chain variant. To quantify this threat, we conduct an empirical study using two months (August 10 to October 10, 2025) of cross-chain transaction data from the Symbiosis protocol and a tailored heuristic detection model. Our analysis identifies attacks that collectively garnered over \\(5.27\\) million USD in profit, equivalent to 1.28\\% of the total bridged volume.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u4e00\u79cd\u9488\u5bf9\u57fa\u4e8e\u6d41\u52a8\u6027\u6c60\u7684\u8de8\u94fe\u6865\u534f\u8bae\u7684\u65b0\u578b\u8de8\u94fe\u4e09\u660e\u6cbb\u653b\u51fb\uff0c\u653b\u51fb\u8005\u5229\u7528\u6e90\u94fe\u4e8b\u4ef6\u63d0\u524d\u83b7\u77e5\u76ee\u6807\u94fe\u4ea4\u6613\u7ec6\u8282\uff0c\u4ece\u800c\u5728MEV\u673a\u5668\u4eba\u4e4b\u524d\u6267\u884c\u524d\u7f6e\u548c\u540e\u7f6e\u4ea4\u6613\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u5bf9\u6b64\u65e0\u6548\uff1b\u901a\u8fc7\u5bf9Symbiosis\u534f\u8bae\u4e24\u4e2a\u6708\u6570\u636e\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u6b64\u7c7b\u653b\u51fb\u5df2\u83b7\u5229\u8d85527\u4e07\u7f8e\u5143\uff0c\u5360\u603b\u8de8\u94fe\u4ea4\u6613\u91cf\u76841.28%\u3002", "motivation": "\u73b0\u6709\u8de8\u94fe\u6865\u534f\u8bae\u5728\u5b9e\u73b0\u8d44\u4ea7\u8f6c\u79fb\u548c\u5e94\u7528\u4e92\u64cd\u4f5c\u6027\u7684\u540c\u65f6\uff0c\u5176\u6d88\u606f\u900f\u660e\u6027\u53ef\u80fd\u6cc4\u9732\u654f\u611f\u4ea4\u6613\u4fe1\u606f\uff0c\u4e3a\u653b\u51fb\u8005\u63d0\u4f9b\u53ef\u5229\u7528\u7684\u4fe1\u606f\u4f18\u52bf\uff0c\u800c\u5f53\u524d\u9488\u5bf9\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u9632\u5fa1\u63aa\u65bd\u65e0\u6cd5\u5e94\u5bf9\u8fd9\u79cd\u65b0\u578b\u8de8\u94fe\u653b\u51fb\u6a21\u5f0f\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5206\u6790\u8de8\u94fe\u6865\u534f\u8bae\u4e2d\u6e90\u94fe\u4e8b\u4ef6\u4e0e\u76ee\u6807\u94fe\u4ea4\u6613\u4e4b\u95f4\u7684\u65f6\u5e8f\u5173\u7cfb\uff0c\u6784\u5efa\u542f\u53d1\u5f0f\u68c0\u6d4b\u6a21\u578b\uff0c\u5e76\u5229\u7528Symbiosis\u534f\u8bae\u57282025\u5e748\u670810\u65e5\u81f310\u670810\u65e5\u671f\u95f4\u7684\u4e24\u4e2a\u6708\u8de8\u94fe\u4ea4\u6613\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc6\u522b\u5e76\u91cf\u5316\u6b64\u7c7b\u8de8\u94fe\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u89c4\u6a21\u4e0e\u6536\u76ca\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u51fa\u5927\u91cf\u8de8\u94fe\u4e09\u660e\u6cbb\u653b\u51fb\uff0c\u7d2f\u8ba1\u83b7\u5229\u8d85\u8fc7527\u4e07\u7f8e\u5143\uff0c\u5360\u6240\u5206\u6790\u65f6\u95f4\u6bb5\u5185\u603b\u8de8\u94fe\u4ea4\u6613\u91cf\u76841.28%\uff0c\u8bc1\u5b9e\u4e86\u8be5\u653b\u51fb\u65b9\u5f0f\u7684\u6709\u6548\u6027\u548c\u73b0\u5b9e\u5371\u5bb3\u6027\u3002", "conclusion": "\u8de8\u94fe\u6865\u534f\u8bae\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u6f0f\u6d1e\u53ef\u88ab\u7528\u4e8e\u5b9e\u65bd\u9ad8\u6548\u7684\u4e09\u660e\u6cbb\u653b\u51fb\uff0c\u73b0\u6709MEV\u9632\u5fa1\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\uff1b\u9700\u91cd\u65b0\u8bbe\u8ba1\u8de8\u94fe\u6d88\u606f\u4f20\u9012\u673a\u5236\u6216\u5f15\u5165\u9690\u79c1\u4fdd\u62a4\u63aa\u65bd\u4ee5\u7f13\u89e3\u6b64\u7c7b\u98ce\u9669\u3002"}}
{"id": "2511.14966", "categories": ["cs.DC", "cs.MS", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.14966", "abs": "https://arxiv.org/abs/2511.14966", "authors": ["David L. Cole", "Jordan Jalving", "Jonah Langlieb", "Jesse D. Jenkins"], "title": "A Graph-Based, Distributed Memory, Modeling Abstraction for Optimization", "comment": "32 pages, 7 Figures", "summary": "We present a general, flexible modeling abstraction for building and working with distributed optimization problems called a RemoteOptiGraph. This abstraction extends the OptiGraph model in Plasmo.jl, where optimization problems are represented as hypergraphs with nodes that define modular subproblems (variables, constraints, and objectives) and edges that encode algebraic linking constraints between nodes. The RemoteOptiGraph allows OptiGraphs to be utilized in distributed memory environments through InterWorkerEdges, which manage linking constraints that span workers. This abstraction offers a unified approach for modeling optimization problems on distributed memory systems (avoiding bespoke modeling approaches), and provides a basis for developing general-purpose meta-algorithms that can exploit distributed memory structure such as Benders or Lagrangian decompositions. We implement this abstraction in the open-source package, Plasmo.jl and we illustrate how it can be used by solving a mixed integer capacity expansion model for the western United States containing over 12 million variables and constraints. The RemoteOptiGraph abstraction together with Benders decomposition performs 7.5 times faster than solving the same problem without decomposition.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 RemoteOptiGraph \u62bd\u8c61\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u73af\u5883\u4e2d\u6784\u5efa\u548c\u6c42\u89e3\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7 InterWorkerEdges \u7ba1\u7406\u8de8\u5de5\u4f5c\u8282\u70b9\u7684\u8026\u5408\u7ea6\u675f\uff0c\u5e76\u5728 Plasmo.jl \u4e2d\u5b9e\u73b0\uff0c\u7ed3\u5408 Benders \u5206\u89e3\u5728\u5927\u89c4\u6a21\u5bb9\u91cf\u6269\u5c55\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86 7.5 \u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u4f18\u5316\u5efa\u6a21\u65b9\u6cd5\u591a\u4e3a\u5b9a\u5236\u5316\uff0c\u7f3a\u4e4f\u7edf\u4e00\u3001\u7075\u6d3b\u7684\u62bd\u8c61\uff1b\u4f5c\u8005\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u901a\u7528\u5efa\u6a21\u6846\u67b6\uff0c\u4ee5\u652f\u6301\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u9ad8\u6548\u8868\u8fbe\u548c\u6c42\u89e3\u7ed3\u6784\u5316\u4f18\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51fa RemoteOptiGraph \u62bd\u8c61\uff0c\u6269\u5c55 Plasmo.jl \u4e2d\u7684 OptiGraph \u6a21\u578b\uff0c\u5f15\u5165 InterWorkerEdges \u6765\u5904\u7406\u8de8\u5de5\u4f5c\u8282\u70b9\u7684\u94fe\u63a5\u7ea6\u675f\uff0c\u4ece\u800c\u652f\u6301\u5206\u5e03\u5f0f\u5185\u5b58\u73af\u5883\u4e0b\u7684\u5efa\u6a21\u4e0e\u7b97\u6cd5\u5f00\u53d1\uff08\u5982 Benders \u6216\u62c9\u683c\u6717\u65e5\u5206\u89e3\uff09\u3002", "result": "\u5728\u5305\u542b\u8d85\u8fc7 1200 \u4e07\u4e2a\u53d8\u91cf\u548c\u7ea6\u675f\u7684\u7f8e\u56fd\u897f\u90e8\u6df7\u5408\u6574\u6570\u5bb9\u91cf\u6269\u5c55\u6a21\u578b\u4e0a\uff0c\u4f7f\u7528 RemoteOptiGraph \u4e0e Benders \u5206\u89e3\u76f8\u6bd4\u65e0\u5206\u89e3\u65b9\u6cd5\u63d0\u901f 7.5 \u500d\u3002", "conclusion": "RemoteOptiGraph \u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u4e14\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u5efa\u6a21\u62bd\u8c61\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u95ee\u9898\u7684\u6c42\u89e3\u6548\u7387\uff0c\u5e76\u4e3a\u901a\u7528\u5206\u5e03\u5f0f\u5143\u7b97\u6cd5\u7684\u5f00\u53d1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.15557", "categories": ["cs.DB", "cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.15557", "abs": "https://arxiv.org/abs/2511.15557", "authors": ["Selim Furkan Tekin", "Rajesh Bordawekar"], "title": "B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index", "comment": null, "summary": "Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u57fa\u4e8e\u78c1\u76d8\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u7d22\u5f15\u7ed3\u6784 B+ANN\uff0c\u901a\u8fc7\u5c06\u8bed\u4e49\u76f8\u4f3c\u7684\u6570\u636e\u5206\u5757\u5e76\u7ed3\u5408\u6539\u8fdb\u7684 B+ \u6811\u7ec4\u7ec7\u65b9\u5f0f\uff0c\u5728\u5185\u5b58\u4e0e\u78c1\u76d8\u4e2d\u9ad8\u6548\u5b58\u50a8\u548c\u68c0\u7d22\u5411\u91cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u51c6\u786e\u7387\uff08Recall\uff09\u3001\u541e\u5410\u91cf\uff08QPS\uff09\uff0c\u964d\u4f4e\u4e86\u7f13\u5b58\u7f3a\u5931\u7387\u548c\u5185\u5b58\u5360\u7528\uff0c\u5e76\u652f\u6301 HNSW \u7b49\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7684\u4e0d\u76f8\u4f3c\u6027\u67e5\u8be2\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u5411\u91cf\u6570\u636e\u5e93\u5e7f\u6cdb\u91c7\u7528 HNSW \u7b97\u6cd5\uff0c\u4f46\u5176\u5b58\u5728\u5185\u5b58\u4f9d\u8d56\u5f3a\u3001\u7f13\u5b58\u6548\u7387\u4f4e\u3001\u8ba1\u7b97\u7c92\u5ea6\u7ec6\u5bfc\u81f4\u52a0\u901f\u53d7\u9650\u3001\u4ec5\u652f\u6301\u76f8\u4f3c\u6027\u67e5\u8be2\u7b49\u95ee\u9898\u3002\u4e3a\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u517c\u987e\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u529f\u80fd\u6269\u5c55\u6027\u7684\u65b0\u578b\u78c1\u76d8\u53cb\u597d\u578b ANN \u7d22\u5f15\u3002", "method": "B+ANN \u9996\u5148\u5c06\u8f93\u5165\u5411\u91cf\u5212\u5206\u4e3a\u8bed\u4e49\u76f8\u8fd1\u7684\u6570\u636e\u5757\uff0c\u7136\u540e\u6784\u5efa\u4e00\u79cd\u53d8\u4f53 B+ \u6811\u7ed3\u6784\uff0c\u5b9e\u73b0\u6570\u636e\u5757\u5728\u5185\u5b58\u4e0e\u78c1\u76d8\u4e0a\u7684\u7edf\u4e00\u7ba1\u7406\uff0c\u5e76\u652f\u6301\u6df7\u5408\u8fb9\u904d\u5386\u4e0e\u5757\u904d\u5386\u7684\u5185\u5b58\u5185\u68c0\u7d22\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4 HNSW\uff0cB+ANN \u5728 Recall \u548c QPS \u4e0a\u5747\u6709\u63d0\u5347\uff1b\u76f8\u6bd4 DiskANN\uff0c\u5185\u5b58\u6d88\u8017\u548c\u78c1\u76d8\u6784\u5efa\u65f6\u95f4\u51cf\u5c11 24 \u500d\uff0c\u7f13\u5b58\u672a\u547d\u4e2d\u7387\u964d\u4f4e 19.23%\uff0c\u540c\u65f6\u9996\u6b21\u652f\u6301\u4e0d\u76f8\u4f3c\u6027\u67e5\u8be2\u3002", "conclusion": "B+ANN \u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u529f\u80fd\u66f4\u5168\u9762\u7684\u78c1\u76d8\u578b ANN \u7d22\u5f15\u7ed3\u6784\uff0c\u6709\u6548\u89e3\u51b3\u4e86 HNSW \u7684\u591a\u9879\u5c40\u9650\uff0c\u5728\u6027\u80fd\u3001\u8d44\u6e90\u5229\u7528\u548c\u67e5\u8be2\u80fd\u529b\u65b9\u9762\u5747\u53d6\u5f97\u663e\u8457\u8fdb\u6b65\u3002"}}
{"id": "2511.14825", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14825", "abs": "https://arxiv.org/abs/2511.14825", "authors": ["Alexandre-Xavier Labont\u00e9-Lamoureux", "Simon Boyer"], "title": "Automatic Pipeline Provisioning", "comment": null, "summary": "The goal of this paper is to explore the benefits of automatic pipeline provisioning and identify how it can be applied. Automatic pipeline provisioning can be defined as a process of quickly deploying a pipeline for a software engineering project. This research will focus on CI pipelines, although the outcomes of this approach on CD pipelines will likely be similar.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u4f18\u52bf\u53ca\u5176\u5728CI\uff08\u6301\u7eed\u96c6\u6210\uff09\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u597d\u5904\uff0c\u5e76\u660e\u786e\u5176\u9002\u7528\u65b9\u5f0f\uff0c\u5c24\u5176\u5173\u6ce8CI\u6d41\u6c34\u7ebf\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u4e3a\u5feb\u901f\u90e8\u7f72\u8f6f\u4ef6\u5de5\u7a0b\u9879\u76ee\u6d41\u6c34\u7ebf\u7684\u8fc7\u7a0b\uff0c\u5bf9CI\u6d41\u6c34\u7ebf\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5c1a\u672a\u63d0\u4f9b\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u9884\u671f\u8be5\u65b9\u6cd5\u5bf9CD\uff08\u6301\u7eed\u4ea4\u4ed8\uff09\u6d41\u6c34\u7ebf\u540c\u6837\u9002\u7528\u3002", "conclusion": "\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u6709\u671b\u63d0\u5347CI/CD\u6d41\u7a0b\u7684\u6548\u7387\u548c\u90e8\u7f72\u901f\u5ea6\u3002"}}
{"id": "2511.15585", "categories": ["cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15585", "abs": "https://arxiv.org/abs/2511.15585", "authors": ["Eugene Wu", "Yiru Chen", "Haneen Mohammed", "Zezhou Huang"], "title": "A Decade of Systems for Human Data Interaction", "comment": null, "summary": "Human-data interaction (HDI) presents fundamentally different challenges from traditional data management. HDI systems must meet latency, correctness, and consistency needs that stem from usability rather than query semantics; failing to meet these expectations breaks the user experience. Moreover, interfaces and systems are tightly coupled; neither can easily be optimized in isolation, and effective solutions demand their co-design. This dependence also presents a research opportunity: rather than adapt systems to interface demands, systems innovations and database theory can also inspire new interaction and visualization designs. We survey a decade of our lab's work that embraces this coupling and argue that HDI systems are the foundation for reliable, interactive, AI-driven applications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4eba\u4e0e\u6570\u636e\u4ea4\u4e92\uff08HDI\uff09\u7cfb\u7edf\u5728\u5ef6\u8fdf\u3001\u6b63\u786e\u6027\u548c\u4e00\u81f4\u6027\u65b9\u9762\u4e0d\u540c\u4e8e\u4f20\u7edf\u6570\u636e\u7ba1\u7406\u7684\u72ec\u7279\u6311\u6218\uff0c\u5f3a\u8c03\u754c\u9762\u4e0e\u7cfb\u7edf\u7684\u7d27\u5bc6\u8026\u5408\u9700\u534f\u540c\u8bbe\u8ba1\uff0c\u5e76\u6307\u51fa\u8fd9\u79cd\u8026\u5408\u4e3a\u6570\u636e\u5e93\u6280\u672f\u521b\u65b0\u548c\u65b0\u578b\u4ea4\u4e92\u53ef\u89c6\u5316\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7814\u7a76\u673a\u9047\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\u65e0\u6cd5\u6ee1\u8db3\u4eba\u4e0e\u6570\u636e\u4ea4\u4e92\u573a\u666f\u4e2d\u7531\u7528\u6237\u4f53\u9a8c\u9a71\u52a8\u7684\u5ef6\u8fdf\u3001\u6b63\u786e\u6027\u548c\u4e00\u81f4\u6027\u9700\u6c42\uff0c\u4e14\u754c\u9762\u4e0e\u7cfb\u7edf\u9ad8\u5ea6\u8026\u5408\uff0c\u9700\u6574\u4f53\u4f18\u5316\u3002", "method": "\u7efc\u8ff0\u4f5c\u8005\u5b9e\u9a8c\u5ba4\u5341\u5e74\u6765\u7684\u7814\u7a76\u6210\u679c\uff0c\u5f3a\u8c03\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u754c\u9762\u4e0e\u7cfb\u7edf\u6765\u5e94\u5bf9HDI\u6311\u6218\uff0c\u5e76\u63a2\u7d22\u6570\u636e\u5e93\u7406\u8bba\u5bf9\u4ea4\u4e92\u4e0e\u53ef\u89c6\u5316\u8bbe\u8ba1\u7684\u542f\u53d1\u3002", "result": "\u5c55\u793a\u4e86HDI\u7cfb\u7edf\u5728\u652f\u6301\u53ef\u9760\u3001\u4ea4\u4e92\u5f0f\u3001AI\u9a71\u52a8\u5e94\u7528\u65b9\u9762\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u7cfb\u7edf\u521b\u65b0\u53ef\u53cd\u5411\u63a8\u52a8\u4ea4\u4e92\u8bbe\u8ba1\u7684\u53d1\u5c55\u3002", "conclusion": "HDI\u7cfb\u7edf\u662f\u6784\u5efa\u53ef\u9760\u3001\u4ea4\u4e92\u5f0f\u3001AI\u9a71\u52a8\u5e94\u7528\u7684\u57fa\u7840\uff0c\u5176\u7814\u7a76\u5e94\u91cd\u89c6\u7cfb\u7edf\u4e0e\u754c\u9762\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5e76\u5229\u7528\u6570\u636e\u5e93\u7406\u8bba\u6fc0\u53d1\u65b0\u7684\u4ea4\u4e92\u8303\u5f0f\u3002"}}
{"id": "2511.15503", "categories": ["cs.AR", "cs.DC", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.15503", "abs": "https://arxiv.org/abs/2511.15503", "authors": ["Peiming Yang", "Sankeerth Durvasula", "Ivan Fernandez", "Mohammad Sadrosadati", "Onur Mutlu", "Gennady Pekhimenko", "Christina Giannoula"], "title": "A Tensor Compiler for Processing-In-Memory Architectures", "comment": null, "summary": "Processing-In-Memory (PIM) devices integrated with high-performance Host processors (e.g., GPUs) can accelerate memory-intensive kernels in Machine Learning (ML) models, including Large Language Models (LLMs), by leveraging high memory bandwidth at PIM cores. However, Host processors and PIM cores require different data layouts: Hosts need consecutive elements distributed across DRAM banks, while PIM cores need them within local banks. This necessitates data rearrangements in ML kernel execution that pose significant performance and programmability challenges, further exacerbated by the need to support diverse PIM backends. Current compilation approaches lack systematic optimization for diverse ML kernels across multiple PIM backends and may largely ignore data rearrangements during compute code optimization. We demonstrate that data rearrangements and compute code optimization are interdependent, and need to be jointly optimized during the tuning process. To address this, we design DCC, the first data-centric ML compiler for PIM systems that jointly co-optimizes data rearrangements and compute code in a unified tuning process. DCC integrates a multi-layer PIM abstraction that enables various data distribution and processing strategies on different PIM backends. DCC enables effective co-optimization by mapping data partitioning strategies to compute loop partitions, applying PIM-specific code optimizations and leveraging a fast and accurate performance prediction model to select optimal configurations. Our evaluations in various individual ML kernels demonstrate that DCC achieves up to 7.68x speedup (2.7x average) on HBM-PIM and up to 13.17x speedup (5.75x average) on AttAcc PIM backend over GPU-only execution. In end-to-end LLM inference, DCC on AttAcc accelerates GPT-3 and LLaMA-2 by up to 7.71x (4.88x average) over GPU.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDCC\uff0c\u9996\u4e2a\u9762\u5411PIM\u7cfb\u7edf\u7684\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u673a\u5668\u5b66\u4e60\u7f16\u8bd1\u5668\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6570\u636e\u91cd\u6392\u4e0e\u8ba1\u7b97\u4ee3\u7801\uff0c\u5728\u591a\u79cdPIM\u540e\u7aef\u4e0a\u663e\u8457\u52a0\u901fML\u5185\u6838\u548cLLM\u63a8\u7406\u3002", "motivation": "\u4e3b\u673a\u5904\u7406\u5668\uff08\u5982GPU\uff09\u4e0ePIM\u6838\u5fc3\u5bf9\u6570\u636e\u5e03\u5c40\u9700\u6c42\u4e0d\u540c\uff0c\u5bfc\u81f4ML\u5185\u6838\u6267\u884c\u4e2d\u9700\u9891\u7e41\u8fdb\u884c\u6570\u636e\u91cd\u6392\uff0c\u5e26\u6765\u6027\u80fd\u4e0e\u7f16\u7a0b\u6311\u6218\uff1b\u73b0\u6709\u7f16\u8bd1\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u591a\u6837\u5316PIM\u540e\u7aef\u4e0b\u6570\u636e\u91cd\u6392\u4e0e\u8ba1\u7b97\u4ee3\u7801\u7684\u8054\u5408\u4f18\u5316\u3002", "method": "\u8bbe\u8ba1DCC\u7f16\u8bd1\u5668\uff0c\u5f15\u5165\u591a\u5c42PIM\u62bd\u8c61\uff0c\u5c06\u6570\u636e\u5212\u5206\u7b56\u7565\u6620\u5c04\u5230\u8ba1\u7b97\u5faa\u73af\u5212\u5206\uff0c\u5e94\u7528PIM\u7279\u5b9a\u4ee3\u7801\u4f18\u5316\uff0c\u5e76\u7ed3\u5408\u5feb\u901f\u51c6\u786e\u7684\u6027\u80fd\u9884\u6d4b\u6a21\u578b\uff0c\u5728\u7edf\u4e00\u8c03\u4f18\u8fc7\u7a0b\u4e2d\u534f\u540c\u4f18\u5316\u6570\u636e\u91cd\u6392\u4e0e\u8ba1\u7b97\u3002", "result": "\u5728HBM-PIM\u548cAttAcc PIM\u540e\u7aef\u4e0a\uff0cDCC\u76f8\u6bd4\u7eafGPU\u6267\u884c\u5728\u5355\u4e2aML\u5185\u6838\u4e0a\u5206\u522b\u6700\u9ad8\u63d0\u901f7.68\u500d\u548c13.17\u500d\uff1b\u5728\u7aef\u5230\u7aefLLM\u63a8\u7406\u4e2d\uff0c\u5bf9GPT-3\u548cLLaMA-2\u6700\u9ad8\u63d0\u901f7.71\u500d\u3002", "conclusion": "DCC\u901a\u8fc7\u6570\u636e\u4e0e\u8ba1\u7b97\u7684\u8054\u5408\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86PIM\u7cfb\u7edf\u4e2d\u56e0\u6570\u636e\u5e03\u5c40\u5dee\u5f02\u5e26\u6765\u7684\u6027\u80fd\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86ML\u6a21\u578b\u5c24\u5176\u662fLLM\u5728\u5f02\u6784PIM\u67b6\u6784\u4e0a\u7684\u6267\u884c\u6548\u7387\u3002"}}
{"id": "2511.15361", "categories": ["cs.DC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.15361", "abs": "https://arxiv.org/abs/2511.15361", "authors": ["Preston Vander Vos", "Alberto Sonnino", "Giorgos Tsimos", "Philipp Jovanovic", "Lefteris Kokoris-Kogias"], "title": "BlueBottle: Fast and Robust Blockchains through Subsystem Specialization", "comment": null, "summary": "Blockchain consensus faces a trilemma of security, latency, and decentralization. High-throughput systems often require a reduction in decentralization or robustness against strong adversaries, while highly decentralized and secure systems tend to have lower performance. We present BlueBottle, a two-layer consensus architecture. The core layer, BB-Core, is an n=5f+1 protocol that trades some fault tolerance for a much lower finality latency with a medium-sized core validator set. Our experiments show that BB-Core reduces latency by 20-25% in comparison to Mysticeti. The guard layer, BB-Guard, provides decentralized timestamping, proactive misbehavior detection in BB-Core, and a synchronous recovery path. When it observes equivocations or liveness failures in the core -- while tolerating up to f<3n/5 faulty nodes in the primary layer -- guard validators disseminate evidence, agree on misbehaving parties for exclusion or slashing, and either restart the core protocol (for liveness violations) or select a canonical fork (for safety violations). Together, these layers enable optimistic sub-second finality at high throughput while maintaining strong safety and liveness under a mild synchrony assumption.", "AI": {"tldr": "BlueBottle \u662f\u4e00\u79cd\u53cc\u5c42\u533a\u5757\u94fe\u5171\u8bc6\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u5f3a\u5b89\u5168\u6027\u548c\u6d3b\u8dc3\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u541e\u5410\u91cf\u548c\u4e9a\u79d2\u7ea7\u786e\u8ba4\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u533a\u5757\u94fe\u5171\u8bc6\u4e2d\u7684\u4e09\u96be\u56f0\u5883\uff08\u5b89\u5168\u6027\u3001\u5ef6\u8fdf\u3001\u53bb\u4e2d\u5fc3\u5316\uff09\uff0c\u5728\u4e0d\u663e\u8457\u727a\u7272\u53bb\u4e2d\u5fc3\u5316\u6216\u5b89\u5168\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51fa BlueBottle \u67b6\u6784\uff1a\u6838\u5fc3\u5c42 BB-Core \u91c7\u7528 n=5f+1 \u534f\u8bae\uff0c\u4ee5\u9002\u5ea6\u964d\u4f4e\u5bb9\u9519\u80fd\u529b\u6362\u53d6\u66f4\u4f4e\u7684\u786e\u8ba4\u5ef6\u8fdf\uff1b\u5b88\u62a4\u5c42 BB-Guard \u63d0\u4f9b\u53bb\u4e2d\u5fc3\u5316\u65f6\u95f4\u6233\u3001\u4e3b\u52a8\u68c0\u6d4b\u6838\u5fc3\u5c42\u5f02\u5e38\u884c\u4e3a\uff0c\u5e76\u5728\u53d1\u751f\u5b89\u5168\u6216\u6d3b\u8dc3\u6027\u6545\u969c\u65f6\u8fdb\u884c\u6062\u590d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBB-Core \u76f8\u8f83 Mysticeti \u964d\u4f4e\u5ef6\u8fdf 20\u201325%\uff0c\u6574\u4f53\u7cfb\u7edf\u5728\u6e29\u548c\u540c\u6b65\u5047\u8bbe\u4e0b\u5b9e\u73b0\u9ad8\u541e\u5410\u4e0e\u4e9a\u79d2\u7ea7\u6700\u7ec8\u6027\u3002", "conclusion": "BlueBottle \u901a\u8fc7\u53cc\u5c42\u8bbe\u8ba1\u6709\u6548\u5e73\u8861\u4e86\u533a\u5757\u94fe\u5171\u8bc6\u7684\u4e09\u96be\u95ee\u9898\uff0c\u5728\u4fdd\u969c\u5f3a\u5b89\u5168\u4e0e\u6d3b\u8dc3\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2511.14967", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14967", "abs": "https://arxiv.org/abs/2511.14967", "authors": ["Basel Shbita", "Farhan Ahmed", "Chad DeLuca"], "title": "MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation", "comment": null, "summary": "Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MermaidSeqBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210Mermaid\u5e8f\u5217\u56fe\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b132\u4e2a\u4eba\u5de5\u9a8c\u8bc1\u4e0eLLM\u6269\u5c55\u7684\u6837\u672c\uff0c\u5e76\u91c7\u7528\u7ec6\u7c92\u5ea6\u6307\u6807\u548cLLM-as-a-judge\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30LLM\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210\u7ed3\u6784\u5316\u56fe\u8868\uff08\u5982Mermaid\u5e8f\u5217\u56fe\uff09\u4efb\u52a1\u4e2d\u6b63\u786e\u6027\u7684\u57fa\u51c6\uff0c\u9650\u5236\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b132\u4e2a\u6837\u672c\u7684\u57fa\u51c6\u6570\u636e\u96c6MermaidSeqBench\uff0c\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u3001\u4e0a\u4e0b\u6587\u63d0\u793aLLM\u751f\u6210\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u53d8\u4f53\u6269\u589e\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\u6784\u5efa\uff1b\u5e76\u4f7f\u7528LLM-as-a-judge\u6a21\u578b\u5bf9\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u6fc0\u6d3b\u5904\u7406\u3001\u9519\u8bef\u5904\u7406\u548c\u5b9e\u7528\u6027\u7b49\u7ec6\u7c92\u5ea6\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5bf9\u591a\u4e2a\u524d\u6cbfLLM\u7684\u521d\u6b65\u8bc4\u4f30\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u548c\u8bc4\u4f30\u6a21\u5f0f\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u80fd\u529b\u5dee\u8ddd\uff0c\u9a8c\u8bc1\u4e86\u8be5\u57fa\u51c6\u7684\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "MermaidSeqBench\u4e3a\u7ed3\u6784\u5316\u56fe\u8868\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u5e76\u63a8\u52a8\u66f4\u4e25\u683c\u3001\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u65b9\u6cd5\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.15007", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15007", "abs": "https://arxiv.org/abs/2511.15007", "authors": ["Shehan I Pranto", "Brett Fassler", "Md Rafi Islam", "Ashley Schenkel", "Larry W Hawk", "Edward Sazonov"], "title": "FRIENDS GUI: A graphical user interface for data collection and visualization of vaping behavior from a passive vaping monitor", "comment": null, "summary": "Understanding puffing topography (PT), which includes puff duration, intra puff interval, and puff count per session, is critical for evaluating Electronic Nicotine Delivery Systems (ENDS) use, toxicant exposure, and informing regulatory decisions. We developed FRIENDS (Flexible Robust Instrumentation of ENDS), an open-source device that records puffing and touch events of ENDS by attaching to it. This paper introduces the FRIENDS GUI that improves accessibility and interpretability of data collected by FRIENDS. The GUI is a Python-based open-source tool that extracts, decodes, and visualizes 24-hour puffing data from the FRIENDS device. Validation using 24-hour experimental data confirmed accurate timestamp conversion, reliable event decoding, and effective behavioral visualization. The software is freely available on GitHub for public use.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86FRIENDS GUI\uff0c\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u7528\u4e8e\u63d0\u53d6\u3001\u89e3\u7801\u548c\u53ef\u89c6\u5316\u7535\u5b50\u5c3c\u53e4\u4e01\u4f20\u9001\u7cfb\u7edf\uff08ENDS\uff09\u768424\u5c0f\u65f6\u62bd\u5438\u6570\u636e\uff0c\u63d0\u5347\u4e86FRIENDS\u8bbe\u5907\u6240\u6536\u96c6\u6570\u636e\u7684\u53ef\u8bbf\u95ee\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4e3a\u63d0\u5347\u5bf9\u7535\u5b50\u5c3c\u53e4\u4e01\u4f20\u9001\u7cfb\u7edf\uff08ENDS\uff09\u4f7f\u7528\u884c\u4e3a\uff08\u5982\u62bd\u5438\u6301\u7eed\u65f6\u95f4\u3001\u62bd\u5438\u95f4\u9694\u548c\u6bcf\u6b21\u4f7f\u7528\u62bd\u5438\u6b21\u6570\uff09\u7684\u7406\u89e3\uff0c\u4ee5\u8bc4\u4f30\u5176\u4f7f\u7528\u6a21\u5f0f\u3001\u6709\u5bb3\u7269\u66b4\u9732\u6c34\u5e73\u5e76\u652f\u6301\u76d1\u7ba1\u51b3\u7b56\u3002", "method": "\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u540d\u4e3aFRIENDS GUI\u7684\u5f00\u6e90Python\u5de5\u5177\uff0c\u7528\u4e8e\u5904\u7406FRIENDS\u8bbe\u5907\u8bb0\u5f55\u7684\u62bd\u5438\u4e0e\u89e6\u6478\u4e8b\u4ef6\u6570\u636e\uff0c\u5b9e\u73b0\u6570\u636e\u7684\u63d0\u53d6\u3001\u89e3\u7801\u548c\u53ef\u89c6\u5316\u3002", "result": "\u901a\u8fc724\u5c0f\u65f6\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\uff0c\u8be5GUI\u80fd\u51c6\u786e\u8f6c\u6362\u65f6\u95f4\u6233\u3001\u53ef\u9760\u89e3\u7801\u4e8b\u4ef6\uff0c\u5e76\u6709\u6548\u53ef\u89c6\u5316\u7528\u6237\u884c\u4e3a\uff1b\u8f6f\u4ef6\u5df2\u5728GitHub\u4e0a\u516c\u5f00\u53d1\u5e03\u3002", "conclusion": "FRIENDS GUI\u663e\u8457\u63d0\u9ad8\u4e86ENDS\u62bd\u5438\u62d3\u6251\u6570\u636e\u7684\u53ef\u7528\u6027\u548c\u89e3\u8bfb\u6548\u7387\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u76d1\u7ba1\u673a\u6784\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2511.15168", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15168", "abs": "https://arxiv.org/abs/2511.15168", "authors": ["Nguyen-Khang Le", "Nguyen Hiep", "Minh Nguyen", "Son Luu", "Trung Vo", "Quan Bui", "Nomura Shoshin", "Le-Minh Nguyen"], "title": "Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework", "comment": "Published in the Proceedings of KSE 2025", "summary": "Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u9ad8\u8d28\u91cf Selenium \u8868\u5355\u4ea4\u4e92\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b0\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u5408\u6210\u4e0e\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5e76\u5728\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u811a\u672c\u53ef\u6267\u884c\u6027\u548c\u5b57\u6bb5\u8986\u76d6\u7387\u7b49\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728 Web \u8868\u5355\u4ea4\u4e92\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u8868\u73b0\u7684\u516c\u5f00\u57fa\u51c6\u548c\u6570\u636e\u96c6\uff0c\u4e14\u8be5\u4efb\u52a1\u5728 LLM \u7814\u7a76\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6784\u5efa\u5305\u542b\u5408\u6210\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u591a\u6837\u5316\u8868\u5355\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30 LLM\uff1b\u5b9a\u4e49\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u811a\u672c\u53ef\u6267\u884c\u6027\u53ca\u8f93\u5165\u5b57\u6bb5\u8986\u76d6\u7387\u7b49\u8bc4\u4f30\u6307\u6807\uff1b\u8bad\u7ec3 LLM \u751f\u6210\u7b26\u5408\u8981\u6c42\u7684 Selenium \u6d4b\u8bd5\u811a\u672c\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u5305\u62ec GPT-4o \u5728\u5185\u7684\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u57fa\u4e8e LLM \u7684 Web \u81ea\u52a8\u5316\u6d4b\u8bd5\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u7528\u4e8e\u540e\u7eed\u7814\u7a76\u7684\u6570\u636e\u8d44\u6e90\u548c\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2511.15229", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15229", "abs": "https://arxiv.org/abs/2511.15229", "authors": ["Bashar Abdallah", "Martyna E. Wojciechowska", "Gustavo Santos", "Edmand Yu", "Maxime Lamothe", "Alain Abran", "Mohammad Hamdaqa"], "title": "From Code Smells to Best Practices: Tackling Resource Leaks in PyTorch, TensorFlow, and Keras", "comment": null, "summary": "Much of the existing ML research focuses on model performance metrics, leaving limited attention to the long-term sustainability and resource efficiency of ML applications. While high performance is essential, ensuring efficient resource management is equally critical for robust deployment. This study addresses this gap by systematically identifying code smells that lead to resource leaks in ML applications. We conducted an empirical investigation of developer discussions and real-world code snippets from PyTorch, TensorFlow, and Keras. The analysis identified 30 PyTorch-related smells and 16 TensorFlow/Keras smells linked to resource leaks. These smells were categorized in two ways: (1) based on their root causes, and (2) as general ML smells with framework-specific characteristics. For each smell, we derived at least one best practice, resulting in 50 recommended coding patterns aimed at reducing resource leakage and improving efficiency. To ensure the validity of our findings, we employed a three-phase validation process involving independent analysis by three authors followed by consensus discussions. This is the first comprehensive study to examine resource-leak-inducing code smells across major ML frameworks and to present actionable best practices for mitigating them. The contributions support developers in building more efficient and sustainable ML applications and offer a structured view of the underlying causes of resource leaks.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u8bc6\u522b\u4e86PyTorch\u3001TensorFlow\u548cKeras\u4e2d\u5bfc\u81f4\u8d44\u6e90\u6cc4\u6f0f\u7684\u4ee3\u7801\u574f\u5473\u9053\uff0c\u63d0\u51fa\u4e8650\u79cd\u63a8\u8350\u7f16\u7801\u5b9e\u8df5\uff0c\u4ee5\u63d0\u5347\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u8d44\u6e90\u6548\u7387\u4e0e\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u7814\u7a76\u591a\u5173\u6ce8\u6a21\u578b\u6027\u80fd\u6307\u6807\uff0c\u5ffd\u89c6\u4e86\u957f\u671f\u53ef\u6301\u7eed\u6027\u548c\u8d44\u6e90\u6548\u7387\uff1b\u9ad8\u6548\u8d44\u6e90\u7ba1\u7406\u5bf9\u7a33\u5065\u90e8\u7f72\u540c\u6837\u5173\u952e\uff0c\u56e0\u6b64\u9700\u7cfb\u7edf\u8bc6\u522b\u5e76\u89e3\u51b3ML\u5e94\u7528\u4e2d\u7684\u8d44\u6e90\u6cc4\u6f0f\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u5f00\u53d1\u8005\u8ba8\u8bba\u548c\u771f\u5b9e\u4ee3\u7801\u7247\u6bb5\uff0c\u8bc6\u522bPyTorch\u3001TensorFlow\u548cKeras\u4e2d\u7684\u8d44\u6e90\u6cc4\u6f0f\u76f8\u5173\u4ee3\u7801\u574f\u5473\u9053\uff0c\u5e76\u57fa\u4e8e\u6839\u672c\u539f\u56e0\u548c\u6846\u67b6\u7279\u6027\u8fdb\u884c\u5206\u7c7b\uff1b\u4e3a\u6bcf\u79cd\u574f\u5473\u9053\u63d0\u70bc\u6700\u4f73\u5b9e\u8df5\uff0c\u5e76\u901a\u8fc7\u4e09\u9636\u6bb5\u9a8c\u8bc1\u6d41\u7a0b\u786e\u4fdd\u7ed3\u679c\u6709\u6548\u6027\u3002", "result": "\u8bc6\u522b\u51fa30\u79cdPyTorch\u76f8\u5173\u548c16\u79cdTensorFlow/Keras\u76f8\u5173\u7684\u8d44\u6e90\u6cc4\u6f0f\u4ee3\u7801\u574f\u5473\u9053\uff0c\u5f52\u7eb3\u51fa50\u9879\u63a8\u8350\u7f16\u7801\u6a21\u5f0f\uff0c\u5e76\u9996\u6b21\u63d0\u4f9b\u8de8\u4e3b\u6d41ML\u6846\u67b6\u7684\u8d44\u6e90\u6cc4\u6f0f\u6210\u56e0\u7ed3\u6784\u5316\u89c6\u56fe\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86ML\u5e94\u7528\u8d44\u6e90\u6548\u7387\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u5f00\u53d1\u8005\u6784\u5efa\u66f4\u9ad8\u6548\u3001\u53ef\u6301\u7eed\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6700\u4f73\u5b9e\u8df5\u548c\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2511.15257", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15257", "abs": "https://arxiv.org/abs/2511.15257", "authors": ["Hiep Hong Trinh", "Federico Ciccozzi", "Abu Naser Masud", "Marjan Sirjani", "Mikael Sj\u00f6din"], "title": "M, Toolchain and Language for Reusable Model Compilation", "comment": null, "summary": "Complex software-driven systems often interleave distributed, concurrent computation processes with physical interactions with the environment. Developing these systems more efficiently and safely can be achieved by employing actionable, software-based models. From a high-level system model, engineers often need to derive multiple specialized models for different purposes, including simulation, deployment, and formal verification. Each of these target models usually rely on its own formalism, specification language, and execution platform. Traditionally, a compiler analyzes a program written in a programming language and generates executable code. In contrast, a model compiler processes a source model written in a modeling language and should ideally support the generation of multiple heterogeneous targets. However, most existing modeling languages are designed with a narrow focus, typically targeting only simulation or implementation. Multi-target compilation, when not considered during the language's early design, becomes significantly harder to achieve. In this paper, we introduce our initiative: a toolchain and modeling language called M, designed to support system modeling and multi-target compilation for model-driven engineering of complex, concurrent, and time-aware systems. M is a textual, grammar-driven language based on the actor model and extended with discrete-event scheduling semantics. It provides constructs for modeling system entities, message-based interactions, and time- or state-triggered reactions. From such models, M enables the systematic generation of diverse target artifacts while preserving semantic conformance to the original model. Moreover, M can serve as a middle language to which other modeling languages may anchor, thereby allowing them to benefit from its compilation framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a M \u7684\u5efa\u6a21\u8bed\u8a00\u548c\u5de5\u5177\u94fe\uff0c\u652f\u6301\u5bf9\u590d\u6742\u3001\u5e76\u53d1\u3001\u65f6\u95f4\u654f\u611f\u7cfb\u7edf\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u5b9e\u73b0\u9762\u5411\u591a\u79cd\u76ee\u6807\uff08\u5982\u4eff\u771f\u3001\u90e8\u7f72\u3001\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff09\u7684\u8bed\u4e49\u4e00\u81f4\u7684\u6a21\u578b\u7f16\u8bd1\u3002", "motivation": "\u73b0\u6709\u5efa\u6a21\u8bed\u8a00\u901a\u5e38\u53ea\u9488\u5bf9\u5355\u4e00\u7528\u9014\uff08\u5982\u4eff\u771f\u6216\u5b9e\u73b0\uff09\uff0c\u7f3a\u4e4f\u5bf9\u591a\u76ee\u6807\u7f16\u8bd1\u7684\u652f\u6301\uff1b\u82e5\u672a\u5728\u8bed\u8a00\u8bbe\u8ba1\u521d\u671f\u8003\u8651\u591a\u76ee\u6807\u7f16\u8bd1\uff0c\u540e\u671f\u5b9e\u73b0\u5c06\u6781\u4e3a\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u4ece\u6e90\u5934\u652f\u6301\u591a\u76ee\u6807\u751f\u6210\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f14\u5458\u6a21\u578b\uff08actor model\uff09\u5e76\u6269\u5c55\u79bb\u6563\u4e8b\u4ef6\u8c03\u5ea6\u8bed\u4e49\u7684\u6587\u672c\u5316\u3001\u8bed\u6cd5\u9a71\u52a8\u5efa\u6a21\u8bed\u8a00 M\uff1b\u8be5\u8bed\u8a00\u652f\u6301\u7cfb\u7edf\u5b9e\u4f53\u5efa\u6a21\u3001\u57fa\u4e8e\u6d88\u606f\u7684\u4ea4\u4e92\u4ee5\u53ca\u65f6\u95f4\u548c\u72b6\u6001\u89e6\u53d1\u7684\u53cd\u5e94\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u6784\u5efa\u591a\u76ee\u6807\u7f16\u8bd1\u5de5\u5177\u94fe\u3002", "result": "M \u80fd\u591f\u4ece\u7edf\u4e00\u7684\u9ad8\u5c42\u6a21\u578b\u7cfb\u7edf\u5730\u751f\u6210\u591a\u79cd\u76ee\u6807\u4ea7\u7269\uff08\u5982\u7528\u4e8e\u4eff\u771f\u3001\u90e8\u7f72\u6216\u9a8c\u8bc1\u7684\u4ee3\u7801\uff09\uff0c\u5e76\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e0e\u539f\u59cb\u6a21\u578b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\uff1b\u6b64\u5916\uff0cM \u8fd8\u53ef\u4f5c\u4e3a\u4e2d\u95f4\u8bed\u8a00\uff0c\u4f9b\u5176\u4ed6\u5efa\u6a21\u8bed\u8a00\u63a5\u5165\u5176\u7f16\u8bd1\u6846\u67b6\u3002", "conclusion": "M \u8bed\u8a00\u53ca\u5176\u5de5\u5177\u94fe\u4e3a\u590d\u6742\u5e76\u53d1\u7cfb\u7edf\u7684\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u8bed\u4e49\u4fdd\u771f\u7684\u591a\u76ee\u6807\u7f16\u8bd1\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5f00\u53d1\u6548\u7387\u4e0e\u5b89\u5168\u6027\u3002"}}
{"id": "2511.15293", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15293", "abs": "https://arxiv.org/abs/2511.15293", "authors": ["Jia Li", "Zhi Jin", "Kechi Zhang", "Huangzhao Zhang", "Jiaru Qian", "Tiankuo Zhao"], "title": "A Viable Paradigm of Software Automation: Iterative End-to-End Automated Software Development", "comment": null, "summary": "Software development automation is a long-term goal in software engineering. With the development of artificial intelligence (AI), more and more researchers are exploring approaches to software automation. They view AI systems as tools or assistants in software development, still requiring significant human involvement. Another initiative is ``vibe coding'', where AI systems write and repeatedly revise most (or even all) of the code. We foresee these two development paths will converge towards the same destination: AI systems participate in throughout the software development lifecycle, expanding boundaries of full-stack software development. In this paper, we present a vision of an iterative end-to-end automated software development paradigm AutoSW. It operates in an analyze-plan-implement-deliver loop, where AI systems as human partners become first-class actors, translating human intentions expressed in natural language into executable software. We explore a lightweight prototype across the paradigm and initially execute various representative cases. The results indicate that AutoSW can successfully deliver executable software, providing a feasible direction for truly end-to-end automated software development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u81ea\u52a8\u8f6f\u4ef6\u5f00\u53d1\u8303\u5f0f AutoSW\uff0c\u901a\u8fc7\u5206\u6790-\u89c4\u5212-\u5b9e\u73b0-\u4ea4\u4ed8\u7684\u95ed\u73af\u6d41\u7a0b\uff0c\u4f7f AI \u7cfb\u7edf\u4f5c\u4e3a\u4e3b\u8981\u53c2\u4e0e\u8005\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u4eba\u7c7b\u610f\u56fe\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u8f6f\u4ef6\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u81ea\u52a8\u5316\u4ecd\u9700\u5927\u91cf\u4eba\u5de5\u53c2\u4e0e\uff0c\u800c\u65b0\u5174\u7684\u201cvibe coding\u201d\u867d\u5f3a\u8c03 AI \u81ea\u52a8\u751f\u6210\u4e0e\u8fed\u4ee3\u4ee3\u7801\uff0c\u4f46\u5c1a\u672a\u5f62\u6210\u7cfb\u7edf\u5316\u8303\u5f0f\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u878d\u5408\u4e24\u8005\u4f18\u52bf\u3001\u5b9e\u73b0\u5168\u5468\u671f\u81ea\u52a8\u5316\u7684\u8f6f\u4ef6\u5f00\u53d1\u65b0\u8def\u5f84\u3002", "method": "\u63d0\u51fa AutoSW \u8303\u5f0f\uff0c\u6784\u5efa\u4e00\u4e2a\u5206\u6790-\u89c4\u5212-\u5b9e\u73b0-\u4ea4\u4ed8\u7684\u8fed\u4ee3\u95ed\u73af\uff0c\u8ba9 AI \u4f5c\u4e3a\u6838\u5fc3\u89d2\u8272\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u53ef\u8fd0\u884c\u8f6f\u4ef6\uff0c\u5e76\u5f00\u53d1\u8f7b\u91cf\u7ea7\u539f\u578b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u539f\u578b\u5728\u591a\u4e2a\u4ee3\u8868\u6027\u6848\u4f8b\u4e2d\u6210\u529f\u751f\u6210\u53ef\u6267\u884c\u8f6f\u4ef6\uff0c\u9a8c\u8bc1\u4e86\u8be5\u8303\u5f0f\u5728\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "AutoSW \u4e3a\u5b9e\u73b0\u771f\u6b63\u610f\u4e49\u4e0a\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u5411\uff0c\u9884\u793a AI \u5c06\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u626e\u6f14\u7b2c\u4e00\u7c7b\u53c2\u4e0e\u8005\u89d2\u8272\u3002"}}
{"id": "2511.15340", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15340", "abs": "https://arxiv.org/abs/2511.15340", "authors": ["Yi Peng", "Hans-Martin Heyn", "Jennifer Horkoff"], "title": "From Machine Learning Documentation to Requirements: Bridging Processes with Requirements Languages", "comment": "To be published in proceedings of the 26th International Conference on Product-Focused Software Process Improvement (PROFES 2025). All raw and processed data are available in online repository, see https://doi.org/10.6084/m9.figshare.28564058.v1", "summary": "In software engineering processes for machine learning (ML)-enabled systems, integrating and verifying ML components is a major challenge. A prerequisite is the specification of ML component requirements, including models and data, an area where traditional requirements engineering (RE) processes face new obstacles. An underexplored source of RE-relevant information in this context is ML documentation such as ModelCards and DataSheets. However, it is uncertain to what extent RE-relevant information can be extracted from these documents. This study first investigates the amount and nature of RE-relevant information in 20 publicly available ModelCards and DataSheets. We show that these documents contain a significant amount of potentially RE-relevant information. Next, we evaluate how effectively three established RE representations (EARS, Rupp's template, and Volere) can structure this knowledge into requirements. Our results demonstrate that there is a pathway to transform ML-specific knowledge into structured requirements, incorporating ML documentation in software engineering processes for ML systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5982\u4f55\u4eceModelCards\u548cDataSheets\u7b49\u673a\u5668\u5b66\u4e60\u6587\u6863\u4e2d\u63d0\u53d6\u4e0e\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e09\u79cdRE\u8868\u793a\u65b9\u6cd5\uff08EARS\u3001Rupp\u6a21\u677f\u548cVolere\uff09\u5728\u5c06\u8fd9\u4e9b\u4fe1\u606f\u7ed3\u6784\u5316\u4e3a\u9700\u6c42\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7ed3\u679c\u8868\u660e\u8fd9\u4e9b\u6587\u6863\u5305\u542b\u5927\u91cfRE\u76f8\u5173\u4fe1\u606f\uff0c\u4e14\u53ef\u6709\u6548\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\u3002", "motivation": "\u5728\u9762\u5411\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u4e2d\uff0c\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u6a21\u578b\u4e0e\u6570\u636e\u9700\u6c42\u7684\u89c4\u8303\u95ee\u9898\uff0c\u800cModelCards\u548cDataSheets\u7b49ML\u6587\u6863\u4f5c\u4e3a\u6f5c\u5728\u7684\u9700\u6c42\u4fe1\u606f\u6765\u6e90\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u9996\u5148\u5206\u679020\u4efd\u516c\u5f00\u7684ModelCards\u548cDataSheets\u4e2dRE\u76f8\u5173\u4fe1\u606f\u7684\u6570\u91cf\u4e0e\u6027\u8d28\uff1b\u968f\u540e\u4f7f\u7528EARS\u3001Rupp\u6a21\u677f\u548cVolere\u4e09\u79cd\u9700\u6c42\u8868\u793a\u65b9\u6cd5\u5bf9\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u7ed3\u6784\u5316\uff0c\u5e76\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "ML\u6587\u6863\u4e2d\u5305\u542b\u5927\u91cf\u6f5c\u5728\u7684RE\u76f8\u5173\u4fe1\u606f\uff0c\u4e14\u901a\u8fc7\u73b0\u6709RE\u8868\u793a\u65b9\u6cd5\u53ef\u6709\u6548\u5c06\u5176\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\u3002", "conclusion": "ML\u6587\u6863\uff08\u5982ModelCards\u548cDataSheets\uff09\u53ef\u4f5c\u4e3a\u9700\u6c42\u5de5\u7a0b\u7684\u91cd\u8981\u4fe1\u606f\u6e90\uff0c\u6709\u52a9\u4e8e\u5c06ML\u7279\u5b9a\u77e5\u8bc6\u6574\u5408\u8fdb\u9762\u5411ML\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2511.15403", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15403", "abs": "https://arxiv.org/abs/2511.15403", "authors": ["Isabel Amaral", "Alexandra Mendes", "Jos\u00e9 Campos"], "title": "MutDafny: A Mutation-Based Approach to Assess Dafny Specifications", "comment": null, "summary": "This paper explores the use of mutation testing to reveal weaknesses in formal specifications written in Dafny. In verification-aware programming languages, such as Dafny, despite their critical role, specifications are as prone to errors as implementations. Flaws in specs can result in formally verified programs that deviate from the intended behavior.\n  We present MutDafny, a tool that increases the reliability of Dafny specifications by automatically signaling potential weaknesses. Using a mutation testing approach, we introduce faults (mutations) into the code and rely on formal specifications for detecting them. If a program with a mutant verifies, this may indicate a weakness in the specification. We extensively analyze mutation operators from popular tools, identifying the ones applicable to Dafny. In addition, we synthesize new operators tailored for Dafny from bugfix commits in publicly available Dafny projects on GitHub. Drawing from both, we equipped our tool with a total of 32 mutation operators. We evaluate MutDafny's effectiveness and efficiency in a dataset of 794 real-world Dafny programs and we manually analyze a subset of the resulting undetected mutants, identifying five weak real-world specifications (on average, one at every 241 lines of code) that would benefit from strengthening.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMutDafny\u5de5\u5177\uff0c\u5229\u7528\u53d8\u5f02\u6d4b\u8bd5\u68c0\u6d4bDafny\u5f62\u5f0f\u5316\u89c4\u7ea6\u4e2d\u7684\u5f31\u70b9\uff0c\u901a\u8fc7\u5f15\u516532\u79cd\u53d8\u5f02\u7b97\u5b50\uff0c\u5728794\u4e2a\u771f\u5b9e\u7a0b\u5e8f\u4e2d\u53d1\u73b0\u591a\u4e2a\u5f31\u89c4\u7ea6\u3002", "motivation": "Dafny\u7b49\u9a8c\u8bc1\u611f\u77e5\u8bed\u8a00\u4e2d\u7684\u5f62\u5f0f\u5316\u89c4\u7ea6\u6613\u51fa\u9519\uff0c\u53ef\u80fd\u5bfc\u81f4\u201c\u5df2\u9a8c\u8bc1\u201d\u7a0b\u5e8f\u884c\u4e3a\u504f\u79bb\u9884\u671f\uff0c\u56e0\u6b64\u9700\u63d0\u9ad8\u89c4\u7ea6\u53ef\u9760\u6027\u3002", "method": "\u5f00\u53d1MutDafny\u5de5\u5177\uff0c\u91c7\u7528\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\uff1a\u5bf9\u4ee3\u7801\u5f15\u5165\u53d8\u5f02\uff0c\u82e5\u5e26\u53d8\u5f02\u7684\u7a0b\u5e8f\u4ecd\u80fd\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u5219\u8868\u660e\u89c4\u7ea6\u53ef\u80fd\u5b58\u5728\u5f31\u70b9\uff1b\u7ed3\u5408\u73b0\u6709\u53d8\u5f02\u7b97\u5b50\u4e0e\u4eceGitHub Dafny\u9879\u76eebug\u4fee\u590d\u63d0\u4ea4\u4e2d\u63d0\u70bc\u7684\u65b0\u7b97\u5b50\uff0c\u5171\u5b9e\u73b032\u79cd\u9002\u7528\u4e8eDafny\u7684\u53d8\u5f02\u7b97\u5b50\u3002", "result": "\u5728794\u4e2a\u771f\u5b9eDafny\u7a0b\u5e8f\u4e0a\u8bc4\u4f30MutDafny\uff0c\u624b\u52a8\u5206\u6790\u672a\u88ab\u68c0\u6d4b\u5230\u7684\u53d8\u5f02\u4f53\uff0c\u53d1\u73b05\u4e2a\u5f31\u89c4\u7ea6\uff08\u5e73\u5747\u6bcf241\u884c\u4ee3\u7801\u51fa\u73b01\u4e2a\uff09\uff0c\u8868\u660e\u8be5\u5de5\u5177\u80fd\u6709\u6548\u8bc6\u522b\u9700\u52a0\u5f3a\u7684\u89c4\u7ea6\u3002", "conclusion": "MutDafny\u80fd\u6709\u6548\u63d0\u5347Dafny\u5f62\u5f0f\u5316\u89c4\u7ea6\u7684\u8d28\u91cf\uff0c\u901a\u8fc7\u81ea\u52a8\u68c0\u6d4b\u6f5c\u5728\u5f31\u70b9\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u5f3a\u5316\u89c4\u7ea6\uff0c\u4ece\u800c\u589e\u5f3a\u9a8c\u8bc1\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2511.15589", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15589", "abs": "https://arxiv.org/abs/2511.15589", "authors": ["Qian Zhu", "Yuxuan Liu", "Ziyuan Zhu", "Shangqing Liu", "Lei Bu"], "title": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode", "comment": null, "summary": "Extended Berkeley Packet Filter (eBPF) allows developers to extend Linux kernel functionality without modifying its source code. To ensure system safety, an in-kernel safety checker, the verifier, enforces strict safety constraints (for example, a limited program size) on eBPF programs loaded into the kernel. These constraints, combined with eBPF's performance-critical use cases, make effective optimization essential. However, existing compilers (such as Clang) offer limited optimization support, and many semantics-preserving transformations are rejected by the verifier, which makes handcrafted optimization rule design both challenging and limited in effectiveness. Superoptimization overcomes the limitations of rule-based methods by automatically discovering optimal transformations, but its high computational cost limits scalability. To address this, we propose EPSO, a caching-based superoptimizer that discovers rewrite rules via offline superoptimization and reuses them to achieve high-quality optimizations with minimal runtime overhead. We evaluate EPSO on benchmarks from the Linux kernel and several eBPF-based projects, including Cilium, Katran, hXDP, Sysdig, Tetragon, and Tracee. EPSO discovers 795 rewrite rules and achieves up to 68.87 percent (average 24.37 percent) reduction in program size compared to Clang's output, outperforming the state-of-the-art BPF optimizer K2 on all benchmarks and Merlin on 92.68 percent of them. Additionally, EPSO reduces program runtime by an average of 6.60 percent, improving throughput and lowering latency in network applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEPSO\uff0c\u4e00\u79cd\u57fa\u4e8e\u7f13\u5b58\u7684eBPF\u8d85\u7ea7\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u79bb\u7ebf\u53d1\u73b0\u91cd\u5199\u89c4\u5219\u5e76\u5728\u8fd0\u884c\u65f6\u590d\u7528\uff0c\u663e\u8457\u51cf\u5c0f\u7a0b\u5e8f\u89c4\u6a21\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "eBPF\u7a0b\u5e8f\u53d7\u5185\u6838\u9a8c\u8bc1\u5668\u4e25\u683c\u9650\u5236\uff0c\u73b0\u6709\u7f16\u8bd1\u5668\uff08\u5982Clang\uff09\u4f18\u5316\u80fd\u529b\u6709\u9650\uff0c\u4e14\u8bb8\u591a\u8bed\u4e49\u4fdd\u6301\u7684\u53d8\u6362\u88ab\u9a8c\u8bc1\u5668\u62d2\u7edd\uff0c\u624b\u5de5\u4f18\u5316\u89c4\u5219\u8bbe\u8ba1\u56f0\u96be\u4e14\u6548\u679c\u6709\u9650\uff1b\u800c\u4f20\u7edf\u8d85\u7ea7\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u96be\u4ee5\u6269\u5c55\u3002", "method": "EPSO\u91c7\u7528\u7f13\u5b58\u673a\u5236\uff0c\u5148\u901a\u8fc7\u79bb\u7ebf\u8d85\u7ea7\u4f18\u5316\u53d1\u73b0\u6709\u6548\u7684\u91cd\u5199\u89c4\u5219\uff0c\u518d\u5728\u8fd0\u884c\u65f6\u590d\u7528\u8fd9\u4e9b\u89c4\u5219\u5bf9eBPF\u7a0b\u5e8f\u8fdb\u884c\u9ad8\u6548\u4f18\u5316\uff0c\u517c\u987e\u4f18\u5316\u8d28\u91cf\u548c\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "result": "\u5728Linux\u5185\u6838\u53ca\u591a\u4e2aeBPF\u9879\u76ee\uff08\u5982Cilium\u3001Katran\u7b49\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEPSO\u53d1\u73b0\u4e86795\u6761\u91cd\u5199\u89c4\u5219\uff0c\u76f8\u6bd4Clang\u5e73\u5747\u51cf\u5c1124.37%\u7684\u7a0b\u5e8f\u5927\u5c0f\uff08\u6700\u9ad8\u8fbe68.87%\uff09\uff0c\u4f18\u4e8e\u73b0\u6709\u4f18\u5316\u5668K2\u548cMerlin\uff0c\u5e76\u5e73\u5747\u964d\u4f4e6.60%\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "EPSO\u6709\u6548\u89e3\u51b3\u4e86eBPF\u7a0b\u5e8f\u4f18\u5316\u4e2d\u7684\u9a8c\u8bc1\u5668\u517c\u5bb9\u6027\u4e0e\u6027\u80fd\u95ee\u9898\uff0c\u5728\u7a0b\u5e8f\u89c4\u6a21\u548c\u8fd0\u884c\u6548\u7387\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
