{"id": "2511.04849", "categories": ["cs.SE", "cs.AI", "I.2.6; I.2.7; D.2.3"], "pdf": "https://arxiv.org/pdf/2511.04849", "abs": "https://arxiv.org/abs/2511.04849", "authors": ["Quang-Dung Nguyen", "Tri-Dung Tran", "Thanh-Hieu Chu", "Hoang-Loc Tran", "Xiangwei Cheng", "Dirk Slama"], "title": "Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach", "comment": "6 pages, 3 figures", "summary": "The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in\nthe automotive industry, where software now plays a pivotal role in defining\nvehicle functionality, enabling rapid innovation of modern vehicles. Developing\nSDV-specific applications demands advanced tools to streamline code generation\nand improve development efficiency. In recent years, general-purpose large\nlanguage models (LLMs) have demonstrated transformative potential across\ndomains. Still, restricted access to proprietary model architectures hinders\ntheir adaption to specific tasks like SDV code generation. In this study, we\npropose using prompts, a common and basic strategy to interact with LLMs and\nredirect their responses. Using only system prompts with an appropriate and\nefficient prompt structure designed using advanced prompt engineering\ntechniques, LLMs can be crafted without requiring a training session or access\nto their base design. This research investigates the extensive experiments on\ndifferent models by applying various prompting techniques, including bare\nmodels, using a benchmark specifically created to evaluate LLMs' performance in\ngenerating SDV code. The results reveal that the model with a few-shot\nprompting strategy outperforms the others in adjusting the LLM answers to match\nthe expected outcomes based on quantitative metrics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\uff08SDV\uff09\u4ee3\u7801\uff0c\u53d1\u73b0\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u5728\u65e0\u9700\u6a21\u578b\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u6700\u4f18\u3002", "motivation": "\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\uff08SDV\uff09\u7684\u5174\u8d77\u8981\u6c42\u9ad8\u6548\u5f00\u53d1\u4e13\u7528\u5e94\u7528\uff0c\u800c\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u67b6\u6784\u5c01\u95ed\u96be\u4ee5\u9002\u914dSDV\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5f15\u5bfc\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u63d0\u793a\u7ed3\u5408\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u5728\u4e0d\u8bbf\u95ee\u6a21\u578b\u5e95\u5c42\u67b6\u6784\u6216\u8fdb\u884c\u8bad\u7ec3\u7684\u524d\u63d0\u4e0b\uff0c\u5bf9\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u4f7f\u7528\u4e13\u4e3aSDV\u4ee3\u7801\u751f\u6210\u8bbe\u8ba1\u7684\u57fa\u51c6\u8bc4\u4f30\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528\u5c11\u6837\u672c\uff08few-shot\uff09\u63d0\u793a\u7b56\u7565\u7684\u6a21\u578b\u5728\u5b9a\u91cf\u6307\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u751f\u6210\u7b26\u5408\u9884\u671f\u7684SDV\u4ee3\u7801\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u7ed3\u6784\uff0c\u5c24\u5176\u662f\u5c11\u6837\u672c\u63d0\u793a\uff0c\u53ef\u6709\u6548\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u5b8c\u6210SDV\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0c\u4e14\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u6216\u8bbf\u95ee\u5176\u5185\u90e8\u7ed3\u6784\u3002"}}
{"id": "2511.04986", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04986", "abs": "https://arxiv.org/abs/2511.04986", "authors": ["Mohammadreza Saeidi", "Ethan Thoma", "Raula Gaikovina Kula", "Gema Rodr\u00edguez-P\u00e9rez"], "title": "What About Our Bug? A Study on the Responsiveness of NPM Package Maintainers", "comment": null, "summary": "Background: Widespread use of third-party libraries makes ecosystems like\nNode Package Manager (npm) critical to modern software development. However,\nthis interconnected chain of dependencies also creates challenges: bugs in one\nlibrary can propagate downstream, potentially impacting many other libraries\nthat rely on it. We hypothesize that maintainers may not always decide to fix a\nbug, especially if the maintainer decides it falls out of their responsibility\nwithin the chain of dependencies. Aims: To confirm this hypothesis, we\ninvestigate the responsiveness of 30,340 bug reports across 500 of the most\ndepended-upon npm packages. Method: We adopt a mixed-method approach to mine\nrepository issue data and perform qualitative open coding to analyze reasons\nbehind unaddressed bug reports. Results: Our findings show that maintainers are\ngenerally responsive, with a median project-level responsiveness of 70% (IQR:\n55%-89%), reflecting their commitment to support downstream developers.\nConclusions: We present a taxonomy of the reasons some bugs remain unresolved.\nThe taxonomy includes contribution practices, dependency constraints, and\nlibrary-specific standards as reasons for not being responsive. Understanding\nmaintainer behavior can inform practices that promote a more robust and\nresponsive open-source ecosystem that benefits the entire community.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86npm\u751f\u6001\u7cfb\u7edf\u4e2d500\u4e2a\u6700\u88ab\u4f9d\u8d56\u7684\u5305\u768430,340\u4efdbug\u62a5\u544a\uff0c\u53d1\u73b0\u7ef4\u62a4\u8005\u6574\u4f53\u54cd\u5e94\u7387\u8f83\u9ad8\uff08\u4e2d\u4f4d\u6570\u4e3a70%\uff09\uff0c\u4f46\u90e8\u5206bug\u672a\u88ab\u4fee\u590d\u7684\u539f\u56e0\u5305\u62ec\u8d21\u732e\u89c4\u8303\u3001\u4f9d\u8d56\u7ea6\u675f\u548c\u5e93\u7279\u5b9a\u6807\u51c6\u7b49\u56e0\u7d20\u3002", "motivation": "\u7b2c\u4e09\u65b9\u5e93\u7684\u5e7f\u6cdb\u4f7f\u7528\u4f7fnpm\u7b49\u751f\u6001\u7cfb\u7edf\u5bf9\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f9d\u8d56\u94fe\u4e2d\u7684bug\u53ef\u80fd\u5411\u4e0b\u4f20\u64ad\uff0c\u5f71\u54cd\u4f17\u591a\u9879\u76ee\u3002\u4f5c\u8005\u5047\u8bbe\u7ef4\u62a4\u8005\u672a\u5fc5\u603b\u4f1a\u4fee\u590dbug\uff0c\u5c24\u5176\u662f\u5f53\u4ed6\u4eec\u8ba4\u4e3a\u8be5\u95ee\u9898\u4e0d\u5728\u5176\u8d23\u4efb\u8303\u56f4\u5185\u65f6\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u6316\u6398\u4ed3\u5e93issue\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u5b9a\u6027\u5f00\u653e\u5f0f\u7f16\u7801\u5206\u6790\u672a\u5904\u7406bug\u62a5\u544a\u80cc\u540e\u7684\u539f\u56e0\u3002", "result": "\u7ef4\u62a4\u8005\u603b\u4f53\u54cd\u5e94\u79ef\u6781\uff0c\u9879\u76ee\u5c42\u9762\u7684\u4e2d\u4f4d\u54cd\u5e94\u7387\u4e3a70%\uff08\u56db\u5206\u4f4d\u8ddd\uff1a55%-89%\uff09\uff1b\u540c\u65f6\u5f52\u7eb3\u51fa\u82e5\u5e72\u5bfc\u81f4bug\u672a\u88ab\u4fee\u590d\u7684\u539f\u56e0\u7c7b\u522b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u672a\u4fee\u590dbug\u539f\u56e0\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u6db5\u76d6\u8d21\u732e\u5b9e\u8df5\u3001\u4f9d\u8d56\u7ea6\u675f\u548c\u5e93\u7279\u5b9a\u6807\u51c6\u7b49\u65b9\u9762\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u66f4\u7a33\u5065\u3001\u54cd\u5e94\u66f4\u53ca\u65f6\u7684\u5f00\u6e90\u751f\u6001\u3002"}}
{"id": "2511.05383", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.05383", "abs": "https://arxiv.org/abs/2511.05383", "authors": ["Elinor Thompson", "Tiantian He", "Anna Schroder", "Ahmed Abdulaal", "Alec Sargood", "Sonja Soskic", "Henry F. J. Tregidgo", "Daniel C. Alexander"], "title": "Connectomics Informed by Large Language Models", "comment": "35 pages, 10 figures", "summary": "Tractography is a unique method for mapping white matter connections in the\nbrain, but tractography algorithms suffer from an inherent trade-off between\nsensitivity and specificity that limits accuracy. Incorporating prior knowledge\nof white matter anatomy is an effective strategy for improving accuracy and has\nbeen successful for reducing false positives and false negatives in\nbundle-mapping protocols. However, it is challenging to scale this approach for\nconnectomics due to the difficulty in synthesising information relating to many\nthousands of possible connections. In this work, we develop and evaluate a\npipeline using large language models (LLMs) to generate quantitative priors for\nconnectomics, based on their knowledge of neuroanatomy. We benchmark our\napproach against an evaluation set derived from a gold-standard tractography\natlas, identifying prompting techniques to elicit accurate connectivity\ninformation from the LLMs. We further identify strategies for incorporating\nexternal knowledge sources into the pipeline, which can provide grounding for\nthe LLM and improve accuracy. Finally, we demonstrate how the LLM-derived\npriors can augment existing tractography filtering approaches by identifying\ntrue-positive connections to retain during the filtering process. We show that\nthese additional connections can improve the accuracy of a connectome-based\nmodel of pathology spread, which provides supporting evidence that the\nconnections preserved by the LLM are valid.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u5b9a\u91cf\u5148\u9a8c\u77e5\u8bc6\uff0c\u4ee5\u63d0\u5347\u8111\u8fde\u63a5\u7ec4\u5b66\u4e2d\u7ea4\u7ef4\u675f\u6210\u50cf\u7684\u51c6\u786e\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u5148\u9a8c\u5728\u4fdd\u7559\u771f\u5b9e\u8fde\u63a5\u548c\u6539\u8fdb\u75c5\u7406\u4f20\u64ad\u6a21\u578b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7ea4\u7ef4\u675f\u6210\u50cf\u7b97\u6cd5\u5728\u654f\u611f\u6027\u4e0e\u7279\u5f02\u6027\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6743\u8861\uff0c\u9650\u5236\u4e86\u5176\u51c6\u786e\u6027\uff1b\u867d\u7136\u5f15\u5165\u767d\u8d28\u89e3\u5256\u5148\u9a8c\u77e5\u8bc6\u53ef\u63d0\u5347\u51c6\u786e\u6027\uff0c\u4f46\u5728\u8fde\u63a5\u7ec4\u5b66\u4e2d\u96be\u4ee5\u6269\u5c55\u81f3\u6570\u5343\u79cd\u53ef\u80fd\u8fde\u63a5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6d41\u7a0b\uff0c\u5229\u7528\u5176\u795e\u7ecf\u89e3\u5256\u77e5\u8bc6\u751f\u6210\u8fde\u63a5\u7ec4\u5b66\u7684\u5b9a\u91cf\u5148\u9a8c\uff1b\u901a\u8fc7\u9ec4\u91d1\u6807\u51c6\u56fe\u8c31\u8bc4\u4f30\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u6e90\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\uff1b\u5c06LLM\u5148\u9a8c\u7528\u4e8e\u589e\u5f3a\u73b0\u6709\u7ea4\u7ef4\u675f\u8fc7\u6ee4\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLM\u80fd\u6709\u6548\u63d0\u4f9b\u51c6\u786e\u7684\u8fde\u63a5\u4fe1\u606f\uff1b\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff1bLLM\u4fdd\u7559\u7684\u771f\u5b9e\u9633\u6027\u8fde\u63a5\u63d0\u9ad8\u4e86\u57fa\u4e8e\u8fde\u63a5\u7ec4\u7684\u75c5\u7406\u4f20\u64ad\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u89e3\u5256\u5148\u9a8c\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u6709\u6548\u7684\u7b56\u7565\uff0c\u53ef\u663e\u8457\u63d0\u5347\u7ea4\u7ef4\u675f\u6210\u50cf\u5728\u8fde\u63a5\u7ec4\u5b66\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5bf9\u795e\u7ecf\u75be\u75c5\u5efa\u6a21\u5177\u6709\u6f5c\u5728\u4ef7\u503c\u3002"}}
{"id": "2511.05165", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05165", "abs": "https://arxiv.org/abs/2511.05165", "authors": ["Ahmad Hatahet", "Christoph Knieke", "Andreas Rausch"], "title": "Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model", "comment": null, "summary": "Software Architecture Descriptions (SADs) are essential for managing the\ninherent complexity of modern software systems. They enable high-level\narchitectural reasoning, guide design decisions, and facilitate effective\ncommunication among diverse stakeholders. However, in practice, SADs are often\nmissing, outdated, or poorly aligned with the system's actual implementation.\nConsequently, developers are compelled to derive architectural insights\ndirectly from source code-a time-intensive process that increases cognitive\nload, slows new developer onboarding, and contributes to the gradual\ndegradation of clarity over the system's lifetime. To address these issues, we\npropose a semi-automated generation of SADs from source code by integrating\nreverse engineering (RE) techniques with a Large Language Model (LLM). Our\napproach recovers both static and behavioral architectural views by extracting\na comprehensive component diagram, filtering architecturally significant\nelements (core components) via prompt engineering, and generating state machine\ndiagrams to model component behavior based on underlying code logic with\nfew-shots prompting. This resulting views representation offer a scalable and\nmaintainable alternative to traditional manual architectural documentation.\nThis methodology, demonstrated using C++ examples, highlights the potent\ncapability of LLMs to: 1) abstract the component diagram, thereby reducing the\nreliance on human expert involvement, and 2) accurately represent complex\nsoftware behaviors, especially when enriched with domain-specific knowledge\nthrough few-shot prompting. These findings suggest a viable path toward\nsignificantly reducing manual effort while enhancing system understanding and\nlong-term maintainability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u9006\u5411\u5de5\u7a0b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u534a\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u4ece\u6e90\u4ee3\u7801\u751f\u6210\u8f6f\u4ef6\u67b6\u6784\u63cf\u8ff0\uff08SAD\uff09\uff0c\u5305\u62ec\u9759\u6001\u7ec4\u4ef6\u56fe\u548c\u884c\u4e3a\u72b6\u6001\u673a\u56fe\uff0c\u4ee5\u51cf\u8f7b\u4eba\u5de5\u8d1f\u62c5\u5e76\u63d0\u5347\u7cfb\u7edf\u53ef\u7ef4\u62a4\u6027\u3002", "motivation": "\u5b9e\u9645\u4e2d\u8f6f\u4ef6\u67b6\u6784\u63cf\u8ff0\u5e38\u7f3a\u5931\u3001\u8fc7\u65f6\u6216\u4e0e\u5b9e\u73b0\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u5f00\u53d1\u8005\u9700\u8017\u8d39\u5927\u91cf\u65f6\u95f4\u4ece\u4ee3\u7801\u4e2d\u63a8\u5bfc\u67b6\u6784\u4fe1\u606f\uff0c\u589e\u52a0\u8ba4\u77e5\u8d1f\u62c5\u3001\u5ef6\u7f13\u65b0\u4eba\u4e0a\u624b\uff0c\u5e76\u968f\u65f6\u95f4\u63a8\u79fb\u964d\u4f4e\u7cfb\u7edf\u6e05\u6670\u5ea6\u3002", "method": "\u6574\u5408\u9006\u5411\u5de5\u7a0b\u6280\u672f\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u901a\u8fc7\u63d0\u53d6\u5b8c\u6574\u7ec4\u4ef6\u56fe\u3001\u5229\u7528\u63d0\u793a\u5de5\u7a0b\u7b5b\u9009\u6838\u5fc3\u67b6\u6784\u5143\u7d20\uff0c\u5e76\u57fa\u4e8e\u4ee3\u7801\u903b\u8f91\u4f7f\u7528\u5c11\u6837\u672c\u63d0\u793a\u751f\u6210\u72b6\u6001\u673a\u56fe\uff0c\u4ece\u800c\u6062\u590d\u9759\u6001\u4e0e\u884c\u4e3a\u67b6\u6784\u89c6\u56fe\u3002", "result": "\u8be5\u65b9\u6cd5\u5728C++\u793a\u4f8b\u4e2d\u6210\u529f\u5c55\u793a\u4e86LLM\u80fd\u6709\u6548\u62bd\u8c61\u7ec4\u4ef6\u56fe\u5e76\u51c6\u786e\u8868\u8fbe\u590d\u6742\u884c\u4e3a\uff0c\u5c24\u5176\u5728\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u7684\u5c11\u6837\u672c\u63d0\u793a\u4e0b\u8868\u73b0\u66f4\u4f73\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u53c2\u4e0e\u3002", "conclusion": "\u7ed3\u5408LLM\u4e0e\u9006\u5411\u5de5\u7a0b\u53ef\u4e3a\u8f6f\u4ef6\u67b6\u6784\u6587\u6863\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6613\u7ef4\u62a4\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u964d\u4f4e\u624b\u52a8\u5de5\u4f5c\u91cf\u3001\u589e\u5f3a\u7cfb\u7edf\u7406\u89e3\u5e76\u63d0\u5347\u957f\u671f\u53ef\u7ef4\u62a4\u6027\u3002"}}
{"id": "2511.05389", "categories": ["cs.CE", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.05389", "abs": "https://arxiv.org/abs/2511.05389", "authors": ["Benjamin G. Zastrow", "Anirban Chaudhuri", "Karen E. Willcox", "Anthony Ashley", "Michael Chamberlain Henson"], "title": "Block-structured Operator Inference for coupled multiphysics model reduction", "comment": "28 pages, 19 figures", "summary": "This paper presents a block-structured formulation of Operator Inference as a\nway to learn structured reduced-order models for multiphysics systems. The\napproach specifies the governing equation structure for each physics component\nand the structure of the coupling terms. Once the multiphysics structure is\nspecified, the reduced-order model is learned from snapshot data following the\nnonintrusive Operator Inference methodology. In addition to preserving physical\nsystem structure, which in turn permits preservation of system properties such\nas stability and second-order structure, the block-structured approach has the\nadvantages of reducing the overall dimensionality of the learning problem and\nadmitting tailored regularization for each physics component. The numerical\nadvantages of the block-structured formulation over a monolithic Operator\nInference formulation are demonstrated for aeroelastic analysis, which couples\naerodynamic and structural models. For the benchmark test case of the AGARD\n445.6 wing, block-structured Operator Inference provides an average 20% online\nprediction speedup over monolithic Operator Inference across subsonic and\nsupersonic flow conditions in both the stable and fluttering parameter regimes\nwhile preserving the accuracy achieved with monolithic Operator Inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5757\u7ed3\u6784\u5316\u7684\u7b97\u5b50\u63a8\u65ad\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e3a\u591a\u7269\u7406\u573a\u7cfb\u7edf\u6784\u5efa\u7ed3\u6784\u4fdd\u6301\u7684\u964d\u9636\u6a21\u578b\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u4e86\u5728\u7ebf\u9884\u6d4b\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u5355\u4f53\u5f0f\u7b97\u5b50\u63a8\u65ad\u65b9\u6cd5\u5728\u5904\u7406\u591a\u7269\u7406\u573a\u7cfb\u7edf\u65f6\u96be\u4ee5\u4fdd\u7559\u7269\u7406\u7ed3\u6784\uff0c\u4e14\u7ef4\u5ea6\u9ad8\u3001\u6b63\u5219\u5316\u7b56\u7565\u5355\u4e00\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u4e0e\u6548\u7387\u3002", "method": "\u901a\u8fc7\u663e\u5f0f\u6307\u5b9a\u5404\u7269\u7406\u573a\u7ec4\u4ef6\u7684\u63a7\u5236\u65b9\u7a0b\u7ed3\u6784\u53ca\u5176\u8026\u5408\u9879\u7ed3\u6784\uff0c\u91c7\u7528\u975e\u4fb5\u5165\u5f0f\u7b97\u5b50\u63a8\u65ad\u65b9\u6cd5\u4ece\u5feb\u7167\u6570\u636e\u4e2d\u5b66\u4e60\u5206\u5757\u7ed3\u6784\u5316\u7684\u964d\u9636\u6a21\u578b\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u7269\u7406\u7ec4\u4ef6\u65bd\u52a0\u5b9a\u5236\u5316\u6b63\u5219\u5316\u3002", "result": "\u5728AGARD 445.6\u673a\u7ffc\u6c14\u52a8\u5f39\u6027\u5206\u6790\u6848\u4f8b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4e9a\u97f3\u901f\u548c\u8d85\u97f3\u901f\u6761\u4ef6\u4e0b\uff08\u5305\u62ec\u7a33\u5b9a\u4e0e\u98a4\u632f\u5de5\u51b5\uff09\u76f8\u6bd4\u5355\u4f53\u5f0f\u65b9\u6cd5\u5e73\u5747\u63d0\u534720%\u7684\u5728\u7ebf\u9884\u6d4b\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7cbe\u5ea6\u3002", "conclusion": "\u5206\u5757\u7ed3\u6784\u5316\u7b97\u5b50\u63a8\u65ad\u4e0d\u4ec5\u80fd\u6709\u6548\u4fdd\u7559\u591a\u7269\u7406\u573a\u7cfb\u7edf\u7684\u7ed3\u6784\u7279\u6027\uff08\u5982\u7a33\u5b9a\u6027\uff09\uff0c\u8fd8\u80fd\u964d\u4f4e\u5b66\u4e60\u95ee\u9898\u7ef4\u5ea6\u5e76\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u662f\u6784\u5efa\u9ad8\u6548\u9ad8\u4fdd\u771f\u964d\u9636\u6a21\u578b\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.04853", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04853", "abs": "https://arxiv.org/abs/2511.04853", "authors": ["Nuno dos Santos Fernandes", "Pedro Tom\u00e1s", "Nuno Roma", "Frank Winklmeier", "Patricia Conde-Mu\u00ed\u00f1o"], "title": "Marionette: Data Structure Description and Management for Heterogeneous Computing", "comment": "5 pages, 2 figures. To be published as a short paper accepted by the\n  24th International Symposium on Parallel and Distributed Computing (ISPDC)", "summary": "Adapting large, object-oriented C++ codebases for hardware acceleration might\nbe extremely challenging, particularly when targeting heterogeneous platforms\nsuch as GPUs. Marionette is a C++17 library designed to address this by\nenabling flexible, efficient, and portable data structure definitions. It\ndecouples data layout from the description of the interface, supports multiple\nmemory management strategies, and provides efficient data transfers and\nconversions across devices, all of this with minimal runtime overhead due to\nthe compile-time nature of its abstractions. By allowing interfaces to be\naugmented with arbitrary functions, Marionette maintains compatibility with\nexisting code and offers a streamlined interface that supports both\nstraightforward and advanced use cases. This paper outlines its design, usage,\nand performance, including a CUDA-based case study demonstrating its efficiency\nand flexibility.", "AI": {"tldr": "Marionette \u662f\u4e00\u4e2a C++17 \u5e93\uff0c\u901a\u8fc7\u5728\u7f16\u8bd1\u65f6\u89e3\u8026\u6570\u636e\u5e03\u5c40\u4e0e\u63a5\u53e3\u5b9a\u4e49\uff0c\u652f\u6301\u591a\u79cd\u5185\u5b58\u7ba1\u7406\u7b56\u7565\u548c\u9ad8\u6548\u8de8\u8bbe\u5907\u6570\u636e\u4f20\u8f93\uff0c\u4ece\u800c\u7b80\u5316\u9762\u5411\u5bf9\u8c61 C++ \u4ee3\u7801\u5728\u5f02\u6784\u786c\u4ef6\uff08\u5982 GPU\uff09\u4e0a\u7684\u52a0\u901f\u3002", "motivation": "\u5c06\u5927\u578b\u9762\u5411\u5bf9\u8c61\u7684 C++ \u4ee3\u7801\u5e93\u9002\u914d\u5230\u5f02\u6784\u786c\u4ef6\uff08\u5982 GPU\uff09\u8fdb\u884c\u52a0\u901f\u6781\u5177\u6311\u6218\u6027\uff0c\u4e3b\u8981\u96be\u70b9\u5728\u4e8e\u6570\u636e\u5e03\u5c40\u3001\u5185\u5b58\u7ba1\u7406\u548c\u8de8\u8bbe\u5907\u6570\u636e\u4f20\u8f93\u7684\u590d\u6742\u6027\u3002", "method": "Marionette \u5229\u7528 C++17 \u7684\u7f16\u8bd1\u671f\u62bd\u8c61\u673a\u5236\uff0c\u5c06\u6570\u636e\u5e03\u5c40\u4e0e\u63a5\u53e3\u63cf\u8ff0\u89e3\u8026\uff0c\u652f\u6301\u7075\u6d3b\u7684\u5185\u5b58\u7ba1\u7406\u7b56\u7565\uff0c\u5e76\u5141\u8bb8\u5bf9\u63a5\u53e3\u6dfb\u52a0\u4efb\u610f\u51fd\u6570\u4ee5\u517c\u5bb9\u73b0\u6709\u4ee3\u7801\u3002", "result": "\u901a\u8fc7 CUDA \u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86 Marionette \u5728\u4fdd\u6301\u4ee3\u7801\u517c\u5bb9\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u786c\u4ef6\u52a0\u901f\uff0c\u8fd0\u884c\u65f6\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "Marionette \u4e3a C++ \u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u79fb\u690d\u4e14\u6613\u4e8e\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5f02\u6784\u5e73\u53f0\u4e0a\u52a0\u901f\u73b0\u6709\u9762\u5411\u5bf9\u8c61\u4ee3\u7801\u3002"}}
{"id": "2511.05082", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.05082", "abs": "https://arxiv.org/abs/2511.05082", "authors": ["Yiming Xie", "Hua Dai", "Mingfeng Jiang", "Pengyue Li", "zhengkai Zhang", "Bohan Li"], "title": "An Efficient Proximity Graph-based Approach to Table Union Search", "comment": null, "summary": "Neural embedding models are extensively employed in the table union search\nproblem, which aims to find semantically compatible tables that can be merged\nwith a given query table. In particular, multi-vector models, which represent a\ntable as a vector set (typically one vector per column), have been demonstrated\nto achieve superior retrieval quality by capturing fine-grained semantic\nalignments. However, this problem faces more severe efficiency challenges than\nthe single-vector problem due to the inherent dependency on bipartite graph\nmaximum matching to compute unionability scores. Therefore, this paper proposes\nan efficient Proximity Graph-based Table Union Search (PGTUS) approach. PGTUS\nemploys a multi-stage pipeline that combines a novel refinement strategy, a\nfiltering strategy based on many-to-one bipartite matching. Besides, we propose\nan enhanced pruning strategy to prune the candidate set, which further improve\nthe search efficiency. Extensive experiments on six benchmark datasets\ndemonstrate that our approach achieves 3.6-6.0X speedup over existing\napproaches while maintaining comparable recall rates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u90bb\u8fd1\u56fe\u7684\u9ad8\u6548\u8868\u8054\u5408\u641c\u7d22\u65b9\u6cd5\uff08PGTUS\uff09\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6d41\u7a0b\u548c\u589e\u5f3a\u526a\u679d\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u53ec\u56de\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u641c\u7d22\u901f\u5ea6\u3002", "motivation": "\u591a\u5411\u91cf\u8868\u5f81\u867d\u80fd\u63d0\u5347\u8bed\u4e49\u5bf9\u9f50\u7cbe\u5ea6\uff0c\u4f46\u56e0\u4f9d\u8d56\u4e8c\u5206\u56fe\u6700\u5927\u5339\u914d\u8ba1\u7b97\u8054\u5408\u6027\u5f97\u5206\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "PGTUS\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u7a0b\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u7cbe\u70bc\u7b56\u7565\u3001\u57fa\u4e8e\u591a\u5bf9\u4e00\u4e8c\u5206\u5339\u914d\u7684\u8fc7\u6ee4\u7b56\u7565\u4ee5\u53ca\u589e\u5f3a\u7684\u526a\u679d\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u8868\u8054\u5408\u641c\u7d22\u6548\u7387\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u901f3.6\u20136.0\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u53ec\u56de\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684PGTUS\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u68c0\u7d22\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5411\u91cf\u6a21\u578b\u5728\u8868\u8054\u5408\u641c\u7d22\u4e2d\u7684\u6548\u7387\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2511.05205", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05205", "abs": "https://arxiv.org/abs/2511.05205", "authors": ["Huimin Hu", "Michael Pradel"], "title": "CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits", "comment": null, "summary": "During software evolution, developers commonly face the problem of mapping a\nspecific code region from one commit to another. For example, they may want to\ndetermine how the condition of an if-statement, a specific line in a\nconfiguration file, or the definition of a function changes. We call this the\ncode mapping problem. Existing techniques, such as git diff, address this\nproblem only insufficiently because they show all changes made to a file\ninstead of focusing on a code region of the developer's choice. Other\ntechniques focus on specific code elements and programming languages (e.g.,\nmethods in Java), limiting their applicability. This paper introduces\nCodeMapper, an approach to address the code mapping problem in a way that is\nindependent of specific program elements and programming languages. Given a\ncode region in one commit, CodeMapper finds the corresponding region in another\ncommit. The approach consists of two phases: (i) computing candidate regions by\nanalyzing diffs, detecting code movements, and searching for specific code\nfragments, and (ii) selecting the most likely target region by calculating\nsimilarities. Our evaluation applies CodeMapper to four datasets, including two\nnew hand-annotated datasets containing code region pairs in ten popular\nprogramming languages. CodeMapper correctly identifies the expected target\nregion in 71.0%--94.5% of all cases, improving over the best available\nbaselines by 1.5--58.8 absolute percent points.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CodeMapper\uff0c\u4e00\u79cd\u4e0e\u7f16\u7a0b\u8bed\u8a00\u548c\u7a0b\u5e8f\u5143\u7d20\u65e0\u5173\u7684\u4ee3\u7801\u6620\u5c04\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4e0d\u540c\u63d0\u4ea4\u4e4b\u95f4\u5b9a\u4f4d\u5bf9\u5e94\u4ee3\u7801\u533a\u57df\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u8f6f\u4ef6\u6f14\u5316\u8fc7\u7a0b\u4e2d\u5e38\u9700\u5c06\u67d0\u4e00\u63d0\u4ea4\u4e2d\u7684\u7279\u5b9a\u4ee3\u7801\u533a\u57df\u6620\u5c04\u5230\u53e6\u4e00\u63d0\u4ea4\u4e2d\uff0c\u4f46\u73b0\u6709\u5de5\u5177\uff08\u5982git diff\uff09\u65e0\u6cd5\u805a\u7126\u4e8e\u7528\u6237\u6307\u5b9a\u7684\u4ee3\u7801\u533a\u57df\uff0c\u800c\u5176\u4ed6\u65b9\u6cd5\u53c8\u53d7\u9650\u4e8e\u7279\u5b9a\u8bed\u8a00\u6216\u4ee3\u7801\u5143\u7d20\uff0c\u9002\u7528\u6027\u6709\u9650\u3002", "method": "CodeMapper\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a(i) \u901a\u8fc7\u5206\u6790diff\u3001\u68c0\u6d4b\u4ee3\u7801\u79fb\u52a8\u548c\u641c\u7d22\u7279\u5b9a\u4ee3\u7801\u7247\u6bb5\u751f\u6210\u5019\u9009\u533a\u57df\uff1b(ii) \u901a\u8fc7\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u9009\u62e9\u6700\u53ef\u80fd\u7684\u76ee\u6807\u533a\u57df\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\uff08\u5305\u62ec\u4e24\u4e2a\u6db5\u76d6\u5341\u79cd\u6d41\u884c\u8bed\u8a00\u7684\u624b\u52a8\u6807\u6ce8\u6570\u636e\u96c6\uff09\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cCodeMapper\u572871.0%\u201394.5%\u7684\u60c5\u51b5\u4e0b\u80fd\u6b63\u786e\u8bc6\u522b\u76ee\u6807\u533a\u57df\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa1.5\u201358.8\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "CodeMapper\u6709\u6548\u89e3\u51b3\u4e86\u901a\u7528\u3001\u8de8\u8bed\u8a00\u7684\u4ee3\u7801\u6620\u5c04\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.04684", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.04684", "abs": "https://arxiv.org/abs/2511.04684", "authors": ["Yuchao Qin", "Anjunyi Fan", "Bonan Yan"], "title": "RAS: A Bit-Exact rANS Accelerator For High-Performance Neural Lossless Compression", "comment": "5 pages, 4 figures", "summary": "Data centers handle vast volumes of data that require efficient lossless\ncompression, yet emerging probabilistic models based methods are often\ncomputationally slow. To address this, we introduce RAS, the Range Asymmetric\nNumeral System Acceleration System, a hardware architecture that integrates the\nrANS algorithm into a lossless compression pipeline and eliminates key\nbottlenecks. RAS couples an rANS core with a probabilistic generator, storing\ndistributions in BF16 format and converting them once into a fixed-point domain\nshared by a unified division/modulo datapath. A two-stage rANS update with\nbyte-level re-normalization reduces logic cost and memory traffic, while a\nprediction-guided decoding path speculatively narrows the cumulative\ndistribution function (CDF) search window and safely falls back to maintain\nbit-exactness. A multi-lane organization scales throughput and enables\nfine-grained clock gating for efficient scheduling. On image workloads, our\nRTL-simulated prototype achieves 121.2x encode and 70.9x decode speedups over a\nPython rANS baseline, reducing average decoder binary-search steps from 7.00 to\n3.15 (approximately 55% fewer). When paired with neural probability models, RAS\nsustains higher compression ratios than classical codecs and outperforms\nCPU/GPU rANS implementations, offering a practical approach to fast neural\nlossless compression.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RAS\uff08Range Asymmetric Numeral System Acceleration System\uff09\uff0c\u4e00\u79cd\u7528\u4e8e\u52a0\u901f\u57fa\u4e8erANS\u7b97\u6cd5\u7684\u795e\u7ecf\u65e0\u635f\u538b\u7f29\u7684\u786c\u4ef6\u67b6\u6784\u3002\u901a\u8fc7\u5c06\u6982\u7387\u5206\u5e03\u4ee5BF16\u683c\u5f0f\u5b58\u50a8\u3001\u7edf\u4e00\u9664\u6cd5/\u53d6\u6a21\u6570\u636e\u901a\u8def\u3001\u4e24\u9636\u6bb5rANS\u66f4\u65b0\u3001\u9884\u6d4b\u5f15\u5bfc\u89e3\u7801\u548c\u591a\u901a\u9053\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f16\u89e3\u7801\u901f\u5ea6\u5e76\u964d\u4f4e\u4e86\u5185\u5b58\u5f00\u9500\uff0c\u5728\u56fe\u50cf\u4efb\u52a1\u4e2d\u76f8\u6bd4Python\u57fa\u7ebf\u5b9e\u73b0\u4e86\u8d85\u8fc770\u500d\u7684\u89e3\u7801\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6982\u7387\u6a21\u578b\u7684\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\uff0c\u96be\u4ee5\u6ee1\u8db3\u6570\u636e\u4e2d\u5fc3\u5bf9\u9ad8\u901f\u538b\u7f29\u7684\u9700\u6c42\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u517c\u987e\u538b\u7f29\u7387\u4e0e\u901f\u5ea6\u7684\u786c\u4ef6\u52a0\u901f\u65b9\u6848\u3002", "method": "\u63d0\u51faRAS\u786c\u4ef6\u67b6\u6784\uff0c\u96c6\u6210rANS\u7b97\u6cd5\uff0c\u91c7\u7528BF16\u683c\u5f0f\u5b58\u50a8\u5206\u5e03\u3001\u56fa\u5b9a\u70b9\u57df\u7edf\u4e00\u9664\u6cd5/\u53d6\u6a21\u901a\u8def\u3001\u4e24\u9636\u6bb5rANS\u66f4\u65b0\u914d\u5408\u5b57\u8282\u7ea7\u91cd\u5f52\u4e00\u5316\u3001\u9884\u6d4b\u5f15\u5bfc\u7684CDF\u641c\u7d22\u7a97\u53e3\u7f29\u5c0f\u673a\u5236\u4ee5\u53ca\u591a\u901a\u9053\u7ed3\u6784\u5b9e\u73b0\u9ad8\u6548\u8c03\u5ea6\u4e0e\u541e\u5410\u6269\u5c55\u3002", "result": "\u5728RTL\u4eff\u771f\u4e2d\uff0cRAS\u5728\u56fe\u50cf\u8d1f\u8f7d\u4e0a\u76f8\u6bd4Python rANS\u57fa\u7ebf\u5b9e\u73b0121.2\u500d\u7f16\u7801\u548c70.9\u500d\u89e3\u7801\u52a0\u901f\uff0c\u5e73\u5747\u89e3\u7801\u4e8c\u5206\u641c\u7d22\u6b65\u6570\u4ece7.00\u964d\u81f33.15\uff08\u51cf\u5c11\u7ea655%\uff09\uff0c\u4e14\u5728\u642d\u914d\u795e\u7ecf\u6982\u7387\u6a21\u578b\u65f6\u538b\u7f29\u7387\u4f18\u4e8e\u4f20\u7edf\u7f16\u89e3\u7801\u5668\uff0c\u5e76\u8d85\u8d8aCPU/GPU\u4e0a\u7684rANS\u5b9e\u73b0\u3002", "conclusion": "RAS\u4e3a\u795e\u7ecf\u65e0\u635f\u538b\u7f29\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9ad8\u538b\u7f29\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5904\u7406\u901f\u5ea6\uff0c\u9002\u7528\u4e8e\u6570\u636e\u4e2d\u5fc3\u7b49\u9ad8\u6027\u80fd\u573a\u666f\u3002"}}
{"id": "2511.05297", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05297", "abs": "https://arxiv.org/abs/2511.05297", "authors": ["Mohammed Hilel", "Yannis Karmim", "Jean De Bodinat", "Reda Sarehane", "Antoine Gillon"], "title": "Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation", "comment": null, "summary": "Digital Adoption Platforms (DAPs) have become essential tools for helping\nemployees navigate complex enterprise software such as CRM, ERP, or HRMS\nsystems. Companies like LemonLearning have shown how digital guidance can\nreduce training costs and accelerate onboarding. However, building and\nmaintaining these interactive guides still requires extensive manual effort.\nLeveraging Large Language Models as virtual assistants is an appealing\nalternative, yet without a structured understanding of the target software,\nLLMs often hallucinate and produce unreliable answers. Moreover, most\nproduction-grade LLMs are black-box APIs, making fine-tuning impractical due to\nthe lack of access to model weights. In this work, we introduce a Graph-based\nRetrieval-Augmented Generation framework that automatically converts enterprise\nweb applications into state-action knowledge graphs, enabling LLMs to generate\ngrounded and context-aware assistance. The framework was co-developed with the\nAI enterprise RAKAM, in collaboration with Lemon Learning. We detail the\nengineering pipeline that extracts and structures software interfaces, the\ndesign of the graph-based retrieval process, and the integration of our\napproach into production DAP workflows. Finally, we discuss scalability,\nrobustness, and deployment lessons learned from industrial use cases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u5c06\u4f01\u4e1a\u7ea7Web\u5e94\u7528\u81ea\u52a8\u8f6c\u5316\u4e3a\u72b6\u6001-\u52a8\u4f5c\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u91c7\u7528\u5e73\u53f0\uff08DAP\uff09\u4e2d\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u91c7\u7528\u5e73\u53f0\uff08DAP\uff09\u4f9d\u8d56\u5927\u91cf\u4eba\u5de5\u6784\u5efa\u4ea4\u4e92\u5f0f\u5f15\u5bfc\uff0c\u800c\u76f4\u63a5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u865a\u62df\u52a9\u624b\u65f6\uff0c\u7531\u4e8e\u7f3a\u4e4f\u5bf9\u76ee\u6807\u8f6f\u4ef6\u7684\u7ed3\u6784\u5316\u7406\u89e3\uff0c\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u548c\u4e0d\u53ef\u9760\u7684\u56de\u7b54\uff1b\u540c\u65f6\uff0c\u4e3b\u6d41LLM\u591a\u4e3a\u9ed1\u76d2API\uff0c\u96be\u4ee5\u5fae\u8c03\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u56fe\u7ed3\u6784\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08Graph-based RAG\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5de5\u7a0b\u6d41\u6c34\u7ebf\u81ea\u52a8\u63d0\u53d6\u5e76\u7ed3\u6784\u5316\u4f01\u4e1a\u8f6f\u4ef6\u754c\u9762\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u72b6\u6001-\u52a8\u4f5c\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u96c6\u6210\u5230\u5b9e\u9645DAP\u5de5\u4f5c\u6d41\u4e2d\u3002", "result": "\u8be5\u6846\u67b6\u5df2\u5728\u4e0eRAKAM\u548cLemon Learning\u5408\u4f5c\u7684\u5de5\u4e1a\u573a\u666f\u4e2d\u90e8\u7f72\uff0c\u5c55\u793a\u4e86\u5176\u5728\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u90e8\u7f72\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u4f01\u4e1a\u8f6f\u4ef6\u8f85\u52a9\u573a\u666f\u4e2d\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4e3aDAP\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u53ef\u843d\u5730\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2511.05067", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.05067", "abs": "https://arxiv.org/abs/2511.05067", "authors": ["Giuseppe Esposito", "Juan-David Guerrero-Balaguera", "Josie Esteban Rodriguez Condia", "Matteo Sonza Reorda", "Marco Barbiero", "Rossella Fortuna"], "title": "GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters", "comment": null, "summary": "Graphics Processing Units (GPUs) are specialized accelerators in data centers\nand high-performance computing (HPC) systems, enabling the fast execution of\ncompute-intensive applications, such as Convolutional Neural Networks (CNNs).\nHowever, sustained workloads can impose significant stress on GPU components,\nraising reliability concerns due to potential faults that corrupt the\nintermediate application computations, leading to incorrect results. Estimating\nthe stress induced by an application is thus crucial to predict reliability\n(with\\,special\\,emphasis\\,on\\,aging\\,effects). In this work, we combine online\ntelemetry parameters and hardware performance counters to assess GPU stress\ninduced by different applications. The experimental results indicate the stress\ninduced by a parallel workload can be estimated by combining telemetry data and\nPerformance Counters that reveal the efficiency in the resource usage of the\ntarget workload. For this purpose the selected performance counters focus on\nmeasuring the i) throughput, ii) amount of issued instructions and iii) stall\nevents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5728\u7ebf\u9065\u6d4b\u53c2\u6570\u4e0e\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30GPU\u5728\u4e0d\u540c\u5e94\u7528\u8d1f\u8f7d\u4e0b\u7684\u5e94\u529b\u6c34\u5e73\uff0c\u4ece\u800c\u9884\u6d4b\u5176\u53ef\u9760\u6027\uff08\u5c24\u5176\u5173\u6ce8\u8001\u5316\u6548\u5e94\uff09\u3002", "motivation": "\u7531\u4e8e\u6301\u7eed\u9ad8\u8d1f\u8f7d\u53ef\u80fd\u5bfc\u81f4GPU\u7ec4\u4ef6\u53d1\u751f\u6545\u969c\uff0c\u8fdb\u800c\u5f71\u54cd\u8ba1\u7b97\u7ed3\u679c\u7684\u6b63\u786e\u6027\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u51c6\u786e\u4f30\u8ba1\u5e94\u7528\u7a0b\u5e8f\u5bf9GPU\u9020\u6210\u7684\u5e94\u529b\uff0c\u4ee5\u9884\u6d4b\u5176\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u8001\u5316\u5e26\u6765\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408GPU\u7684\u5728\u7ebf\u9065\u6d4b\u6570\u636e\u4e0e\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\uff08\u91cd\u70b9\u5173\u6ce8\u541e\u5410\u91cf\u3001\u53d1\u51fa\u6307\u4ee4\u6570\u91cf\u548c\u505c\u987f\u4e8b\u4ef6\uff09\u6765\u8bc4\u4f30\u4e0d\u540c\u5e76\u884c\u5de5\u4f5c\u8d1f\u8f7d\u6240\u5f15\u8d77\u7684GPU\u5e94\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u6240\u9009\u7684\u9065\u6d4b\u6570\u636e\u4e0e\u6027\u80fd\u8ba1\u6570\u5668\u7ec4\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u4f30\u8ba1\u5e76\u884c\u5de5\u4f5c\u8d1f\u8f7d\u5bf9GPU\u9020\u6210\u7684\u5e94\u529b\u3002", "conclusion": "\u5229\u7528\u9065\u6d4b\u53c2\u6570\u4e0e\u7279\u5b9a\u6027\u80fd\u8ba1\u6570\u5668\u7684\u7ec4\u5408\uff0c\u80fd\u591f\u6709\u6548\u8bc4\u4f30GPU\u5728\u8fd0\u884c\u4e0d\u540c\u5e94\u7528\u65f6\u7684\u5e94\u529b\u6c34\u5e73\uff0c\u4e3a\u53ef\u9760\u6027\u9884\u6d4b\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.04687", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.04687", "abs": "https://arxiv.org/abs/2511.04687", "authors": ["Teona Bagashvili", "Tarikul Islam Papon", "Subhadeep Sarkar", "Manos Athanassoulis"], "title": "Eliminating the Hidden Cost of Zone Management in ZNS SSDs", "comment": null, "summary": "Zoned Namespace (ZNS) SSDs offer a promising interface for stable throughput\nand low-latency storage by eliminating device-side garbage collection. They\nexpose storage as append-only zones that give the host applications direct\ncontrol over data placement. However, current ZNS implementations suffer from\n(a) device-level write amplification (DLWA), (b) increased wear, and (c)\ninterference with host I/O due to zone mapping and management. We identify two\nprimary design decisions as the main cause: (i) fixed physical zones and (ii)\nfull-zone operations that lead to excessive physical writes. We propose\nSilentZNS, a new zone mapping and management approach that addresses the\naforementioned limitations by on-the-fly allocating available resources to\nzones, while minimizing wear, maintaining parallelism, and avoiding unnecessary\nwrites at the device-level. SilentZNS is a flexible zone allocation scheme that\ndeparts from the traditional logical-to-physical zone mapping and allows for\narbitrary collections of blocks to be assigned to a zone. We add the necessary\nconstraints to ensure wear-leveling and state-of-the-art read performance, and\nuse only the required blocks to avoid dummy writes during zone reset. We\nimplement SilentZNS using the state-of-the-art ConfZNS++ emulator and show that\nit eliminates the undue burden of dummy writes by up to 20x, leading to lower\nDLWA (86% less at 10% zone occupancy), less overall wear (up to 76.9%), and up\nto 3.7x faster workload execution.", "AI": {"tldr": "SilentZNS \u662f\u4e00\u79cd\u65b0\u578b ZNS SSD \u533a\u6620\u5c04\u4e0e\u7ba1\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u914d\u7269\u7406\u8d44\u6e90\u3001\u907f\u514d\u5168\u533a\u57df\u64cd\u4f5c\u548c\u5197\u4f59\u5199\u5165\uff0c\u663e\u8457\u964d\u4f4e\u8bbe\u5907\u7ea7\u5199\u653e\u5927\u3001\u78e8\u635f\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d Zoned Namespace\uff08ZNS\uff09SSD \u5b58\u5728\u8bbe\u5907\u7ea7\u5199\u653e\u5927\uff08DLWA\uff09\u3001\u78e8\u635f\u52a0\u5267\u4ee5\u53ca\u56e0\u533a\u57df\u6620\u5c04\u548c\u7ba1\u7406\u5bfc\u81f4\u7684\u4e3b\u673a I/O \u5e72\u6270\u7b49\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u56fa\u5b9a\u7269\u7406\u533a\u57df\u548c\u5168\u533a\u57df\u64cd\u4f5c\u7684\u8bbe\u8ba1\u7f3a\u9677\u3002", "method": "\u63d0\u51fa SilentZNS \u65b9\u6cd5\uff0c\u6452\u5f03\u4f20\u7edf\u7684\u903b\u8f91\u5230\u7269\u7406\u533a\u57df\u6620\u5c04\uff0c\u91c7\u7528\u7075\u6d3b\u7684\u5757\u7ea7\u533a\u57df\u5206\u914d\u673a\u5236\uff0c\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u5206\u914d\u53ef\u7528\u8d44\u6e90\uff0c\u5e76\u5f15\u5165\u7ea6\u675f\u4ee5\u4fdd\u8bc1\u78e8\u635f\u5747\u8861\u548c\u9ad8\u6027\u80fd\u8bfb\u53d6\uff0c\u540c\u65f6\u907f\u514d\u533a\u57df\u91cd\u7f6e\u65f6\u7684\u65e0\u6548\u5199\u5165\u3002", "result": "\u57fa\u4e8e ConfZNS++ \u6a21\u62df\u5668\u5b9e\u73b0\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSilentZNS \u53ef\u5c06\u65e0\u6548\u5199\u5165\u51cf\u5c11\u6700\u591a 20 \u500d\uff0c\u5728 10% \u533a\u57df\u5360\u7528\u7387\u4e0b DLWA \u964d\u4f4e 86%\uff0c\u6574\u4f53\u78e8\u635f\u51cf\u5c11\u9ad8\u8fbe 76.9%\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u6267\u884c\u901f\u5ea6\u63d0\u5347\u6700\u9ad8\u8fbe 3.7 \u500d\u3002", "conclusion": "SilentZNS \u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709 ZNS SSD \u7684\u5173\u952e\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b58\u50a8\u6548\u7387\u3001\u5bff\u547d\u548c\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u80fd\u5b58\u50a8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.05302", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05302", "abs": "https://arxiv.org/abs/2511.05302", "authors": ["Qianru Meng", "Xiao Zhang", "Zhaochen Ren", "Joost Visser"], "title": "Code Review Automation using Retrieval Augmented Generation", "comment": null, "summary": "Code review is essential for maintaining software quality but is\nlabor-intensive. Automated code review generation offers a promising solution\nto this challenge. Both deep learning-based generative techniques and\nretrieval-based methods have demonstrated strong performance in this task.\nHowever, despite these advancements, there are still some limitations where\ngenerated reviews can be either off-point or overly general. To address these\nissues, we introduce Retrieval-Augmented Reviewer (RARe), which leverages\nRetrieval-Augmented Generation (RAG) to combine retrieval-based and generative\nmethods, explicitly incorporating external domain knowledge into the code\nreview process. RARe uses a dense retriever to select the most relevant reviews\nfrom the codebase, which then enrich the input for a neural generator,\nutilizing the contextual learning capacity of large language models (LLMs), to\nproduce the final review. RARe outperforms state-of-the-art methods on two\nbenchmark datasets, achieving BLEU-4 scores of 12.32 and 12.96, respectively.\nIts effectiveness is further validated through a detailed human evaluation and\na case study using an interpretability tool, demonstrating its practical\nutility and reliability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRARe\uff08Retrieval-Augmented Reviewer\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u68c0\u7d22\u4e0e\u751f\u6210\u6280\u672f\uff0c\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u9886\u57df\u77e5\u8bc6\u63d0\u5347\u4ee3\u7801\u8bc4\u5ba1\u7684\u51c6\u786e\u6027\u548c\u5177\u4f53\u6027\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u4ee3\u7801\u8bc4\u5ba1\u65b9\u6cd5\uff08\u5305\u62ec\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u751f\u6210\u65b9\u6cd5\u548c\u68c0\u7d22\u65b9\u6cd5\uff09\u4ecd\u5b58\u5728\u751f\u6210\u5185\u5bb9\u504f\u79bb\u4e3b\u9898\u6216\u8fc7\u4e8e\u6cdb\u5316\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u878d\u5408\u4e24\u8005\u4f18\u52bf\u5e76\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u8bc4\u5ba1\u8d28\u91cf\u3002", "method": "RARe\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u7a20\u5bc6\u68c0\u7d22\u5668\u4ece\u4ee3\u7801\u5e93\u4e2d\u9009\u53d6\u6700\u76f8\u5173\u7684\u5df2\u6709\u8bc4\u5ba1\uff0c\u5c06\u5176\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u8f93\u5165\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u795e\u7ecf\u751f\u6210\u5668\uff0c\u4ece\u800c\u751f\u6210\u66f4\u7cbe\u51c6\u3001\u5177\u4f53\u7684\u4ee3\u7801\u8bc4\u5ba1\u3002", "result": "RARe\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5206\u522b\u53d6\u5f97\u4e8612.32\u548c12.96\u7684BLEU-4\u5206\u6570\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff1b\u5e76\u901a\u8fc7\u4eba\u5de5\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u7ed3\u5408\u68c0\u7d22\u4e0e\u751f\u6210\u7684RARe\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u81ea\u52a8\u4ee3\u7801\u8bc4\u5ba1\u7684\u8d28\u91cf\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u548c\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2511.05238", "categories": ["cs.NI", "68T05, 90C26, 68M10", "I.2.11; C.2.1; C.4; G.3"], "pdf": "https://arxiv.org/pdf/2511.05238", "abs": "https://arxiv.org/abs/2511.05238", "authors": ["Peide Li", "Liu Cao", "Lyutianyang Zhang", "Dongyu Wei", "Ye Hu", "Qipeng Xie"], "title": "EPFL-REMNet: Efficient Personalized Federated Digital Twin Towards 6G Heterogeneous Radio Environme", "comment": "Approx. 12 pages, 3 figures, 3 tables; focuses on 6G heterogeneous\n  radio environment digital twin construction via personalized federated\n  learning", "summary": "Radio Environment Map (REM) is transitioning from 5G homogeneous environments\nto B5G/6G heterogeneous landscapes. However, standard Federated Learning (FL),\na natural fit for this distributed task, struggles with performance degradation\nin accuracy and communication efficiency under the non-independent and\nidentically distributed (Non-IID) data conditions inherent to these new\nenvironments. This paper proposes EPFL-REMNet, an efficient personalized\nfederated framework for constructing a high-fidelity digital twin of the 6G\nheterogeneous radio environment. The proposed EPFL-REMNet employs a\"shared\nbackbone + lightweight personalized head\" model, where only the compressed\nshared backbone is transmitted between the server and clients, while each\nclient's personalized head is maintained locally. We tested EPFL-REMNet by\nconstructing three distinct Non-IID scenarios (light, medium, and heavy) based\non radio environment complexity, with data geographically partitioned across 90\nclients. Experimental results demonstrate that EPFL-REMNet simultaneously\nachieves higher digital twin fidelity (accuracy) and lower uplink overhead\nacross all Non-IID settings compared to standard FedAvg and recent\nstate-of-the-art methods. Particularly, it significantly reduces performance\ndisparities across datasets and improves local map accuracy for long-tail\nclients, enhancing the overall integrity of digital twin.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEPFL-REMNet\uff0c\u4e00\u79cd\u9762\u54116G\u5f02\u6784\u65e0\u7ebf\u73af\u5883\u7684\u9ad8\u6548\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u201c\u5171\u4eab\u4e3b\u5e72+\u8f7b\u91cf\u7ea7\u4e2a\u6027\u5316\u5934\u201d\u7ed3\u6784\uff0c\u5728Non-IID\u6570\u636e\u6761\u4ef6\u4e0b\u540c\u65f6\u63d0\u5347\u6570\u5b57\u5b6a\u751f\u7cbe\u5ea6\u5e76\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u5728\u6784\u5efa6G\u5f02\u6784\u65e0\u7ebf\u73af\u5883\u6570\u5b57\u5b6a\u751f\uff08\u5982\u65e0\u7ebf\u7535\u73af\u5883\u56feREM\uff09\u65f6\uff0c\u56e0Non-IID\u6570\u636e\u5206\u5e03\u5bfc\u81f4\u51c6\u786e\u6027\u548c\u901a\u4fe1\u6548\u7387\u4e0b\u964d\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "EPFL-REMNet\u91c7\u7528\u201c\u5171\u4eab\u4e3b\u5e72+\u8f7b\u91cf\u7ea7\u4e2a\u6027\u5316\u5934\u201d\u7684\u6a21\u578b\u67b6\u6784\uff0c\u4ec5\u5728\u670d\u52a1\u5668\u4e0e\u5ba2\u6237\u7aef\u95f4\u4f20\u8f93\u538b\u7f29\u540e\u7684\u5171\u4eab\u4e3b\u5e72\uff0c\u4e2a\u6027\u5316\u5934\u90e8\u5219\u4fdd\u7559\u5728\u672c\u5730\uff1b\u5b9e\u9a8c\u57fa\u4e8e90\u4e2a\u5730\u7406\u5206\u533a\u5ba2\u6237\u7aef\u6784\u5efa\u4e09\u79cdNon-IID\u573a\u666f\uff08\u8f7b\u5ea6\u3001\u4e2d\u5ea6\u3001\u91cd\u5ea6\uff09\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "EPFL-REMNet\u5728\u6240\u6709Non-IID\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8eFedAvg\u53ca\u6700\u65b0\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6570\u5b57\u5b6a\u751f\u4fdd\u771f\u5ea6\u548c\u4e0a\u884c\u94fe\u8def\u6548\u7387\uff0c\u8fd8\u663e\u8457\u7f29\u5c0f\u4e86\u4e0d\u540c\u5ba2\u6237\u7aef\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5c24\u5176\u6539\u5584\u4e86\u957f\u5c3e\u5ba2\u6237\u7aef\u7684\u672c\u5730\u5730\u56fe\u7cbe\u5ea6\u3002", "conclusion": "EPFL-REMNet\u6709\u6548\u89e3\u51b3\u4e866G\u5f02\u6784\u73af\u5883\u4e2dNon-IID\u6570\u636e\u5e26\u6765\u7684\u8054\u90a6\u5b66\u4e60\u6311\u6218\uff0c\u4e3a\u9ad8\u4fdd\u771f\u3001\u4f4e\u5f00\u9500\u7684\u65e0\u7ebf\u7535\u73af\u5883\u56fe\u6784\u5efa\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u6570\u5b57\u5b6a\u751f\u7684\u6574\u4f53\u5b8c\u6574\u6027\u3002"}}
{"id": "2511.05459", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05459", "abs": "https://arxiv.org/abs/2511.05459", "authors": ["Jingxuan Xu", "Ken Deng", "Weihao Li", "Songwei Yu", "Huaixi Tang", "Haoyang Huang", "Zhiyi Lai", "Zizheng Zhan", "Yanan Wu", "Chenchen Zhang", "Kepeng Lei", "Yifan Yao", "Xinping Lei", "Wenqiang Zhu", "Zongxian Feng", "Han Li", "Junqi Xiong", "Dailin Li", "Zuchen Gao", "Kun Wu", "Wen Xiang", "Ziqi Zhan", "Yuanxing Zhang", "Wuxuan Gong", "Ziyuan Gao", "Guanxiang Wang", "Yirong Xue", "Xiaojiang Zhang", "Jinghui Wang", "Huiming Wang", "Wenhao Zhuang", "Zhaoxiang Zhang", "Yuqun Zhang", "Haotian Zhang", "Bin Chen", "Jiaheng Liu"], "title": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models", "comment": null, "summary": "Evaluating large language models (LLMs) for software engineering has been\nlimited by narrow task coverage, language bias, and insufficient alignment with\nreal-world developer workflows. Existing benchmarks often focus on algorithmic\nproblems or Python-centric bug fixing, leaving critical dimensions of software\nengineering underexplored. To address these gaps, we introduce SWE-Compass1, a\ncomprehensive benchmark that unifies heterogeneous code-related evaluations\ninto a structured and production-aligned framework. SWE-Compass spans 8 task\ntypes, 8 programming scenarios, and 10 programming languages, with 2000\nhigh-quality instances curated from authentic GitHub pull requests and refined\nthrough systematic filtering and validation. We benchmark ten state-of-the-art\nLLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear\nhierarchy of difficulty across task types, languages, and scenarios. Moreover,\nby aligning evaluation with real-world developer practices, SWE-Compass\nprovides a rigorous and reproducible foundation for diagnosing and advancing\nagentic coding capabilities in large language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SWE-Compass\uff0c\u4e00\u4e2a\u8986\u76d68\u7c7b\u4efb\u52a1\u30018\u79cd\u7f16\u7a0b\u573a\u666f\u548c10\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u7efc\u5408\u6027\u8f6f\u4ef6\u5de5\u7a0b\u8bc4\u6d4b\u57fa\u51c6\uff0c\u57fa\u4e8e2000\u4e2a\u6765\u81ea\u771f\u5b9eGitHub PR\u7684\u9ad8\u8d28\u91cf\u5b9e\u4f8b\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d34\u8fd1\u5f00\u53d1\u8005\u5b9e\u9645\u5de5\u4f5c\u6d41\u4e2d\u7684\u7f16\u7801\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u8bc4\u6d4b\u5b58\u5728\u4efb\u52a1\u8986\u76d6\u72ed\u7a84\u3001\u8bed\u8a00\u504f\u5411\u6027\u5f3a\u4ee5\u53ca\u4e0e\u771f\u5b9e\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u7a0b\u8131\u8282\u7b49\u95ee\u9898\uff0c\u5c24\u5176\u7f3a\u4e4f\u5bf9\u591a\u8bed\u8a00\u3001\u591a\u573a\u666f\u4e0b\u5b9e\u9645\u7f16\u7801\u4efb\u52a1\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u6784\u5efaSWE-Compass\u57fa\u51c6\uff0c\u6574\u5408\u6765\u81eaGitHub\u771f\u5b9ePR\u76842000\u4e2a\u9ad8\u8d28\u91cf\u5b9e\u4f8b\uff0c\u6db5\u76d68\u7c7b\u4efb\u52a1\u30018\u79cd\u573a\u666f\u548c10\u79cd\u8bed\u8a00\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u8fc7\u6ee4\u4e0e\u9a8c\u8bc1\u786e\u4fdd\u8d28\u91cf\uff1b\u5728SWE-Agent\u548cClaude Code\u4e24\u4e2a\u667a\u80fd\u4f53\u6846\u67b6\u4e0b\u5bf910\u4e2a\u524d\u6cbf\u5927\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u8bc4\u6d4b\u63ed\u793a\u4e86\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u3001\u7f16\u7a0b\u8bed\u8a00\u548c\u573a\u666f\u4e4b\u95f4\u7684\u96be\u5ea6\u5c42\u7ea7\u5dee\u5f02\uff0c\u9a8c\u8bc1\u4e86SWE-Compass\u5728\u8bc4\u4f30\u6a21\u578b\u5b9e\u9645\u7f16\u7801\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u4e0e\u533a\u5206\u5ea6\u3002", "conclusion": "SWE-Compass\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u4e0e\u771f\u5b9e\u5f00\u53d1\u5b9e\u8df5\u5bf9\u9f50\u3001\u7ed3\u6784\u6e05\u6670\u4e14\u53ef\u590d\u73b0\u7684\u7efc\u5408\u6027\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u667a\u80fd\u4f53\u7f16\u7801\u80fd\u529b\u7684\u8bca\u65ad\u4e0e\u8fdb\u6b65\u3002"}}
{"id": "2511.05334", "categories": ["cs.NI", "F.2.2; G.2.2"], "pdf": "https://arxiv.org/pdf/2511.05334", "abs": "https://arxiv.org/abs/2511.05334", "authors": ["Giovanni Fiaschi", "Carlo Vitucci", "Thomas Westerb\u00e4ck", "Daniel Sundmark", "Thomas Nolte"], "title": "A Formal Model for Path Set Attribute Calculation in Network Systems", "comment": "8 pages, 3 figures, to be published in the proceedings of the IEEE\n  International Symposium on Networks, Computers and Communications (ISNCC'25),\n  27-28 Oct. 2025", "summary": "In graph theory and its practical networking applications, e.g.,\ntelecommunications and transportation, the problem of finding paths has\nparticular importance. Selecting paths requires giving scores to the\nalternative solutions to drive a choice. While previous studies have provided\ncomprehensive evaluation of single-path solutions, the same level of detail is\nlacking when considering sets of paths. This paper emphasizes that the path\ncharacterization strongly depends on the properties under consideration. While\nproperty-based characterization is also valid for single paths, it becomes\ncrucial to analyse multiple path sets. From the above consideration, this paper\nproposes a mathematical approach, defining a functional model that lends itself\nwell to characterizing the path set in its general formulation. The paper shows\nhow the functional model contextualizes specific attributes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u523b\u753b\u8def\u5f84\u96c6\u5408\u7684\u6cdb\u5316\u51fd\u6570\u6a21\u578b\uff0c\u5f3a\u8c03\u5728\u591a\u8def\u5f84\u9009\u62e9\u4e2d\u9700\u4f9d\u636e\u4e0d\u540c\u5c5e\u6027\u5bf9\u8def\u5f84\u96c6\u5408\u8fdb\u884c\u7279\u5f81\u5316\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u5355\u6761\u8def\u5f84\u7684\u8bc4\u4f30\u8f83\u4e3a\u5b8c\u5584\uff0c\u4f46\u5728\u8def\u5f84\u96c6\u5408\u5c42\u9762\u7f3a\u4e4f\u540c\u7b49\u7ec6\u81f4\u7684\u5206\u6790\uff1b\u800c\u8def\u5f84\u96c6\u5408\u7684\u7279\u6027\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6240\u8003\u8651\u7684\u5c5e\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u523b\u753b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u901a\u7528\u7684\u51fd\u6570\u6a21\u578b\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u5730\u63cf\u8ff0\u548c\u5206\u6790\u8def\u5f84\u96c6\u5408\uff0c\u5e76\u5c55\u793a\u8be5\u6a21\u578b\u5982\u4f55\u7ed3\u5408\u5177\u4f53\u5c5e\u6027\u8fdb\u884c\u4e0a\u4e0b\u6587\u5316\u5efa\u6a21\u3002", "result": "\u8be5\u51fd\u6570\u6a21\u578b\u80fd\u591f\u6709\u6548\u8868\u5f81\u8def\u5f84\u96c6\u5408\u7684\u6574\u4f53\u7279\u6027\uff0c\u5e76\u4e3a\u4e0d\u540c\u5c5e\u6027\u4e0b\u7684\u8def\u5f84\u9009\u62e9\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u8def\u5f84\u96c6\u5408\u7684\u523b\u753b\u5fc5\u987b\u57fa\u4e8e\u5176\u6240\u5173\u6ce8\u7684\u5c5e\u6027\uff0c\u672c\u6587\u63d0\u51fa\u7684\u51fd\u6570\u6a21\u578b\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u4e14\u901a\u7528\u7684\u6570\u5b66\u6846\u67b6\u3002"}}
{"id": "2511.04798", "categories": ["cs.AR", "cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04798", "abs": "https://arxiv.org/abs/2511.04798", "authors": ["Matheus Farias", "Wanghley Martins", "H. T. Kung"], "title": "MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars", "comment": "5 pages, 6 figures", "summary": "Manhattan Distance Mapping (MDM) is a post-training deep neural network (DNN)\nweight mapping technique for memristive bit-sliced compute-in-memory (CIM)\ncrossbars that reduces parasitic resistance (PR) nonidealities.\n  PR limits crossbar efficiency by mapping DNN matrices into small crossbar\ntiles, reducing CIM-based speedup. Each crossbar executes one tile, requiring\ndigital synchronization before the next layer. At this granularity, designers\neither deploy many small crossbars in parallel or reuse a few sequentially-both\nincreasing analog-to-digital conversions, latency, I/O pressure, and chip area.\n  MDM alleviates PR effects by optimizing active-memristor placement.\nExploiting bit-level structured sparsity, it feeds activations from the denser\nlow-order side and reorders rows according to the Manhattan distance,\nrelocating active cells toward regions less affected by PR and thus lowering\nthe nonideality factor (NF).\n  Applied to DNN models on ImageNet-1k, MDM reduces NF by up to 46% and\nimproves accuracy under analog distortion by an average of 3.6% in ResNets.\nOverall, it provides a lightweight, spatially informed method for scaling CIM\nDNN accelerators.", "AI": {"tldr": "MDM \u662f\u4e00\u79cd\u7528\u4e8e\u5fc6\u963b\u5668\u4f4d\u5207\u7247\u5b58\u5185\u8ba1\u7b97\uff08CIM\uff09\u4ea4\u53c9\u9635\u5217\u7684\u8bad\u7ec3\u540e\u6743\u91cd\u6620\u5c04\u6280\u672f\uff0c\u901a\u8fc7\u4f18\u5316\u6d3b\u8dc3\u5fc6\u963b\u5668\u7684\u4f4d\u7f6e\u6765\u51cf\u8f7b\u5bc4\u751f\u7535\u963b\uff08PR\uff09\u975e\u7406\u60f3\u6027\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7cbe\u5ea6\u4e0e\u786c\u4ef6\u6548\u7387\u3002", "motivation": "\u5bc4\u751f\u7535\u963b\uff08PR\uff09\u9650\u5236\u4e86 CIM \u4ea4\u53c9\u9635\u5217\u7684\u6548\u7387\uff0c\u8feb\u4f7f DNN \u6743\u91cd\u77e9\u9635\u88ab\u5212\u5206\u4e3a\u5c0f\u5757\uff0c\u5bfc\u81f4\u6a21\u62df-\u6570\u5b57\u8f6c\u6362\u589e\u591a\u3001\u5ef6\u8fdf\u589e\u52a0\u3001I/O \u538b\u529b\u589e\u5927\u548c\u82af\u7247\u9762\u79ef\u4e0a\u5347\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u4e0d\u6539\u53d8\u786c\u4ef6\u7ed3\u6784\u7684\u524d\u63d0\u4e0b\u7f13\u89e3 PR \u5f71\u54cd\u3002", "method": "MDM \u5229\u7528\u4f4d\u7ea7\u7ed3\u6784\u7a00\u758f\u6027\uff0c\u5c06\u6765\u81ea\u4f4e\u9636\u5bc6\u96c6\u4fa7\u7684\u6fc0\u6d3b\u8f93\u5165\u4ea4\u53c9\u9635\u5217\uff0c\u5e76\u6839\u636e\u66fc\u54c8\u987f\u8ddd\u79bb\u5bf9\u884c\u8fdb\u884c\u91cd\u6392\u5e8f\uff0c\u5c06\u6d3b\u8dc3\u5355\u5143\u79fb\u81f3\u53d7 PR \u5f71\u54cd\u8f83\u5c0f\u7684\u533a\u57df\uff0c\u4ece\u800c\u964d\u4f4e\u975e\u7406\u60f3\u6027\u56e0\u5b50\uff08NF\uff09\u3002", "result": "\u5728 ImageNet-1k \u4e0a\u5bf9 DNN \u6a21\u578b\u5e94\u7528 MDM \u540e\uff0c\u975e\u7406\u60f3\u6027\u56e0\u5b50\u6700\u591a\u964d\u4f4e 46%\uff0c\u5728 ResNet \u4e2d\u5e73\u5747\u7cbe\u5ea6\u63d0\u5347 3.6%\u3002", "conclusion": "MDM \u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u4e14\u5177\u6709\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u6269\u5c55 CIM DNN \u52a0\u901f\u5668\u7684\u89c4\u6a21\u5e76\u63d0\u5347\u5176\u5728\u6a21\u62df\u975e\u7406\u60f3\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.05476", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05476", "abs": "https://arxiv.org/abs/2511.05476", "authors": ["Md. Abdul Awal", "Mrigank Rochan", "Chanchal K. Roy"], "title": "A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?", "comment": "The paper is currently under review at a peer-reviewed journal", "summary": "Transformer-based language models of code have achieved state-of-the-art\nperformance across a wide range of software analytics tasks, but their\npractical deployment remains limited due to high computational costs, slow\ninference speeds, and significant environmental impact. To address these\nchallenges, recent research has increasingly explored knowledge distillation as\na method for compressing a large language model of code (the teacher) into a\nsmaller model (the student) while maintaining performance. However, the degree\nto which a student model deeply mimics the predictive behavior and internal\nrepresentations of its teacher remains largely unexplored, as current\naccuracy-based evaluation provides only a surface-level view of model quality\nand often fails to capture more profound discrepancies in behavioral fidelity\nbetween the teacher and student models. To address this gap, we empirically\nshow that the student model often fails to deeply mimic the teacher model,\nresulting in up to 285% greater performance drop under adversarial attacks,\nwhich is not captured by traditional accuracy-based evaluation. Therefore, we\npropose MetaCompress, a metamorphic testing framework that systematically\nevaluates behavioral fidelity by comparing the outputs of teacher and student\nmodels under a set of behavior-preserving metamorphic relations. We evaluate\nMetaCompress on two widely studied tasks, using compressed versions of popular\nlanguage models of code, obtained via three different knowledge distillation\ntechniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress\nidentifies up to 62% behavioral discrepancies in student models, underscoring\nthe need for behavioral fidelity evaluation within the knowledge distillation\npipeline and establishing MetaCompress as a practical framework for testing\ncompressed language models of code derived through knowledge distillation.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5f53\u524d\u57fa\u4e8e\u51c6\u786e\u7387\u7684\u8bc4\u4f30\u65e0\u6cd5\u5145\u5206\u8861\u91cf\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u540e\u5b66\u751f\u6a21\u578b\u5bf9\u6559\u5e08\u6a21\u578b\u884c\u4e3a\u4fdd\u771f\u5ea6\u7684\u6a21\u4eff\u7a0b\u5ea6\uff0c\u4e3a\u6b64\u63d0\u51fa\u4e86\u540d\u4e3aMetaCompress\u7684\u5143\u8715\u53d8\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u884c\u4e3a\u4fdd\u6301\u7684\u8715\u53d8\u5173\u7cfb\u7cfb\u7edf\u8bc4\u4f30\u5e08\u751f\u6a21\u578b\u8f93\u51fa\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u84b8\u998f\u65b9\u6cd5\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u51c6\u786e\u7387\u7684\u8bc4\u4f30\u65b9\u6cd5\u4ec5\u80fd\u8868\u9762\u8861\u91cf\u538b\u7f29\u540e\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u96be\u4ee5\u63ed\u793a\u5176\u5728\u9884\u6d4b\u884c\u4e3a\u548c\u5185\u90e8\u8868\u793a\u4e0a\u4e0e\u6559\u5e08\u6a21\u578b\u7684\u6df1\u5c42\u5dee\u5f02\uff0c\u5c24\u5176\u5728\u9762\u5bf9\u5bf9\u6297\u653b\u51fb\u65f6\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6df1\u5165\u7684\u884c\u4e3a\u4fdd\u771f\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMetaCompress\u6846\u67b6\uff0c\u5229\u7528\u4e00\u7ec4\u884c\u4e3a\u4fdd\u6301\u7684\u8715\u53d8\u5173\u7cfb\uff0c\u7cfb\u7edf\u6bd4\u8f83\u6559\u5e08\u6a21\u578b\u4e0e\u5b66\u751f\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u4ece\u800c\u8bc4\u4f30\u77e5\u8bc6\u84b8\u998f\u8fc7\u7a0b\u4e2d\u5b66\u751f\u6a21\u578b\u5bf9\u6559\u5e08\u6a21\u578b\u884c\u4e3a\u7684\u6a21\u4eff\u7a0b\u5ea6\u3002", "result": "\u5728\u4e24\u4e2a\u5178\u578b\u4efb\u52a1\u548c\u4e09\u79cd\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff08Compressor\u3001AVATAR\u3001MORPH\uff09\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cMetaCompress\u6700\u591a\u53ef\u8bc6\u522b\u51fa62%\u7684\u5b66\u751f\u6a21\u578b\u884c\u4e3a\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4e14\u5b66\u751f\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u6027\u80fd\u4e0b\u964d\u9ad8\u8fbe285%\uff0c\u8fdc\u8d85\u4f20\u7edf\u8bc4\u4f30\u6240\u80fd\u53d1\u73b0\u7684\u95ee\u9898\u3002", "conclusion": "\u4f20\u7edf\u51c6\u786e\u7387\u8bc4\u4f30\u4e0d\u8db3\u4ee5\u53cd\u6620\u77e5\u8bc6\u84b8\u998f\u540e\u6a21\u578b\u7684\u884c\u4e3a\u4fdd\u771f\u5ea6\uff0cMetaCompress\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u5b9e\u7528\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u5e94\u88ab\u7eb3\u5165\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u538b\u7f29\u6d41\u7a0b\u4e2d\u4ee5\u4fdd\u969c\u6a21\u578b\u8d28\u91cf\u3002"}}
