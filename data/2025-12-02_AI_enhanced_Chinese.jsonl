{"id": "2511.21844", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21844", "abs": "https://arxiv.org/abs/2511.21844", "authors": ["Murat Yaslioglu"], "title": "A Sustainable and Reward Incentivized High-Performance Cluster Computing for Artificial Intelligence: A Novel Bayesian-Time-Decay Trust Mechanism in Blockchain", "comment": null, "summary": "In an age where sustainability is of paramount importance, the significance of both high-performance computing and intelligent algorithms cannot be understated. Yet, these domains often demand hefty computational power, translating to substantial energy usage and potentially sidelining less robust computing systems. It's evident that we need an approach that is more encompassing, scalable, and eco-friendly for intelligent algorithm development and implementation. The strategy we present in this paper offers a compelling answer to these issues. We unveil a fresh framework that seamlessly melds high-performance cluster computing with intelligent algorithms, all within a blockchain infrastructure. This promotes both efficiency and a broad-based participation. At its core, our design integrates an evolved proof-of-work consensus process, which links computational efforts directly to rewards for producing blocks. This ensures both optimal resource use and participation from a wide spectrum of computational capacities. Additionally, our approach incorporates a dynamic 'trust rating' that evolves based on a track record of accurate block validations. This rating determines the likelihood of a node being chosen for block generation, creating a merit-based system that recognizes and rewards genuine and precise contributions. To level the playing field further, we suggest a statistical 'draw' system, allowing even less powerful nodes a chance to be part of the block creation process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9ad8\u6027\u80fd\u96c6\u7fa4\u8ba1\u7b97\u3001\u667a\u80fd\u7b97\u6cd5\u4e0e\u533a\u5757\u94fe\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u5de5\u4f5c\u91cf\u8bc1\u660e\u673a\u5236\u3001\u52a8\u6001\u4fe1\u4efb\u8bc4\u5206\u548c\u7edf\u8ba1\u62bd\u7b7e\u7cfb\u7edf\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u516c\u5e73\u4e14\u73af\u4fdd\u7684\u667a\u80fd\u7b97\u6cd5\u90e8\u7f72\u3002", "motivation": "\u5f53\u524d\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u667a\u80fd\u7b97\u6cd5\u867d\u91cd\u8981\uff0c\u4f46\u80fd\u8017\u9ad8\u3001\u8d44\u6e90\u96c6\u4e2d\uff0c\u4e0d\u5229\u4e8e\u53ef\u6301\u7eed\u53d1\u5c55\u548c\u5e7f\u6cdb\u53c2\u4e0e\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u5305\u5bb9\u3001\u53ef\u6269\u5c55\u4e14\u73af\u4fdd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u878d\u5408\u9ad8\u6027\u80fd\u96c6\u7fa4\u8ba1\u7b97\u4e0e\u667a\u80fd\u7b97\u6cd5\u7684\u533a\u5757\u94fe\u6846\u67b6\uff0c\u5305\u542b\u6539\u8fdb\u7684PoW\u5171\u8bc6\u673a\u5236\u3001\u57fa\u4e8e\u9a8c\u8bc1\u51c6\u786e\u6027\u7684\u52a8\u6001\u4fe1\u4efb\u8bc4\u5206\u673a\u5236\uff0c\u4ee5\u53ca\u5141\u8bb8\u4f4e\u7b97\u529b\u8282\u70b9\u53c2\u4e0e\u7684\u7edf\u8ba1\u62bd\u7b7e\u7cfb\u7edf\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u5347\u4e86\u8d44\u6e90\u5229\u7528\u6548\u7387\uff0c\u6269\u5927\u4e86\u4e0d\u540c\u8ba1\u7b97\u80fd\u529b\u8282\u70b9\u7684\u53c2\u4e0e\u673a\u4f1a\uff0c\u5e76\u901a\u8fc7\u4fe1\u4efb\u673a\u5236\u6fc0\u52b1\u51c6\u786e\u8d21\u732e\uff0c\u4ece\u800c\u5728\u4fdd\u969c\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u516c\u5e73\u6027\u4e0e\u53ef\u6301\u7eed\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u8ba1\u7b97\u6548\u7387\u3001\u53c2\u4e0e\u516c\u5e73\u6027\u4e0e\u80fd\u6e90\u53ef\u6301\u7eed\u6027\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u7b97\u6cd5\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.21859", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21859", "abs": "https://arxiv.org/abs/2511.21859", "authors": ["Hagit Attiya", "Armando Casta\u00f1eda", "Dhrubajyoti Ghosh", "Thomas Nowak"], "title": "Equivalence and Separation between Heard-Of and Asynchronous Message-Passing Models", "comment": "18 pages", "summary": "We revisit the relationship between two fundamental models of distributed computation: the asynchronous message-passing model with up to $f$ crash failures ($\\operatorname{AMP}_f$) and the Heard-Of model with up to $f$ message omissions ($\\operatorname{HO}_f$). We show that for $n > 2f$, the two models are equivalent with respect to the solvability of colorless tasks, and that for colored tasks the equivalence holds only when $f = 1$ (and $n > 2$). The separation for larger $f$ arises from the presence of silenced processes in $\\operatorname{HO}_f$, which may lead to incompatible decisions. The proofs proceed through bidirectional simulations between $\\operatorname{AMP}_f$ and $\\operatorname{HO}_f$ via an intermediate model that captures this notion of silencing. The results extend to randomized protocols against a non-adaptive adversary, indicating that the expressive limits of canonical rounds are structural rather than probabilistic. Together, these results delineate precisely where round-based abstractions capture asynchronous computation, and where they do not.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f02\u6b65\u6d88\u606f\u4f20\u9012\u6a21\u578b\uff08AMP_f\uff09\u4e0eHeard-Of\u6a21\u578b\uff08HO_f\uff09\u5728\u5bb9\u9519\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u53d1\u73b0\u5bf9\u4e8e\u65e0\u8272\u4efb\u52a1\u5728 n > 2f \u65f6\u4e24\u8005\u7b49\u4ef7\uff0c\u800c\u5bf9\u6709\u8272\u4efb\u52a1\u4ec5\u5728 f = 1 \u4e14 n > 2 \u65f6\u7b49\u4ef7\uff1b\u5dee\u5f02\u6e90\u4e8e HO_f \u4e2d\u5b58\u5728\u201c\u9759\u9ed8\u201d\u8fdb\u7a0b\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u4e00\u81f4\u51b3\u7b56\u3002", "motivation": "\u5398\u6e05\u4e24\u79cd\u4e3b\u6d41\u5206\u5e03\u5f0f\u8ba1\u7b97\u6a21\u578b\uff08AMP_f \u4e0e HO_f\uff09\u4e4b\u95f4\u7684\u8868\u8fbe\u80fd\u529b\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u6545\u969c\u6570\u91cf\u548c\u4efb\u52a1\u7c7b\u578b\u4e0b\u7684\u53ef\u89e3\u6027\u7b49\u4ef7\u6027\uff0c\u4ee5\u660e\u786e\u57fa\u4e8e\u8f6e\u6b21\u7684\u62bd\u8c61\u6a21\u578b\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u80fd\u51c6\u786e\u523b\u753b\u5f02\u6b65\u8ba1\u7b97\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u53cc\u5411\u6a21\u62df\uff0c\u5728 AMP_f \u4e0e HO_f \u4e4b\u95f4\u5f15\u5165\u4e00\u4e2a\u4e2d\u95f4\u6a21\u578b\u6765\u523b\u753b\u201c\u9759\u9ed8\u201d\u884c\u4e3a\uff0c\u5e76\u5206\u522b\u8bc1\u660e\u5728\u65e0\u8272\u4efb\u52a1\u548c\u6709\u8272\u4efb\u52a1\u4e0b\u4e24\u8005\u7684\u7b49\u4ef7\u6216\u5206\u79bb\u6761\u4ef6\uff1b\u540c\u65f6\u5c06\u7ed3\u679c\u6269\u5c55\u81f3\u975e\u81ea\u9002\u5e94\u654c\u624b\u4e0b\u7684\u968f\u673a\u534f\u8bae\u3002", "result": "\u8bc1\u660e\u4e86\u5f53 n > 2f \u65f6\uff0cAMP_f \u4e0e HO_f \u5bf9\u65e0\u8272\u4efb\u52a1\u7b49\u4ef7\uff1b\u5bf9\u6709\u8272\u4efb\u52a1\uff0c\u4ec5\u5f53 f = 1 \u4e14 n > 2 \u65f6\u7b49\u4ef7\uff1b\u66f4\u5927\u7684 f \u503c\u4f1a\u5bfc\u81f4 HO_f \u4e2d\u56e0\u9759\u9ed8\u8fdb\u7a0b\u800c\u65e0\u6cd5\u8fbe\u6210\u4e00\u81f4\uff0c\u4ece\u800c\u7834\u574f\u7b49\u4ef7\u6027\uff1b\u8be5\u7ed3\u8bba\u5728\u968f\u673a\u534f\u8bae\u4e0b\u4f9d\u7136\u6210\u7acb\u3002", "conclusion": "\u57fa\u4e8e\u8f6e\u6b21\u7684 Heard-Of \u6a21\u578b\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff08\u5982\u65e0\u8272\u4efb\u52a1\u6216 f=1 \u7684\u6709\u8272\u4efb\u52a1\uff09\u80fd\u591f\u7cbe\u786e\u6355\u6349\u5f02\u6b65\u6d88\u606f\u4f20\u9012\u6a21\u578b\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u4f46\u5728\u66f4\u4e00\u822c\u7684\u6709\u8272\u4efb\u52a1\u548c\u9ad8\u5bb9\u9519\u573a\u666f\u4e2d\u5b58\u5728\u7ed3\u6784\u6027\u5c40\u9650\u3002"}}
{"id": "2511.21862", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21862", "abs": "https://arxiv.org/abs/2511.21862", "authors": ["Siyu Wu", "Zihan Tang", "Yuting Zeng", "Hui Chen", "Guiguang Ding", "Tongxuan Liu", "Ke Zhang", "Hailong Yang"], "title": "OOCO: Latency-disaggregated Architecture for Online-Offline Co-locate LLM Serving", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in both latency-sensitive online services and cost-sensitive offline workloads. Co-locating these workloads on shared serving instances can improve resource utilization, but directly applying this approach to Prefill/Decode (P/D) disaggregated systems introduces severe load imbalance, as fluctuating request mixes alter the intrinsic P/D ratio. Existing dynamic adjustment techniques cannot keep up with the bursty traffic patterns of online services.\n  We propose a latency-constraint disaggregated architecture, which separates cluster resources into latency-strict and latency-relaxed pools based on task latency requirements. This design enables flexible placement of offline decode tasks, mitigating P/D imbalance while preserving online performance. To fully exploit this flexibility, we propose (1) a bottleneck-based scheduler guided by a Roofline-based performance model for performance bottleneck based scheduling, and (2) a fast preemption mechanism that strictly enforces Service Level Objectives (SLOs) for online requests.\n  Experiments on real-world traces show that compared to existing offline system approaches, our method improves offline throughput by up to 3x, while maintaining online request SLOs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9762\u5411\u5ef6\u8fdf\u7ea6\u675f\u7684\u89e3\u8026\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u79bb\u5ef6\u8fdf\u654f\u611f\u4e0e\u975e\u654f\u611f\u4efb\u52a1\u6c60\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u74f6\u9888\u7684\u8c03\u5ea6\u5668\u548c\u5feb\u901f\u62a2\u5360\u673a\u5236\uff0c\u5728\u4fdd\u969c\u5728\u7ebf\u8bf7\u6c42SLO\u7684\u540c\u65f6\uff0c\u5c06\u79bb\u7ebf\u541e\u5410\u91cf\u63d0\u5347\u6700\u9ad83\u500d\u3002", "motivation": "\u5728Prefill/Decode\u89e3\u8026\u7cfb\u7edf\u4e2d\uff0c\u76f4\u63a5\u5171\u7f6e\u5ef6\u8fdf\u654f\u611f\u7684\u5728\u7ebf\u670d\u52a1\u4e0e\u6210\u672c\u654f\u611f\u7684\u79bb\u7ebf\u4efb\u52a1\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\uff0c\u800c\u73b0\u6709\u52a8\u6001\u8c03\u6574\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5728\u7ebf\u670d\u52a1\u7a81\u53d1\u6d41\u91cf\u3002", "method": "\u8bbe\u8ba1\u5ef6\u8fdf\u7ea6\u675f\u89e3\u8026\u67b6\u6784\uff0c\u5c06\u96c6\u7fa4\u8d44\u6e90\u5212\u5206\u4e3a\u5ef6\u8fdf\u4e25\u683c\u4e0e\u5ef6\u8fdf\u5bbd\u677e\u6c60\uff1b\u5f15\u5165\u57fa\u4e8eRoofline\u6a21\u578b\u7684\u74f6\u9888\u611f\u77e5\u8c03\u5ea6\u5668\uff0c\u5e76\u5b9e\u73b0\u5feb\u901f\u62a2\u5360\u673a\u5236\u4ee5\u4fdd\u969c\u5728\u7ebf\u8bf7\u6c42\u7684SLO\u3002", "result": "\u5728\u771f\u5b9e\u8f68\u8ff9\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u79bb\u7ebf\u7cfb\u7edf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u6ee1\u8db3\u5728\u7ebf\u8bf7\u6c42SLO\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u79bb\u7ebf\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53473\u500d\u3002", "conclusion": "\u6240\u63d0\u67b6\u6784\u6709\u6548\u7f13\u89e3\u4e86P/D\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u5728\u4fdd\u969c\u5728\u7ebf\u670d\u52a1\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u79bb\u7ebf\u4efb\u52a1\u541e\u5410\u80fd\u529b\u3002"}}
{"id": "2511.21958", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21958", "abs": "https://arxiv.org/abs/2511.21958", "authors": ["Yiyan Zhai", "Bintang Dwi Marthen", "Sarath Balivada", "Vamsi Sudhakar Bojji", "Eric Knauft", "Jitender Rohilla", "Jiaqi Zuo", "Quanxing Liu", "Maxime Austruy", "Wenguang Wang", "Juncheng Yang"], "title": "Clock2Q+: A Simple and Efficient Replacement Algorithm for Metadata Cache in VMware vSAN", "comment": "12 pages, 14 figures", "summary": "Cache replacement algorithms are critical building blocks of storage systems. This paper examines the characteristics of metadata caches and argues that they inherently exhibit correlated references, even when the corresponding data accesses do not contain correlated references. The presence of correlated references reduces the effectiveness of cache replacement algorithms because these references are often mistakenly categorized as hot blocks. Clock2Q+ is specifically designed for metadata caches and has been implemented in vSAN and VDFS, two flagship storage products of VMware by Broadcom. Similar to S3-FIFO, Clock2Q+ uses three queues; however, Clock2Q+ introduces a correlation window in the Small FIFO queue, where blocks in this window do not set the reference bit. This simple enhancement allows Clock2Q+ to outperform state-of-the-art replacement algorithms. Compared to S3-FIFO, the second-best performing algorithm, Clock2Q+ achieves up to a 28.5% lower miss ratio on metadata traces. Clock2Q+ possesses the essential properties required for large-scale storage systems: it has low CPU overhead on cache hits, low memory overhead, scales efficiently to multiple CPUs, and is both easy to tune and implement. Additionally, Clock2Q+ outperforms state-of-the-art cache replacement algorithms on data traces as well.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u5143\u6570\u636e\u7f13\u5b58\u8bbe\u8ba1\u7684\u65b0\u578b\u7f13\u5b58\u66ff\u6362\u7b97\u6cd5Clock2Q+\uff0c\u901a\u8fc7\u5728Small FIFO\u961f\u5217\u4e2d\u5f15\u5165\u76f8\u5173\u6027\u7a97\u53e3\u6765\u907f\u514d\u5c06\u76f8\u5173\u5f15\u7528\u8bef\u5224\u4e3a\u70ed\u70b9\u5757\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u7f13\u5b58\u672a\u547d\u4e2d\u7387\u3002\u8be5\u7b97\u6cd5\u5df2\u5728VMware\u7684vSAN\u548cVDFS\u4ea7\u54c1\u4e2d\u5b9e\u73b0\uff0c\u5177\u6709\u4f4eCPU\u5f00\u9500\u3001\u4f4e\u5185\u5b58\u5f00\u9500\u3001\u826f\u597d\u7684\u591a\u6838\u6269\u5c55\u6027\u4ee5\u53ca\u6613\u4e8e\u8c03\u4f18\u548c\u5b9e\u73b0\u7b49\u4f18\u70b9\u3002", "motivation": "\u5143\u6570\u636e\u7f13\u5b58\u4e2d\u5b58\u5728\u56fa\u6709\u7684\u76f8\u5173\u5f15\u7528\uff0c\u5373\u4f7f\u5bf9\u5e94\u7684\u6570\u636e\u8bbf\u95ee\u6ca1\u6709\u76f8\u5173\u6027\u3002\u8fd9\u79cd\u76f8\u5173\u5f15\u7528\u4f1a\u8bef\u5bfc\u4f20\u7edf\u7f13\u5b58\u66ff\u6362\u7b97\u6cd5\uff0c\u4f7f\u5176\u5c06\u975e\u70ed\u70b9\u5757\u8bef\u5224\u4e3a\u70ed\u70b9\u5757\uff0c\u4ece\u800c\u964d\u4f4e\u7f13\u5b58\u6548\u7387\u3002", "method": "Clock2Q+\u57fa\u4e8eS3-FIFO\u7684\u4e09\u961f\u5217\u7ed3\u6784\uff0c\u5728Small FIFO\u961f\u5217\u4e2d\u5f15\u5165\u4e00\u4e2a\u201c\u76f8\u5173\u6027\u7a97\u53e3\u201d\uff0c\u5904\u4e8e\u8be5\u7a97\u53e3\u5185\u7684\u5757\u4e0d\u4f1a\u8bbe\u7f6e\u5f15\u7528\u4f4d\uff0c\u4ece\u800c\u907f\u514d\u5c06\u76f8\u5173\u5f15\u7528\u8bef\u8ba4\u4e3a\u9891\u7e41\u8bbf\u95ee\u7684\u70ed\u70b9\u5757\u3002", "result": "\u5728\u5143\u6570\u636e\u8f68\u8ff9\u4e0a\uff0cClock2Q+\u76f8\u6bd4\u6b21\u4f18\u7b97\u6cd5S3-FIFO\u6700\u591a\u53ef\u964d\u4f4e28.5%\u7684\u672a\u547d\u4e2d\u7387\uff1b\u540c\u65f6\u5728\u6570\u636e\u8f68\u8ff9\u4e0a\u4e5f\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u5b83\u5177\u5907\u4f4eCPU\u5f00\u9500\uff08\u547d\u4e2d\u65f6\uff09\u3001\u4f4e\u5185\u5b58\u5f00\u9500\u3001\u826f\u597d\u7684\u591a\u6838\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u4e14\u6613\u4e8e\u5b9e\u73b0\u548c\u8c03\u4f18\u3002", "conclusion": "Clock2Q+\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u7528\u4e14\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5b58\u50a8\u7cfb\u7edf\u7684\u7f13\u5b58\u66ff\u6362\u7b97\u6cd5\uff0c\u7279\u522b\u9002\u5408\u5904\u7406\u5143\u6570\u636e\u7f13\u5b58\u4e2d\u7684\u76f8\u5173\u5f15\u7528\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u5de5\u7a0b\u5b9e\u73b0\u4e0a\u5747\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2511.21942", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.21942", "abs": "https://arxiv.org/abs/2511.21942", "authors": ["Elisa Quintarelli", "Fabio Alberto Schreiber", "Kostas Stefanidis", "Letizia Tanca", "Barbara Oliboni"], "title": "A Conceptual Model for Context Awareness in Ethical Data Management", "comment": "14 pages, 3 figures", "summary": "Ethics has become a major concern to the information management community, as both algorithms and data should satisfy ethical rules that guarantee not to generate dishonourable behaviours when they are used. However, these ethical rules may vary according to the situation-the context-in which the application programs must work. In this paper, after reviewing the basic ethical concepts and their possible influence on data management, we propose a bipartite conceptual model, composed of the Context Dimensions Tree (CDT), which describes the possible contexts, and the Ethical Requirements Tree (ERT), representing the ethical rules necessary to tailor and preprocess the datasets that should be fed to Data Analysis and Learning Systems in each possible context. We provide some examples and suggestions on how these conceptual tools can be used.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5206\u652f\u6982\u5ff5\u6a21\u578b\uff0c\u7528\u4e8e\u6839\u636e\u5e94\u7528\u573a\u666f\u7684\u4e0a\u4e0b\u6587\u52a8\u6001\u9002\u914d\u6570\u636e\u4f26\u7406\u89c4\u5219\uff0c\u4ee5\u786e\u4fdd\u6570\u636e\u5206\u6790\u4e0e\u5b66\u4e60\u7cfb\u7edf\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u7b26\u5408\u76f8\u5e94\u7684\u4f26\u7406\u8981\u6c42\u3002", "motivation": "\u7531\u4e8e\u7b97\u6cd5\u548c\u6570\u636e\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u4ea7\u751f\u4e0d\u9053\u5fb7\u884c\u4e3a\uff0c\u800c\u4f26\u7406\u89c4\u5219\u53c8\u968f\u5e94\u7528\u60c5\u5883\uff08\u4e0a\u4e0b\u6587\uff09\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u6839\u636e\u4e0a\u4e0b\u6587\u7075\u6d3b\u8c03\u6574\u4f26\u7406\u89c4\u8303\u7684\u65b9\u6cd5\u6765\u6307\u5bfc\u6570\u636e\u7ba1\u7406\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u7531\u201c\u4e0a\u4e0b\u6587\u7ef4\u5ea6\u6811\u201d\uff08CDT\uff09\u548c\u201c\u4f26\u7406\u9700\u6c42\u6811\u201d\uff08ERT\uff09\u7ec4\u6210\u7684\u53cc\u5206\u652f\u6982\u5ff5\u6a21\u578b\u3002CDT \u63cf\u8ff0\u53ef\u80fd\u7684\u5e94\u7528\u4e0a\u4e0b\u6587\uff0cERT \u8868\u793a\u5728\u5404\u4e0a\u4e0b\u6587\u4e2d\u6240\u9700\u9075\u5b88\u7684\u4f26\u7406\u89c4\u5219\uff0c\u7528\u4ee5\u6307\u5bfc\u6570\u636e\u96c6\u7684\u5b9a\u5236\u4e0e\u9884\u5904\u7406\u3002", "result": "\u8be5\u6a21\u578b\u4e3a\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u7684\u6570\u636e\u4f26\u7406\u9700\u6c42\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8868\u8fbe\u65b9\u5f0f\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528 CDT \u548c ERT \u6307\u5bfc\u6570\u636e\u9884\u5904\u7406\u548c\u7cfb\u7edf\u8bbe\u8ba1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53cc\u5206\u652f\u6982\u5ff5\u6a21\u578b\u6709\u52a9\u4e8e\u5c06\u4f26\u7406\u89c4\u5219\u5d4c\u5165\u6570\u636e\u7ba1\u7406\u6d41\u7a0b\u4e2d\uff0c\u63d0\u5347\u4fe1\u606f\u7ba1\u7406\u7cfb\u7edf\u5728\u591a\u6837\u5316\u5e94\u7528\u573a\u666f\u4e0b\u7684\u4f26\u7406\u5408\u89c4\u6027\u3002"}}
{"id": "2511.22185", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.22185", "abs": "https://arxiv.org/abs/2511.22185", "authors": ["Ruize Gao", "Feng Xiao", "Jinpu Li", "Shaoze Cui"], "title": "Textual semantics and machine learning methods for data product pricing", "comment": null, "summary": "Reasonable pricing of data products enables data trading platforms to maximize revenue and foster the growth of the data trading market. The textual semantics of data products are vital for pricing and contain significant value that remains largely underexplored. Therefore, to investigate how textual features influence data product pricing, we employ five prevalent text representation techniques to encode the descriptive text of data products. And then, we employ six machine learning methods to predict data product prices, including linear regression, neural networks, decision trees, support vector machines, random forests, and XGBoost. Our empirical design consists of two tasks: a regression task that predicts the continuous price of data products, and a classification task that discretizes price into ordered categories. Furthermore, we conduct feature importance analysis by the mRMR feature selection method and SHAP-based interpretability techniques. Based on empirical data from the AWA Data Exchange, we find that for predicting continuous prices, Word2Vec text representations capturing semantic similarity yield superior performance. In contrast, for price-tier classification tasks, simpler representations that do not rely on semantic similarity, such as Bag-of-Words and TF-IDF, perform better. SHAP analysis reveals that semantic features related to healthcare and demographics tend to increase prices, whereas those associated with weather and environmental topics are linked to lower prices. This analytical framework significantly enhances the interpretability of pricing models.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u591a\u79cd\u6587\u672c\u8868\u793a\u65b9\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6570\u636e\u4ea7\u54c1\u7684\u4ef7\u683c\uff0c\u53d1\u73b0Word2Vec\u5728\u8fde\u7eed\u4ef7\u683c\u9884\u6d4b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u800cBag-of-Words\u548cTF-IDF\u5728\u4ef7\u683c\u7b49\u7ea7\u5206\u7c7b\u4efb\u52a1\u4e2d\u66f4\u4f18\uff1bSHAP\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u8bed\u4e49\u7279\u5f81\u5bf9\u4ef7\u683c\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u6570\u636e\u4ea7\u54c1\u63cf\u8ff0\u6587\u672c\u7684\u8bed\u4e49\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u5176\u5b9a\u4ef7\uff0c\u4ee5\u63d0\u5347\u6570\u636e\u4ea4\u6613\u5e73\u53f0\u7684\u6536\u5165\u4e0e\u5e02\u573a\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u4e94\u79cd\u6587\u672c\u8868\u793a\u65b9\u6cd5\uff08\u5982Word2Vec\u3001Bag-of-Words\u3001TF-IDF\u7b49\uff09\u5bf9\u6570\u636e\u4ea7\u54c1\u63cf\u8ff0\u6587\u672c\u8fdb\u884c\u7f16\u7801\uff0c\u5e76\u7ed3\u5408\u516d\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982\u7ebf\u6027\u56de\u5f52\u3001XGBoost\u7b49\uff09\u8fdb\u884c\u4ef7\u683c\u9884\u6d4b\uff1b\u540c\u65f6\u5229\u7528mRMR\u548cSHAP\u65b9\u6cd5\u8fdb\u884c\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u3002", "result": "\u5728\u8fde\u7eed\u4ef7\u683c\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684Word2Vec\u8868\u73b0\u6700\u4f18\uff1b\u5728\u4ef7\u683c\u7b49\u7ea7\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u975e\u8bed\u4e49\u65b9\u6cd5\uff08\u5982Bag-of-Words\u548cTF-IDF\uff09\u6548\u679c\u66f4\u597d\u3002SHAP\u5206\u6790\u663e\u793a\u533b\u7597\u4e0e\u4eba\u53e3\u7edf\u8ba1\u76f8\u5173\u8bed\u4e49\u7279\u5f81\u63a8\u9ad8\u4ef7\u683c\uff0c\u800c\u5929\u6c14\u4e0e\u73af\u5883\u7c7b\u7279\u5f81\u5219\u4e0e\u8f83\u4f4e\u4ef7\u683c\u76f8\u5173\u3002", "conclusion": "\u6587\u672c\u8bed\u4e49\u5bf9\u6570\u636e\u4ea7\u54c1\u5b9a\u4ef7\u5177\u6709\u663e\u8457\u5f71\u54cd\uff0c\u7ed3\u5408\u5408\u9002\u7684\u6587\u672c\u8868\u793a\u65b9\u6cd5\u548c\u53ef\u89e3\u91ca\u6027\u6280\u672f\u53ef\u6709\u6548\u63d0\u5347\u5b9a\u4ef7\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.21769", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.21769", "abs": "https://arxiv.org/abs/2511.21769", "authors": ["Royer David Estrada-Esponda", "Gerardo Matturro", "Jose Reinaldo Sabogal-Pinilla"], "title": "Technical knowledge and soft skills in software startups within the Colombian entrepreneurial ecosystem", "comment": "30 pages", "summary": "The technical knowledge and soft skills of entrepreneurial team members significantly impact the early stages of software startups. It is widely recognized that the success or failure of a startup is determined by the quality of the individuals who constitute the founding team. This article presents the findings of a study conducted within the Colombian entrepreneurial ecosystem, focusing on which technical knowledge and soft skills are the most valued by founding teams of software startups, and how the needs for knowledge and skills evolve as the startup grows. A survey of software startup representatives revealed that the most valued knowledge includes requirements engineering, software testing, project planning and management, agile methodologies, marketing, business model definition, and budgeting. The most valued soft skills are typically communication, leadership, and teamwork. The outcomes of this work are relevant to software entrepreneurs, incubators, and researchers.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u54e5\u4f26\u6bd4\u4e9a\u8f6f\u4ef6\u521d\u521b\u4f01\u4e1a\u521b\u59cb\u56e2\u961f\u5728\u4e0d\u540c\u53d1\u5c55\u9636\u6bb5\u6700\u91cd\u89c6\u7684\u6280\u672f\u77e5\u8bc6\uff08\u5982\u9700\u6c42\u5de5\u7a0b\u3001\u8f6f\u4ef6\u6d4b\u8bd5\u3001\u654f\u6377\u65b9\u6cd5\u7b49\uff09\u548c\u8f6f\u6280\u80fd\uff08\u5982\u6c9f\u901a\u3001\u9886\u5bfc\u529b\u3001\u56e2\u961f\u5408\u4f5c\uff09\uff0c\u4e3a\u521b\u4e1a\u8005\u3001\u5b75\u5316\u5668\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u521d\u521b\u4f01\u4e1a\u7684\u6210\u8d25\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u521b\u59cb\u56e2\u961f\u6210\u5458\u7684\u8d28\u91cf\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u4e86\u89e3\u5728\u8f6f\u4ef6\u521d\u521b\u4f01\u4e1a\u65e9\u671f\u53ca\u6210\u957f\u9636\u6bb5\uff0c\u54ea\u4e9b\u6280\u672f\u77e5\u8bc6\u548c\u8f6f\u6280\u80fd\u6700\u53d7\u91cd\u89c6\u3002", "method": "\u901a\u8fc7\u5bf9\u54e5\u4f26\u6bd4\u4e9a\u8f6f\u4ef6\u521d\u521b\u4f01\u4e1a\u4ee3\u8868\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u6536\u96c6\u5e76\u5206\u6790\u521b\u59cb\u56e2\u961f\u5bf9\u5404\u7c7b\u6280\u672f\u77e5\u8bc6\u548c\u8f6f\u6280\u80fd\u7684\u91cd\u89c6\u7a0b\u5ea6\u53ca\u5176\u968f\u4f01\u4e1a\u53d1\u5c55\u9636\u6bb5\u7684\u53d8\u5316\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6700\u53d7\u91cd\u89c6\u7684\u6280\u672f\u77e5\u8bc6\u5305\u62ec\u9700\u6c42\u5de5\u7a0b\u3001\u8f6f\u4ef6\u6d4b\u8bd5\u3001\u9879\u76ee\u89c4\u5212\u4e0e\u7ba1\u7406\u3001\u654f\u6377\u65b9\u6cd5\u3001\u5e02\u573a\u8425\u9500\u3001\u5546\u4e1a\u6a21\u5f0f\u5b9a\u4e49\u548c\u9884\u7b97\u7f16\u5236\uff1b\u6700\u53d7\u91cd\u89c6\u7684\u8f6f\u6280\u80fd\u662f\u6c9f\u901a\u3001\u9886\u5bfc\u529b\u548c\u56e2\u961f\u5408\u4f5c\u3002", "conclusion": "\u8be5\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u8f6f\u4ef6\u521b\u4e1a\u8005\u3001\u5b75\u5316\u5668\u548c\u7814\u7a76\u4eba\u5458\u66f4\u597d\u5730\u7406\u89e3\u521d\u521b\u56e2\u961f\u80fd\u529b\u5efa\u8bbe\u7684\u5173\u952e\u8981\u7d20\uff0c\u4ece\u800c\u5728\u4e0d\u540c\u9636\u6bb5\u6709\u9488\u5bf9\u6027\u5730\u57f9\u517b\u6216\u62db\u52df\u5177\u5907\u76f8\u5e94\u77e5\u8bc6\u4e0e\u6280\u80fd\u7684\u4eba\u624d\u3002"}}
{"id": "2511.22035", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.22035", "abs": "https://arxiv.org/abs/2511.22035", "authors": ["Amirhossein Alizad", "Mostafa Milani"], "title": "Relation-Stratified Sampling for Shapley Values Estimation in Relational Databases", "comment": "10 Pages, Conference Paper", "summary": "Shapley-like values, including the Shapley and Banzhaf values, provide a principled way to quantify how individual tuples contribute to a query result. Their exact computation, however, is intractable because it requires aggregating marginal contributions over exponentially many permutations or subsets. While sampling-based estimators have been studied in cooperative game theory, their direct use for relational query answering remains underexplored and often ignores the structure of schemas and joins.\n  We study tuple-level attribution for relational queries through sampling and introduce Relation-Stratified Sampling (RSS). Instead of stratifying coalitions only by size, RSS partitions the sample space by a relation-wise count vector that records how many tuples are drawn from each relation. This join-aware stratification concentrates samples on structurally valid and informative coalitions and avoids strata that cannot satisfy query conditions. We further develop an adaptive variant, ARSS, that reallocates budget across strata using variance estimates obtained during sampling, improving estimator efficiency without increasing the total number of samples. We analyze these estimators, describe a practical implementation that reuses compiled views to reduce per-sample query cost, and evaluate them on TPCH workloads.\n  Across diverse queries with multi-relation joins and aggregates, RSS and ARSS consistently outperform classical Monte Carlo (MCS) and size-based Stratified Sampling (SS), yielding lower error and variance with fewer samples. An ablation shows that relation-aware stratification and adaptive allocation contribute complementary gains, making ARSS a simple, effective, and anytime estimator for database-centric Shapley attribution.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5173\u7cfb\u67e5\u8be2\u4e2d\u5143\u7ec4\u7ea7\u5f52\u56e0\u7684\u91c7\u6837\u65b9\u6cd5\u2014\u2014\u5173\u7cfb\u5206\u5c42\u91c7\u6837\uff08RSS\uff09\u53ca\u5176\u81ea\u9002\u5e94\u53d8\u4f53ARSS\uff0c\u901a\u8fc7\u8003\u8651\u5173\u7cfb\u7ed3\u6784\u548c\u8fde\u63a5\u4fe1\u606f\uff0c\u5728\u51cf\u5c11\u6837\u672c\u6570\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u4f30\u8ba1\u8bef\u5dee\u548c\u65b9\u5dee\u3002", "motivation": "\u7cbe\u786e\u8ba1\u7b97Shapley\u7c7b\u503c\u5728\u5173\u7cfb\u67e5\u8be2\u4e2d\u4e0d\u53ef\u884c\uff0c\u56e0\u5176\u9700\u5bf9\u6307\u6570\u7ea7\u591a\u7684\u6392\u5217\u6216\u5b50\u96c6\u8fdb\u884c\u805a\u5408\uff1b\u73b0\u6709\u57fa\u4e8e\u91c7\u6837\u7684\u4f30\u8ba1\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u5173\u7cfb\u6a21\u5f0f\u548c\u8fde\u63a5\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u5173\u7cfb\u5206\u5c42\u91c7\u6837\uff08RSS\uff09\uff0c\u6309\u6bcf\u4e2a\u5173\u7cfb\u4e2d\u62bd\u53d6\u7684\u5143\u7ec4\u6570\u91cf\u5411\u91cf\u5212\u5206\u6837\u672c\u7a7a\u95f4\uff0c\u4ee5\u805a\u7126\u4e8e\u7ed3\u6784\u6709\u6548\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u8054\u76df\uff1b\u8fdb\u4e00\u6b65\u63d0\u51fa\u81ea\u9002\u5e94\u7248\u672cARSS\uff0c\u6839\u636e\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u65b9\u5dee\u4f30\u8ba1\u52a8\u6001\u5206\u914d\u5404\u5c42\u91c7\u6837\u9884\u7b97\uff0c\u5e76\u5229\u7528\u7f16\u8bd1\u89c6\u56fe\u964d\u4f4e\u5355\u6b21\u91c7\u6837\u67e5\u8be2\u5f00\u9500\u3002", "result": "\u5728TPCH\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRSS\u548cARSS\u5728\u591a\u79cd\u542b\u591a\u5173\u7cfb\u8fde\u63a5\u4e0e\u805a\u5408\u7684\u67e5\u8be2\u4e2d\uff0c\u76f8\u6bd4\u7ecf\u5178\u8499\u7279\u5361\u6d1b\u91c7\u6837\uff08MCS\uff09\u548c\u57fa\u4e8e\u5927\u5c0f\u7684\u5206\u5c42\u91c7\u6837\uff08SS\uff09\uff0c\u80fd\u4ee5\u66f4\u5c11\u6837\u672c\u83b7\u5f97\u66f4\u4f4e\u7684\u8bef\u5dee\u548c\u65b9\u5dee\u3002", "conclusion": "\u5173\u7cfb\u611f\u77e5\u7684\u5206\u5c42\u7b56\u7565\u4e0e\u81ea\u9002\u5e94\u9884\u7b97\u5206\u914d\u76f8\u7ed3\u5408\uff0c\u4f7fARSS\u6210\u4e3a\u4e00\u79cd\u7b80\u5355\u3001\u9ad8\u6548\u4e14\u9002\u7528\u4e8e\u4efb\u610f\u65f6\u95f4\u7684\u6570\u636e\u5e93\u4e2d\u5fc3Shapley\u5f52\u56e0\u4f30\u8ba1\u5668\u3002"}}
{"id": "2511.23016", "categories": ["cs.CE", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.23016", "abs": "https://arxiv.org/abs/2511.23016", "authors": ["Moritz H\u00fctten"], "title": "Maritime Activities Observed Through Open-Access Positioning Data: Moving and Stationary Vessels in the Baltic Sea", "comment": "29 pages, 15 figures, and 9 tables, matching the version published in Geomatics. Accompanying research data are available at http://dx.doi.org/10.6084/m9.figshare.29062715", "summary": "Understanding past and present maritime activity patterns is critical for navigation safety, environmental assessment, and commercial operations. An increasing number of services now openly provide positioning data from the Automatic Identification System (AIS) via ground-based receivers. We show that coastal vessel activity can be reconstructed from open access data with high accuracy, even with limited data quality and incomplete receiver coverage. For three months of open AIS data in the Baltic Sea from August to October 2024, we present (i) cleansing and reconstruction methods to improve the data quality, and (ii) a journey model that converts AIS message data into vessel counts, traffic estimates, and spatially resolved vessel density at a resolution of $\\sim$400 m. Vessel counts are provided, along with their uncertainties, for both moving and stationary activity. Vessel density maps also enable the identification of port locations, and we infer the most crowded and busiest coastal areas in the Baltic Sea. We find that on average, $\\gtrsim$4000 vessels simultaneously operate in the Baltic Sea, and more than 300 vessels enter or leave the area each day. Our results agree within 20\\% with previous studies relying on proprietary data.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u516c\u5f00\u7684AIS\u6570\u636e\uff0c\u901a\u8fc7\u6570\u636e\u6e05\u6d17\u4e0e\u91cd\u5efa\u65b9\u6cd5\uff0c\u5728\u63a5\u6536\u5668\u8986\u76d6\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\u9ad8\u7cbe\u5ea6\u91cd\u6784\u4e86\u6ce2\u7f57\u7684\u6d77\u6cbf\u5cb8\u8239\u8236\u6d3b\u52a8\uff0c\u5e76\u6784\u5efa\u4e86\u884c\u7a0b\u6a21\u578b\u4ee5\u751f\u6210\u8239\u8236\u6570\u91cf\u3001\u4ea4\u901a\u6d41\u91cf\u53ca\u7ea6400\u7c73\u5206\u8fa8\u7387\u7684\u8239\u8236\u5bc6\u5ea6\u56fe\u3002", "motivation": "\u7406\u89e3\u8fc7\u53bb\u548c\u73b0\u5728\u7684\u6d77\u4e0a\u6d3b\u52a8\u6a21\u5f0f\u5bf9\u822a\u884c\u5b89\u5168\u3001\u73af\u5883\u8bc4\u4f30\u548c\u5546\u4e1a\u8fd0\u8425\u81f3\u5173\u91cd\u8981\uff1b\u800c\u76ee\u524d\u8d8a\u6765\u8d8a\u591a\u7684\u670d\u52a1\u901a\u8fc7\u5730\u9762\u63a5\u6536\u5668\u516c\u5f00\u63d0\u4f9bAIS\u5b9a\u4f4d\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u5b58\u5728\u8d28\u91cf\u6709\u9650\u548c\u8986\u76d6\u4e0d\u5168\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u91c7\u75282024\u5e748\u6708\u81f310\u6708\u6ce2\u7f57\u7684\u6d77\u4e09\u4e2a\u6708\u7684\u516c\u5f00AIS\u6570\u636e\uff0c\u63d0\u51fa\uff08i\uff09\u6570\u636e\u6e05\u6d17\u4e0e\u91cd\u5efa\u65b9\u6cd5\u4ee5\u63d0\u5347\u6570\u636e\u8d28\u91cf\uff0c\uff08ii\uff09\u4e00\u79cd\u5c06AIS\u6d88\u606f\u8f6c\u5316\u4e3a\u8239\u8236\u6570\u91cf\u3001\u4ea4\u901a\u4f30\u8ba1\u548c\u7a7a\u95f4\u5206\u8fa8\u8239\u8236\u5bc6\u5ea6\uff08\u7ea6400\u7c73\u5206\u8fa8\u7387\uff09\u7684\u884c\u7a0b\u6a21\u578b\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u79fb\u52a8\u548c\u9759\u6b62\u8239\u8236\u7684\u6570\u91cf\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\uff0c\u8bc6\u522b\u51fa\u6e2f\u53e3\u4f4d\u7f6e\uff0c\u5e76\u63a8\u65ad\u51fa\u6ce2\u7f57\u7684\u6d77\u6700\u62e5\u6324\u548c\u6700\u7e41\u5fd9\u7684\u6cbf\u5cb8\u533a\u57df\uff1b\u5e73\u5747\u6bcf\u5929\u6709\u8d85\u8fc7300\u8258\u8239\u8fdb\u51fa\u8be5\u6d77\u57df\uff0c\u540c\u65f6\u6709\u8d85\u8fc74000\u8258\u8239\u5728\u533a\u57df\u5185\u8fd0\u884c\uff1b\u7ed3\u679c\u4e0e\u4f9d\u8d56\u4e13\u6709\u6570\u636e\u7684\u5148\u524d\u7814\u7a76\u76f8\u5dee\u572820%\u4ee5\u5185\u3002", "conclusion": "\u516c\u5f00AIS\u6570\u636e\u5373\u4f7f\u5728\u8986\u76d6\u4e0d\u5168\u548c\u8d28\u91cf\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u6709\u6548\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u91cd\u5efa\u6cbf\u6d77\u8239\u8236\u6d3b\u52a8\uff0c\u4e3a\u822a\u884c\u5b89\u5168\u3001\u73af\u5883\u76d1\u6d4b\u548c\u5546\u4e1a\u51b3\u7b56\u63d0\u4f9b\u53ef\u9760\u652f\u6301\u3002"}}
{"id": "2511.21788", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.21788", "abs": "https://arxiv.org/abs/2511.21788", "authors": ["Md. Raihan Tapader", "Md. Mostafizer Rahman", "Ariful Islam Shiplu", "Md Faizul Ibne Amin", "Yutaka Watanobe"], "title": "Code Refactoring with LLM: A Comprehensive Evaluation With Few-Shot Settings", "comment": null, "summary": "In today's world, the focus of programmers has shifted from writing complex, error-prone code to prioritizing simple, clear, efficient, and sustainable code that makes programs easier to understand. Code refactoring plays a critical role in this transition by improving structural organization and optimizing performance. However, existing refactoring methods are limited in their ability to generalize across multiple programming languages and coding styles, as they often rely on manually crafted transformation rules. The objectives of this study are to (i) develop an Large Language Models (LLMs)-based framework capable of performing accurate and efficient code refactoring across multiple languages (C, C++, C#, Python, Java), (ii) investigate the impact of prompt engineering (Temperature, Different shot algorithm) and instruction fine-tuning on refactoring effectiveness, and (iii) evaluate the quality improvements (Compilability, Correctness, Distance, Similarity, Number of Lines, Token, Character, Cyclomatic Complexity) in refactored code through empirical metrics and human assessment. To accomplish these goals, we propose a fine-tuned prompt-engineering-based model combined with few-shot learning for multilingual code refactoring. Experimental results indicate that Java achieves the highest overall correctness up to 99.99% the 10-shot setting, records the highest average compilability of 94.78% compared to the original source code and maintains high similarity (Approx. 53-54%) and thus demonstrates a strong balance between structural modifications and semantic preservation. Python exhibits the lowest structural distance across all shots (Approx. 277-294) while achieving moderate similarity ( Approx. 44-48%) that indicates consistent and minimally disruptive refactoring.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u591a\u8bed\u8a00\u4ee3\u7801\u91cd\u6784\u6846\u67b6\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u4e0e\u5c11\u6837\u672c\u5b66\u4e60\uff0c\u5728C\u3001C++\u3001C#\u3001Python\u548cJava\u4e0a\u5b9e\u73b0\u9ad8\u6548\u91cd\u6784\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u6307\u6807\u8bc4\u4f30\u91cd\u6784\u8d28\u91cf\u3002\u5b9e\u9a8c\u8868\u660e\uff0cJava\u5728\u6b63\u786e\u6027\u548c\u53ef\u7f16\u8bd1\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u800cPython\u5728\u7ed3\u6784\u6539\u52a8\u6700\u5c0f\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u9002\u5ea6\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u91cd\u6784\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u7f16\u5199\u89c4\u5219\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c\u7f16\u7801\u98ce\u683c\u3002\u968f\u7740\u5bf9\u7b80\u6d01\u3001\u6e05\u6670\u3001\u9ad8\u6548\u548c\u53ef\u6301\u7eed\u4ee3\u7801\u7684\u9700\u6c42\u589e\u52a0\uff0c\u4e9f\u9700\u4e00\u79cd\u901a\u7528\u4e14\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u91cd\u6784\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u6307\u4ee4\u5fae\u8c03\u3001\u63d0\u793a\u5de5\u7a0b\uff08\u5982Temperature\u63a7\u5236\u548c\u4e0d\u540c\u5c11\u6837\u672c\u7b56\u7565\uff09\u4e0e\u5c11\u6837\u672c\u5b66\u4e60\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u8bed\u8a00\u4ee3\u7801\u91cd\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1aJava\u572810-shot\u8bbe\u7f6e\u4e0b\u6b63\u786e\u7387\u8fbe99.99%\uff0c\u5e73\u5747\u53ef\u7f16\u8bd1\u6027\u8fbe94.78%\uff0c\u8bed\u4e49\u76f8\u4f3c\u6027\u7ea653\u201354%\uff1bPython\u7ed3\u6784\u8ddd\u79bb\u6700\u5c0f\uff08\u7ea6277\u2013294\uff09\uff0c\u8bed\u4e49\u76f8\u4f3c\u6027\u7ea644\u201348%\uff0c\u8868\u660e\u5176\u91cd\u6784\u4e00\u81f4\u6027\u9ad8\u4e14\u5e72\u6270\u5c0f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LLM\u9a71\u52a8\u6846\u67b6\u5728\u591a\u8bed\u8a00\u4ee3\u7801\u91cd\u6784\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\uff0c\u5c24\u5176\u5728Java\u548cPython\u4e0a\u5b9e\u73b0\u4e86\u7ed3\u6784\u4f18\u5316\u4e0e\u8bed\u4e49\u4fdd\u7559\u7684\u826f\u597d\u5e73\u8861\uff0c\u9a8c\u8bc1\u4e86\u63d0\u793a\u5de5\u7a0b\u4e0e\u5c11\u6837\u672c\u5b66\u4e60\u5728\u63d0\u5347\u91cd\u6784\u8d28\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.21936", "categories": ["cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21936", "abs": "https://arxiv.org/abs/2511.21936", "authors": ["T. Rebolo", "A. Grilo", "C. Ribeiro"], "title": "Secure Command, Control and Communications Systems (C3) for Army UxVs", "comment": "13 pages", "summary": "Unmanned Vehicles (UxVs) are increasingly used in modern military operations for reconnaissance, surveillance, and strike missions, enhancing situational awareness while reducing risk to personnel. Their affordability and rapid deployment have encouraged the adoption of commercial solutions. However, many rely on insecure protocols such as MAVLink, which lack authentication and encryption mechanisms. This paper designed, implemented, and evaluated a new secure command-and-control architecture that ensures confidentiality, integrity, and authentication (CIA) while supporting real-time control delegation between Ground Control Stations (GCSs). The proposed solution, named New Command and Control System (NC2S), enforces a zero-trust model integrating hierarchical credential-based privileges to regulate access and control among Tactical Commanders (TC), GCSs, and UxVs. It employs mutual Transport Layer Security (mTLS) with Elliptic Curve Digital Signature Algorithm (ECDSA) certificates and Elliptic Curve Diffie-Hellman (ECDH) key exchange, while message integrity is ensured through Hash-based Message Authentication Codes (HMAC). Multiple lightweight protocols were developed for credential management, key renewal, and control handover. The NC2S prototype was experimentally validated over Wi-Fi and Rohde&Schwarz HR-5000H tactical radios. Results showed that HR-5000H links introduce latencies roughly two orders of magnitude higher than broadband technologies (e.g., Wi-Fi or 5G&Beyond technologies) but are still able to maintain stable communication with minimal message loss, making them suitable for the NC2S links among TC terminals and GCSs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u540d\u4e3aNC2S\u7684\u5b89\u5168\u6307\u6325\u63a7\u5236\u7cfb\u7edf\uff0c\u901a\u8fc7\u96f6\u4fe1\u4efb\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u5b89\u5168\u534f\u8bae\uff0c\u4e3a\u65e0\u4eba\u8f7d\u5177\uff08UxV\uff09\u63d0\u4f9b\u5177\u5907\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u4e0e\u8ba4\u8bc1\u80fd\u529b\u7684\u5b9e\u65f6\u6307\u6325\u63a7\u5236\u67b6\u6784\uff0c\u5e76\u5728Wi-Fi\u4e0e\u6218\u672f\u65e0\u7ebf\u7535\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u519b\u7528\u65e0\u4eba\u8f7d\u5177\u5e7f\u6cdb\u91c7\u7528\u5982MAVLink\u7b49\u7f3a\u4e4f\u8ba4\u8bc1\u4e0e\u52a0\u5bc6\u673a\u5236\u7684\u4e0d\u5b89\u5168\u901a\u4fe1\u534f\u8bae\uff0c\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff1b\u540c\u65f6\u9700\u652f\u6301\u591a\u5730\u9762\u63a7\u5236\u7ad9\u95f4\u7684\u5b9e\u65f6\u63a7\u5236\u6743\u5207\u6362\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u517c\u987e\u5b89\u5168\u6027\u4e0e\u5b9e\u65f6\u6027\u7684\u65b0\u578b\u6307\u6325\u63a7\u5236\u67b6\u6784\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u96f6\u4fe1\u4efb\u6a21\u578b\u7684NC2S\u7cfb\u7edf\uff0c\u91c7\u7528mTLS\u7ed3\u5408ECDSA\u8bc1\u4e66\u4e0eECDH\u5bc6\u94a5\u4ea4\u6362\u4fdd\u969c\u901a\u4fe1\u5b89\u5168\uff0c\u4f7f\u7528HMAC\u786e\u4fdd\u6d88\u606f\u5b8c\u6574\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u8f7b\u91cf\u7ea7\u534f\u8bae\u7528\u4e8e\u51ed\u8bc1\u7ba1\u7406\u3001\u5bc6\u94a5\u66f4\u65b0\u4e0e\u63a7\u5236\u6743\u4ea4\u63a5\u3002", "result": "\u5728Wi-Fi\u548cRohde&Schwarz HR-5000H\u6218\u672f\u65e0\u7ebf\u7535\u4e0a\u5bf9NC2S\u539f\u578b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u7ed3\u679c\u663e\u793a\uff0cHR-5000H\u94fe\u8def\u5ef6\u8fdf\u6bd4\u5bbd\u5e26\u6280\u672f\u9ad8\u7ea6\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u4f46\u4ecd\u80fd\u7ef4\u6301\u7a33\u5b9a\u901a\u4fe1\u4e14\u6d88\u606f\u4e22\u5931\u6781\u5c11\uff0c\u9002\u7528\u4e8e\u6218\u672f\u6307\u6325\u7ec8\u7aef\u4e0e\u5730\u9762\u63a7\u5236\u7ad9\u4e4b\u95f4\u7684\u5b89\u5168\u8fde\u63a5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684NC2S\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65e0\u4eba\u8f7d\u5177\u6307\u6325\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u5728\u4fdd\u8bc1CIA\u4e09\u8981\u7d20\u7684\u540c\u65f6\u652f\u6301\u5b9e\u65f6\u63a7\u5236\u6743\u8f6c\u79fb\uff0c\u4e14\u5728\u6218\u672f\u901a\u4fe1\u73af\u5883\u4e2d\u5177\u6709\u826f\u597d\u7684\u9002\u7528\u6027\u4e0e\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.22010", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.22010", "abs": "https://arxiv.org/abs/2511.22010", "authors": ["Provakar Mondal", "Eli Tilevich"], "title": "An Empirical Study of Cross-Language Interoperability in Replicated Data Systems", "comment": null, "summary": "BACKGROUND: Modern distributed systems replicate data across multiple execution sites. Business requirements and resource constraints often necessitate mixing different languages across replica sites. To facilitate the management of replicated data, modern software engineering practices integrate special-purpose replicated data libraries (RDLs) that provide read-write access to the data and ensure its synchronization. Irrespective of the implementation languages, an RDL typically uses a single language or offers bindings to a designated one. Hence, integrating existing RDLs in multilingual environments requires special-purpose code, whose software quality and performance characteristics are poorly understood.\n  AIMS: We aim to bridge this knowledge gap to understand the software quality and performance characteristics of RDL integration in multilingual environments.\n  METHOD: We conduct an empirical study of two key strategies for integrating RDLs in the context of multilingual replicated data systems: foreign-function interface (FFI) and a common data format (CDF); we measure and compare their respective software metrics and performance to understand their suitability for the task at hand.\n  RESULTS: Our results reveal that adopting CDF for cross-language interaction offers software quality, latency, memory consumption, and throughput advantages. We further validate our findings by (1) creating a CDF-based RDL for mixing compiled, interpreted, and managed languages; and (2) enhancing our RDL with plug-in extensibility that enables adding functionality in a single language while maintaining integration within a multilingual environment.\n  CONCLUSIONS: With modern distributed systems utilizing multiple languages, our findings provide novel insights for designing RDLs in multilingual replicated data systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u4e86\u5728\u591a\u8bed\u8a00\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u96c6\u6210\u590d\u5236\u6570\u636e\u5e93\uff08RDL\uff09\u7684\u4e24\u79cd\u7b56\u7565\u2014\u2014\u5916\u90e8\u51fd\u6570\u63a5\u53e3\uff08FFI\uff09\u548c\u901a\u7528\u6570\u636e\u683c\u5f0f\uff08CDF\uff09\uff0c\u53d1\u73b0CDF\u5728\u8f6f\u4ef6\u8d28\u91cf\u3001\u5ef6\u8fdf\u3001\u5185\u5b58\u6d88\u8017\u548c\u541e\u5410\u91cf\u65b9\u9762\u66f4\u5177\u4f18\u52bf\uff0c\u5e76\u636e\u6b64\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u652f\u6301\u591a\u8bed\u8a00\u4e14\u5177\u6709\u63d2\u4ef6\u6269\u5c55\u80fd\u529b\u7684RDL\u3002", "motivation": "\u73b0\u4ee3\u5206\u5e03\u5f0f\u7cfb\u7edf\u5e38\u9700\u5728\u591a\u4e2a\u6267\u884c\u7ad9\u70b9\u95f4\u590d\u5236\u6570\u636e\uff0c\u5e76\u6df7\u5408\u4f7f\u7528\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u3002\u73b0\u6709\u590d\u5236\u6570\u636e\u5e93\uff08RDL\uff09\u901a\u5e38\u4ec5\u652f\u6301\u5355\u4e00\u8bed\u8a00\u6216\u63d0\u4f9b\u7279\u5b9a\u8bed\u8a00\u7ed1\u5b9a\uff0c\u5bfc\u81f4\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u96c6\u6210\u65f6\u9700\u7f16\u5199\u4e13\u7528\u4ee3\u7801\uff0c\u800c\u8fd9\u7c7b\u4ee3\u7801\u7684\u8f6f\u4ef6\u8d28\u91cf\u4e0e\u6027\u80fd\u7279\u5f81\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5f00\u5c55\u5b9e\u8bc1\u7814\u7a76\uff0c\u5bf9\u6bd4\u4e24\u79cdRDL\u96c6\u6210\u7b56\u7565\uff1a\u5916\u90e8\u51fd\u6570\u63a5\u53e3\uff08FFI\uff09\u4e0e\u901a\u7528\u6570\u636e\u683c\u5f0f\uff08CDF\uff09\uff0c\u901a\u8fc7\u6d4b\u91cf\u548c\u6bd4\u8f83\u5b83\u4eec\u7684\u8f6f\u4ef6\u6307\u6807\u4e0e\u6027\u80fd\u8868\u73b0\uff0c\u8bc4\u4f30\u5176\u5728\u591a\u8bed\u8a00\u590d\u5236\u6570\u636e\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u91c7\u7528CDF\u8fdb\u884c\u8de8\u8bed\u8a00\u4ea4\u4e92\u5728\u8f6f\u4ef6\u8d28\u91cf\u3001\u5ef6\u8fdf\u3001\u5185\u5b58\u5360\u7528\u548c\u541e\u5410\u91cf\u65b9\u9762\u5747\u4f18\u4e8eFFI\uff1b\u4f5c\u8005\u8fdb\u4e00\u6b65\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8eCDF\u7684RDL\uff0c\u652f\u6301\u7f16\u8bd1\u578b\u3001\u89e3\u91ca\u578b\u548c\u6258\u7ba1\u8bed\u8a00\u7684\u6df7\u5408\u4f7f\u7528\uff0c\u5e76\u901a\u8fc7\u63d2\u4ef6\u673a\u5236\u5b9e\u73b0\u5355\u8bed\u8a00\u529f\u80fd\u6269\u5c55\u7684\u540c\u65f6\u7ef4\u6301\u591a\u8bed\u8a00\u96c6\u6210\u3002", "conclusion": "\u5728\u73b0\u4ee3\u591a\u8bed\u8a00\u5206\u5e03\u5f0f\u7cfb\u7edf\u80cc\u666f\u4e0b\uff0c\u672c\u7814\u7a76\u4e3a\u8bbe\u8ba1\u9002\u7528\u4e8e\u591a\u8bed\u8a00\u73af\u5883\u7684\u590d\u5236\u6570\u636e\u5e93\uff08RDL\uff09\u63d0\u4f9b\u4e86\u65b0\u7684\u5b9e\u8df5\u6307\u5bfc\u548c\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2511.22267", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.22267", "abs": "https://arxiv.org/abs/2511.22267", "authors": ["Yuyang Zou", "Youwei Xiao", "Yansong Xu", "Chenyun Yin", "Yuhao Luo", "Yitian Sun", "Ruifan Xu", "Renze Chen", "Yun Liang"], "title": "Aquas: Enhancing Domain Specialization through Holistic Hardware-Software Co-Optimization based on MLIR", "comment": null, "summary": "Application-Specific Instruction-Set Processors (ASIPs) built on the RISC-V architecture offer specialization opportunities for various applications. However, existing frameworks from the open-source RISC-V ecosystem suffer from limited performance due to restricted hardware synthesis and rigid compiler support. To address these challenges, we introduce Aquas, a holistic hardware-software co-design framework built upon MLIR. Aquas enhances ASIP synthesis with fast memory access capability via a burst DMA engine and advanced high-level synthesis (HLS) optimizations. On the compiler side, we propose an e-graph based retargetable approach with a novel matching engine for efficient instruction matching. Evaluation demonstrates up to 9.27x speedup on real-world workloads, including point cloud processing and LLM inference.", "AI": {"tldr": "Aquas is a hardware-software co-design framework based on MLIR that improves RISC-V-based ASIP performance through burst DMA and HLS optimizations in hardware, and an e-graph\u2013based retargetable compiler with a novel matching engine, achieving up to 9.27x speedup on real-world workloads.", "motivation": "Existing open-source RISC-V frameworks for ASIPs suffer from limited performance due to constrained hardware synthesis capabilities and inflexible compiler support, hindering effective application specialization.", "method": "The authors propose Aquas, a co-design framework leveraging MLIR. It introduces a burst DMA engine and advanced HLS techniques for hardware acceleration, and employs an e-graph\u2013based retargetable compilation approach with a new instruction-matching engine on the software side.", "result": "Evaluation shows Aquas achieves up to 9.27\u00d7 speedup on practical applications such as point cloud processing and large language model (LLM) inference.", "conclusion": "Aquas effectively bridges hardware and compiler limitations in current RISC-V ASIP frameworks, delivering significant performance gains through integrated co-design innovations."}}
{"id": "2511.23064", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.23064", "abs": "https://arxiv.org/abs/2511.23064", "authors": ["Jonas Heinzmann", "Francesco Vicentini", "Pietro Carrara", "Laura De Lorenzis"], "title": "Iterative convergence in phase-field brittle fracture computations: exact line search is all you need", "comment": null, "summary": "Variational phase-field models of brittle fracture pose a local constrained minimization problem of a non-convex energy functional. In the discrete setting, the problem is most often solved by alternate minimization, exploiting the separate convexity of the energy with respect to the two unknowns. This approach is theoretically guaranteed to converge, provided each of the individual subproblems is solved successfully. However, strong non-linearities of the energy functional may lead to failure of iterative convergence within one or both subproblems. In this paper, we propose an exact line search algorithm based on bisection, which (under certain conditions) guarantees global convergence of Newton's method for each subproblem and consequently the successful determination of critical points of the energy through the alternate minimization scheme. Through several benchmark tests computed with various strain energy decompositions and two strategies for the enforcement of the irreversibility constraint in two and three dimensions, we demonstrate the robustness of the approach and assess its efficiency in comparison with other commonly used line search algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e8c\u5206\u6cd5\u7684\u7cbe\u786e\u7ebf\u641c\u7d22\u7b97\u6cd5\uff0c\u7528\u4e8e\u4fdd\u8bc1\u725b\u987f\u6cd5\u5728\u53d8\u5206\u76f8\u573a\u65ad\u88c2\u6a21\u578b\u4ea4\u66ff\u6700\u5c0f\u5316\u5b50\u95ee\u9898\u4e2d\u7684\u5168\u5c40\u6536\u655b\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u7ec4\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u5176\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u53d8\u5206\u76f8\u573a\u65ad\u88c2\u6a21\u578b\u4e2d\u7684\u80fd\u91cf\u6cdb\u51fd\u5177\u6709\u5f3a\u975e\u7ebf\u6027\uff0c\u5bfc\u81f4\u4ea4\u66ff\u6700\u5c0f\u5316\u8fc7\u7a0b\u4e2d\u5b50\u95ee\u9898\u53ef\u80fd\u65e0\u6cd5\u8fed\u4ee3\u6536\u655b\uff0c\u5f71\u54cd\u6574\u4f53\u6c42\u89e3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e8c\u5206\u6cd5\u7684\u7cbe\u786e\u7ebf\u641c\u7d22\u7b97\u6cd5\uff0c\u5728\u6ee1\u8db3\u4e00\u5b9a\u6761\u4ef6\u4e0b\u786e\u4fdd\u6bcf\u4e2a\u5b50\u95ee\u9898\u4e2d\u725b\u987f\u6cd5\u7684\u5168\u5c40\u6536\u655b\uff0c\u5e76\u7ed3\u5408\u4ea4\u66ff\u6700\u5c0f\u5316\u7b56\u7565\u6c42\u89e3\u80fd\u91cf\u6cdb\u51fd\u7684\u4e34\u754c\u70b9\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u5e94\u53d8\u80fd\u5206\u89e3\u65b9\u5f0f\u548c\u4e24\u79cd\u4e0d\u53ef\u9006\u7ea6\u675f\u5904\u7406\u7b56\u7565\uff0c\u5728\u4e8c\u7ef4\u548c\u4e09\u7ef4\u57fa\u51c6\u7b97\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e0e\u5176\u4ed6\u5e38\u7528\u7ebf\u641c\u7d22\u7b97\u6cd5\u8fdb\u884c\u4e86\u6548\u7387\u5bf9\u6bd4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ebf\u641c\u7d22\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u53d8\u5206\u76f8\u573a\u65ad\u88c2\u6a21\u578b\u4e2d\u4ea4\u66ff\u6700\u5c0f\u5316\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\uff0c\u5177\u5907\u826f\u597d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.21877", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21877", "abs": "https://arxiv.org/abs/2511.21877", "authors": ["Nenad Petrovic", "Norbert Kroth", "Axel Torschmied", "Yinglei Song", "Fengjunjie Pan", "Vahid Zolfaghari", "Nils Purschke", "Sven Kirchner", "Chengdong Wu", "Andre Schamschurko", "Yi Zhang", "Alois Knoll"], "title": "LLM-Empowered Event-Chain Driven Code Generation for ADAS in SDV systems", "comment": null, "summary": "This paper presents an event-chain-driven, LLM-empowered workflow for generating validated, automotive code from natural-language requirements. A Retrieval-Augmented Generation (RAG) layer retrieves relevant signals from large and evolving Vehicle Signal Specification (VSS) catalogs as code generation prompt context, reducing hallucinations and ensuring architectural correctness. Retrieved signals are mapped and validated before being transformed into event chains that encode causal and timing constraints. These event chains guide and constrain LLM-based code synthesis, ensuring behavioral consistency and real-time feasibility. Based on our initial findings from the emergency braking case study, with the proposed approach, we managed to achieve valid signal usage and consistent code generation without LLM retraining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u9a71\u52a8\u3001\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u589e\u5f3a\u7684\u5de5\u4f5c\u6d41\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u751f\u6210\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u6c7d\u8f66\u4ee3\u7801\uff0c\u5229\u7528RAG\u6280\u672f\u68c0\u7d22\u8f66\u8f86\u4fe1\u53f7\u89c4\u8303\uff08VSS\uff09\u4ee5\u51cf\u5c11\u5e7b\u89c9\u5e76\u786e\u4fdd\u67b6\u6784\u6b63\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u81ea\u52a8\u751f\u6210\u6c7d\u8f66\u4ee3\u7801\u9762\u4e34\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u548c\u67b6\u6784\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u786e\u4fdd\u4fe1\u53f7\u6b63\u786e\u4f7f\u7528\u4e0e\u884c\u4e3a\u4e00\u81f4\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5c42\u4eceVSS\u76ee\u5f55\u4e2d\u68c0\u7d22\u76f8\u5173\u4fe1\u53f7\u4f5c\u4e3a\u63d0\u793a\u4e0a\u4e0b\u6587\uff1b\u5c06\u68c0\u7d22\u5230\u7684\u4fe1\u53f7\u6620\u5c04\u9a8c\u8bc1\u540e\u8f6c\u5316\u4e3a\u7f16\u7801\u56e0\u679c\u4e0e\u65f6\u5e8f\u7ea6\u675f\u7684\u4e8b\u4ef6\u94fe\uff0c\u7528\u4ee5\u5f15\u5bfc\u548c\u7ea6\u675fLLM\u8fdb\u884c\u4ee3\u7801\u5408\u6210\u3002", "result": "\u5728\u7d27\u6025\u5236\u52a8\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3LLM\u5373\u53ef\u751f\u6210\u4fe1\u53f7\u4f7f\u7528\u6b63\u786e\u3001\u884c\u4e3a\u4e00\u81f4\u7684\u4ee3\u7801\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u751f\u6210\u6c7d\u8f66\u4ee3\u7801\u7684\u51c6\u786e\u6027\u4e0e\u5b9e\u65f6\u53ef\u884c\u6027\uff0c\u4e3aLLM\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.22333", "categories": ["cs.DC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22333", "abs": "https://arxiv.org/abs/2511.22333", "authors": ["Jinjun Yi", "Zhixin Zhao", "Yitao Hu", "Ke Yan", "Weiwei Sun", "Hao Wang", "Laiping Zhao", "Yuhao Zhang", "Wenxin Li", "Keqiu Li"], "title": "PAT: Accelerating LLM Decoding via Prefix-Aware Attention with Resource Efficient Multi-Tile Kernel", "comment": "Accepted by ASPLOS'26", "summary": "LLM serving is increasingly dominated by decode attention, which is a memory-bound operation due to massive KV cache loading from global memory. Meanwhile, real-world workloads exhibit substantial, hierarchical shared prefixes across requests (e.g., system prompts, tools/templates, RAG). Existing attention implementations fail to fully exploit prefix sharing: *one-query-per-CTA* execution repeatedly loads shared prefix KV cache, while *one-size-fits-all* tiling leaves on-chip resources idle and exacerbates bubbles for uneven KV lengths. These choices amplify memory bandwidth pressure and stall memory-bound decode attention.\n  This paper introduces PAT, a prefix-aware attention kernel implementation for LLM decoding that organizes execution with a pack-forward-merge paradigm. PAT packs queries by shared prefix to reduce repeated memory accesses, runs a customized multi-tile kernel to achieve high resource efficiency. It further applies practical multi-stream forwarding and KV splitting to reduce resource bubbles. The final merge performs online softmax with negligible overhead. We implement PAT as an off-the-shelf plugin for vLLM. Evaluation on both real-world and synthetic workloads shows that PAT reduces attention latency by 67.4% on average and TPOT by 13.6-83.4% under the same configurations against state-of-the-art attention kernels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPAT\uff0c\u4e00\u79cd\u9762\u5411LLM\u89e3\u7801\u7684\u524d\u7f00\u611f\u77e5\u6ce8\u610f\u529b\u6838\uff0c\u901a\u8fc7\u6253\u5305\u5171\u4eab\u524d\u7f00\u67e5\u8be2\u3001\u5b9a\u5236\u591a\u5206\u5757\u6838\u53ca\u591a\u6d41\u8f6c\u53d1\u7b49\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u6ce8\u610f\u529b\u5ef6\u8fdf\u548cTPOT\u3002", "motivation": "\u73b0\u6709\u6ce8\u610f\u529b\u5b9e\u73b0\u672a\u80fd\u5145\u5206\u5229\u7528\u771f\u5b9e\u8d1f\u8f7d\u4e2d\u8bf7\u6c42\u95f4\u5b58\u5728\u7684\u5927\u91cf\u5c42\u6b21\u5316\u5171\u4eab\u524d\u7f00\uff08\u5982\u7cfb\u7edf\u63d0\u793a\u3001\u5de5\u5177\u6a21\u677f\u3001RAG\uff09\uff0c\u5bfc\u81f4\u91cd\u590d\u52a0\u8f7dKV\u7f13\u5b58\u3001\u7247\u4e0a\u8d44\u6e90\u95f2\u7f6e\u53ca\u5185\u5b58\u5e26\u5bbd\u538b\u529b\u589e\u5927\uff0c\u4ece\u800c\u62d6\u6162\u5185\u5b58\u53d7\u9650\u7684\u89e3\u7801\u6ce8\u610f\u529b\u64cd\u4f5c\u3002", "method": "\u63d0\u51faPAT\u65b9\u6cd5\uff0c\u91c7\u7528\u201c\u6253\u5305-\u524d\u5411-\u5408\u5e76\u201d\u8303\u5f0f\uff1a\u6309\u5171\u4eab\u524d\u7f00\u6253\u5305\u67e5\u8be2\u4ee5\u51cf\u5c11\u91cd\u590d\u5185\u5b58\u8bbf\u95ee\uff1b\u8fd0\u884c\u5b9a\u5236\u5316\u7684\u591a\u5206\u5757\u6838\u4ee5\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\uff1b\u7ed3\u5408\u591a\u6d41\u524d\u5411\u4e0eKV\u5206\u5272\u4ee5\u51cf\u5c11\u8d44\u6e90\u6c14\u6ce1\uff1b\u6700\u540e\u901a\u8fc7\u5728\u7ebfsoftmax\u5b8c\u6210\u5408\u5e76\uff0c\u5f00\u9500\u53ef\u5ffd\u7565\u3002\u8be5\u65b9\u6cd5\u4ee5\u5373\u63d2\u5373\u7528\u63d2\u4ef6\u5f62\u5f0f\u96c6\u6210\u5230vLLM\u4e2d\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u8d1f\u8f7d\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6ce8\u610f\u529b\u6838\uff0cPAT\u5728\u76f8\u540c\u914d\u7f6e\u4e0b\u5e73\u5747\u964d\u4f4e\u6ce8\u610f\u529b\u5ef6\u8fdf67.4%\uff0cTPOT\u964d\u4f4e13.6%\u81f383.4%\u3002", "conclusion": "PAT\u901a\u8fc7\u9ad8\u6548\u5229\u7528\u8bf7\u6c42\u95f4\u7684\u5171\u4eab\u524d\u7f00\u4fe1\u606f\uff0c\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u7ed3\u6784\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u4e86LLM\u89e3\u7801\u9636\u6bb5\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u6548\u7387\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5185\u5b58\u5e26\u5bbd\u74f6\u9888\u3002"}}
{"id": "2511.22832", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.22832", "abs": "https://arxiv.org/abs/2511.22832", "authors": ["Rohan Bopardikar", "Jin Wang", "Jia Zou"], "title": "Structured Multi-Step Reasoning for Entity Matching Using Large Language Model", "comment": null, "summary": "Entity matching is a fundamental task in data cleaning and data integration. With the rapid adoption of large language models (LLMs), recent studies have explored zero-shot and few-shot prompting to improve entity matching accuracy. However, most existing approaches rely on single-step prompting and offer limited investigation into structured reasoning strategies. In this work, we investigate how to enhance LLM-based entity matching by decomposing the matching process into multiple explicit reasoning stages. We propose a three-step framework that first identifies matched and unmatched tokens between two records, then determines the attributes most influential to the matching decision, and finally predicts whether the records refer to the same real-world entity. In addition, we explore a debate-based strategy that contrasts supporting and opposing arguments to improve decision robustness. We evaluate our approaches against multiple existing baselines on several real-world entity matching benchmark datasets. Experimental results demonstrate that structured multi-step reasoning can improve matching performance in several cases, while also highlighting remaining challenges and opportunities for further refinement of reasoning-guided LLM approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u6b65\u7ed3\u6784\u5316\u63a8\u7406\u7684LLM\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u8bc6\u522b\u5339\u914d/\u4e0d\u5339\u914d\u9879\u3001\u5173\u952e\u5c5e\u6027\u5224\u65ad\u548c\u6700\u7ec8\u51b3\u7b56\uff0c\u5e76\u5f15\u5165\u8fa9\u8bba\u673a\u5236\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\u591a\u91c7\u7528\u5355\u6b65\u63d0\u793a\uff0c\u7f3a\u4e4f\u5bf9\u7ed3\u6784\u5316\u63a8\u7406\u7b56\u7565\u7684\u6df1\u5165\u63a2\u7d22\uff0c\u9650\u5236\u4e86\u5339\u914d\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u6b65\u6846\u67b6\uff1a\u9996\u5148\u8bc6\u522b\u4e24\u6761\u8bb0\u5f55\u4e2d\u5339\u914d\u4e0e\u4e0d\u5339\u914d\u7684\u8bcd\u5143\uff0c\u5176\u6b21\u786e\u5b9a\u5bf9\u5339\u914d\u51b3\u7b56\u5f71\u54cd\u6700\u5927\u7684\u5c5e\u6027\uff0c\u6700\u540e\u5224\u65ad\u662f\u5426\u6307\u5411\u540c\u4e00\u73b0\u5b9e\u5b9e\u4f53\uff1b\u540c\u65f6\u5f15\u5165\u652f\u6301\u4e0e\u53cd\u5bf9\u8bba\u70b9\u5bf9\u6bd4\u7684\u8fa9\u8bba\u673a\u5236\u4ee5\u589e\u5f3a\u51b3\u7b56\u9c81\u68d2\u6027\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u5b9e\u4f53\u5339\u914d\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u6784\u5316\u591a\u6b65\u63a8\u7406\u5728\u82e5\u5e72\u573a\u666f\u4e0b\u63d0\u5347\u4e86\u5339\u914d\u6027\u80fd\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u4ecd\u9762\u4e34\u7684\u6311\u6218\u548c\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u7ed3\u6784\u5316\u591a\u6b65\u63a8\u7406\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u5b9e\u4f53\u5339\u914d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u63a8\u7406\u5f15\u5bfc\u7b56\u7565\u4ee5\u5e94\u5bf9\u590d\u6742\u5339\u914d\u573a\u666f\u3002"}}
{"id": "2511.21878", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.21878", "abs": "https://arxiv.org/abs/2511.21878", "authors": ["Kaiyao Ke", "Ali Reza Ibrahimzada", "Rangeet Pan", "Saurabh Sinha", "Reyhaneh Jabbarvand"], "title": "Advancing Automated In-Isolation Validation in Repository-Level Code Translation", "comment": null, "summary": "Repository-level code translation aims to migrate entire repositories across programming languages while preserving functionality automatically. Despite advancements in repository-level code translation, validating the translations remains challenging. This paper proposes TRAM, which combines context-aware type resolution with mock-based in-isolation validation to achieve high-quality translations between programming languages. Prior to translation, TRAM retrieves API documentation and contextual code information for each variable type in the source language. It then prompts a large language model (LLM) with retrieved contextual information to resolve type mappings across languages with precise semantic interpretations. Using the automatically constructed type mapping, TRAM employs a custom serialization/deserialization workflow that automatically constructs equivalent mock objects in the target language. This enables each method fragment to be validated in isolation, without the high cost of using agents for translation validation, or the heavy manual effort required by existing approaches that rely on language interoperability. TRAM demonstrates state-of-the-art performance in Java-to-Python translation, underscoring the effectiveness of its integration of RAG-based type resolution with reliable in-isolation validation.", "AI": {"tldr": "TRAM is a novel approach for repository-level code translation that combines retrieval-augmented type resolution with mock-based isolated validation to achieve high-quality Java-to-Python translations without relying on costly agent-based validation or manual interoperability efforts.", "motivation": "Validating automatically translated code across entire repositories remains a major challenge due to semantic differences between languages and the high cost or manual effort required by existing validation methods.", "method": "TRAM retrieves API documentation and contextual code information to perform context-aware type resolution using a large language model (LLM). It then constructs mock objects in the target language via a custom serialization/deserialization workflow, enabling each method to be validated in isolation.", "result": "TRAM achieves state-of-the-art performance in Java-to-Python repository-level translation, demonstrating the effectiveness of combining RAG-based type mapping with in-isolation validation.", "conclusion": "Integrating context-aware type resolution with mock-based isolated validation significantly improves the quality and feasibility of automatic repository-level code translation."}}
{"id": "2511.22046", "categories": ["cs.NI", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.22046", "abs": "https://arxiv.org/abs/2511.22046", "authors": ["Tong Li", "Xu Yan", "Bo Wu", "Cheng Luo", "Fuyu Wang", "Jiuxiang Zhu", "Haoyi Fang", "Xinle Du", "Ke Xu"], "title": "AutoRec: Accelerating Loss Recovery for Live Streaming in a Multi-Supplier Market", "comment": null, "summary": "Due to the limited permissions for upgrading dualside (i.e., server-side and client-side) loss tolerance schemes from the perspective of CDN vendors in a multi-supplier market, modern large-scale live streaming services are still using the automatic-repeat-request (ARQ) based paradigm for loss recovery, which only requires server-side modifications. In this paper, we first conduct a large-scale measurement study with up to 50 million live streams. We find that loss shows dynamics and live streaming contains frequent on-off mode switching in the wild. We further find that the recovery latency, enlarged by the ubiquitous retransmission loss, is a critical factor affecting live streaming's client-side QoE (e.g., video freezing). We then propose an enhanced recovery mechanism called AutoRec, which can transform the disadvantages of on-off mode switching into an advantage for reducing loss recovery latency without any modifications on the client side. AutoRec allows users to customize overhead tolerance and recovery latency tolerance and adaptively adjusts strategies as the network environment changes to ensure that recovery latency meets user demands whenever possible while keeping overhead under control. We implement AutoRec upon QUIC and evaluate it via testbed and real-world commercial services deployments. The experimental results demonstrate the practicability and profitability of AutoRec.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u6d4b\u91cf\u53d1\u73b0\u76f4\u64ad\u6d41\u4e2d\u4e22\u5305\u5177\u6709\u52a8\u6001\u6027\u4e14\u5b58\u5728\u9891\u7e41\u7684\u5f00\u5173\u6a21\u5f0f\u5207\u6362\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5ba2\u6237\u7aef\u4fee\u6539\u7684\u589e\u5f3a\u6062\u590d\u673a\u5236AutoRec\uff0c\u53ef\u5728\u63a7\u5236\u5f00\u9500\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6062\u590d\u5ef6\u8fdf\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eARQ\u7684\u4e22\u5305\u6062\u590d\u673a\u5236\u4ec5\u5728\u670d\u52a1\u7aef\u8fdb\u884c\u4fee\u6539\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u76f4\u64ad\u6d41\u4e2d\u52a8\u6001\u4e22\u5305\u548c\u9891\u7e41\u5f00\u5173\u6a21\u5f0f\u5207\u6362\u5e26\u6765\u7684\u9ad8\u6062\u590d\u5ef6\u8fdf\u95ee\u9898\uff0c\u5f71\u54cd\u5ba2\u6237\u7aefQoE\u3002", "method": "\u63d0\u51faAutoRec\u673a\u5236\uff0c\u5728QUIC\u534f\u8bae\u4e0a\u5b9e\u73b0\uff0c\u5229\u7528\u76f4\u64ad\u6d41\u7684\u5f00\u5173\u6a21\u5f0f\u5207\u6362\u7279\u6027\uff0c\u5728\u4e0d\u4fee\u6539\u5ba2\u6237\u7aef\u7684\u524d\u63d0\u4e0b\u81ea\u9002\u5e94\u8c03\u6574\u6062\u590d\u7b56\u7565\uff0c\u4ee5\u6ee1\u8db3\u7528\u6237\u5bf9\u6062\u590d\u5ef6\u8fdf\u548c\u5f00\u9500\u7684\u5bb9\u5fcd\u5ea6\u3002", "result": "\u901a\u8fc7\u6d4b\u8bd5\u5e8a\u548c\u771f\u5b9e\u5546\u4e1a\u90e8\u7f72\u9a8c\u8bc1\uff0cAutoRec\u5728\u63a7\u5236\u989d\u5916\u5f00\u9500\u7684\u540c\u65f6\u6709\u6548\u964d\u4f4e\u4e86\u4e22\u5305\u6062\u590d\u5ef6\u8fdf\uff0c\u63d0\u5347\u4e86\u76f4\u64ad\u670d\u52a1\u8d28\u91cf\uff0c\u5c55\u73b0\u51fa\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u6536\u76ca\u6027\u3002", "conclusion": "AutoRec\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u4e22\u5305\u6062\u590d\u673a\u5236\uff0c\u80fd\u591f\u5728\u591a\u4f9b\u5e94\u5546CDN\u5e02\u573a\u9650\u5236\u4e0b\uff0c\u65e0\u9700\u5ba2\u6237\u7aef\u6539\u52a8\u5373\u53ef\u663e\u8457\u6539\u5584\u76f4\u64ad\u6d41\u7684QoE\u3002"}}
{"id": "2511.22380", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.22380", "abs": "https://arxiv.org/abs/2511.22380", "authors": ["Kaya Alpturer", "Ron van der Meyden", "Sushmita Ruj", "Godfrey Wong"], "title": "Optimality of Simultaneous Consensus with Limited Information Exchange (Extended Abstract)", "comment": "In Proceedings TARK 2025, arXiv:2511.20540", "summary": "Work on the development of optimal fault-tolerant Agreement protocols using the logic of knowledge has concentrated on the \"full information\" approach to information exchange, which is costly with respect to message size. Alpturer, Halpern, and van der Meyden (PODC 2023) introduced the notion of optimality with respect to a limited information exchange, and studied the Eventual Agreement problem in the sending omissions failure model. The present paper studies the Simultaneous Agreement problem for the crash failures model, and a number of limited information exchanges from the literature. In particular, the paper considers information exchanges from a FloodSet protocol (Lynch, Distributed Algorithms 1996), a variant of this in which agents also count the number of failures (Casta\u00f1eda et al, NETYS 2017), and a variant in which agents associate each agent with a value (Raynal, PRDC 2002). A new information exchange is also introduced that enables decisions to be made at worst one round later than the optimal protocol of Dwork and Moses (I&C 88), but with lower computation cost and space requirements. By determining implementations of a knowledge based program, protocols are derived that are optimal amongst protocols for each of these information exchanges.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5d29\u6e83\u6545\u969c\u6a21\u578b\u4e0b\uff0c\u9488\u5bf9\u591a\u79cd\u53d7\u9650\u4fe1\u606f\u4ea4\u6362\u673a\u5236\u7684\u540c\u6b65\u5171\u8bc6\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u673a\u5236\uff0c\u5728\u63a5\u8fd1\u6700\u4f18\u51b3\u7b56\u5ef6\u8fdf\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u903b\u8f91\u7684\u5bb9\u9519\u5171\u8bc6\u534f\u8bae\u591a\u91c7\u7528\u201c\u5168\u4fe1\u606f\u201d\u4ea4\u6362\u65b9\u5f0f\uff0c\u6d88\u606f\u5f00\u9500\u5927\uff1b\u4e3a\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u9700\u7814\u7a76\u5728\u53d7\u9650\u4fe1\u606f\u4ea4\u6362\u4e0b\u7684\u6700\u4f18\u534f\u8bae\u8bbe\u8ba1\u3002", "method": "\u5206\u6790\u5e76\u6bd4\u8f83\u4e86\u591a\u79cd\u5df2\u6709\u53d7\u9650\u4fe1\u606f\u4ea4\u6362\u673a\u5236\uff08\u5982FloodSet\u53ca\u5176\u53d8\u4f53\uff09\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u4fe1\u606f\u4ea4\u6362\u673a\u5236\uff1b\u901a\u8fc7\u5b9e\u73b0\u57fa\u4e8e\u77e5\u8bc6\u7684\u7a0b\u5e8f\uff0c\u63a8\u5bfc\u51fa\u5728\u6bcf\u79cd\u673a\u5236\u4e0b\u6700\u4f18\u7684\u540c\u6b65\u5171\u8bc6\u534f\u8bae\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b0\u4fe1\u606f\u4ea4\u6362\u673a\u5236\u53ef\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u4ec5\u6bd4Dwork\u548cMoses\u7684\u6700\u4f18\u534f\u8bae\u665a\u4e00\u8f6e\u505a\u51fa\u51b3\u7b56\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u9700\u6c42\uff1b\u9488\u5bf9\u5404\u7c7b\u4fe1\u606f\u4ea4\u6362\u673a\u5236\u5747\u83b7\u5f97\u4e86\u6700\u4f18\u534f\u8bae\u3002", "conclusion": "\u5728\u5d29\u6e83\u6545\u969c\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u53d7\u9650\u4fe1\u606f\u4ea4\u6362\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u63a5\u8fd1\u6700\u4f18\u54cd\u5e94\u65f6\u95f4\u7684\u540c\u65f6\uff0c\u6709\u6548\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u540c\u6b65\u5171\u8bc6\u534f\u8bae\u3002"}}
{"id": "2511.22551", "categories": ["cs.AR", "cs.ET", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.22551", "abs": "https://arxiv.org/abs/2511.22551", "authors": ["Elham Cheshmikhani", "Hamed Farbeh", "Hossein Asad"], "title": "3RSeT: Read Disturbance Rate Reduction in STT-MRAM Caches by Selective Tag Comparison", "comment": null, "summary": "Recent development in memory technologies has introduced Spin-Transfer Torque Magnetic RAM (STT-MRAM) as the most promising replacement for SRAMs in on-chip cache memories. Besides its lower leakage power, higher density, immunity to radiation-induced particles, and non-volatility, an unintentional bit flip during read operation, referred to as read disturbance error, is a severe reliability challenge in STT-MRAM caches. One major source of read disturbance error in STT-MRAM caches is simultaneous accesses to all tags for parallel comparison operation in a cache set, which has not been addressed in previous work. This paper first demonstrates that high read accesses to tag array extremely increase the read disturbance rate and then proposes a low-cost scheme, so-called Read Disturbance Rate Reduction in STT-MRAM Caches by Selective Tag Comparison (3RSeT), to reduce the error rate by eliminating a significant portion of tag reads. 3RSeT proactively disables the tags that have no chance for hit, using low significant bits of the tags on each access request. Our evaluations using gem5 full-system cycle-accurate simulator show that 3RSeT reduces the read disturbance rate in the tag array by 71.8%, which results in 3.6x improvement in Mean Time To Failure (MTTF). In addition, the energy consumption is reduced by 62.1% without compromising performance and with less than 0.4% area overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a3RSeT\u7684\u4f4e\u6210\u672c\u65b9\u6848\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6807\u7b7e\u6bd4\u8f83\u663e\u8457\u964d\u4f4eSTT-MRAM\u7f13\u5b58\u4e2d\u7684\u8bfb\u5e72\u6270\u9519\u8bef\u7387\uff0c\u4ece\u800c\u63d0\u5347\u53ef\u9760\u6027\u3001\u964d\u4f4e\u80fd\u8017\uff0c\u5e76\u51e0\u4e4e\u4e0d\u5f71\u54cd\u6027\u80fd\u548c\u9762\u79ef\u3002", "motivation": "STT-MRAM\u4f5c\u4e3aSRAM\u7684\u6f5c\u5728\u66ff\u4ee3\u54c1\uff0c\u5728\u7247\u4e0a\u7f13\u5b58\u4e2d\u9762\u4e34\u4e25\u91cd\u7684\u8bfb\u5e72\u6270\u9519\u8bef\u95ee\u9898\uff0c\u5c24\u5176\u5728\u5e76\u884c\u6807\u7b7e\u6bd4\u8f83\u64cd\u4f5c\u65f6\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u4e9f\u9700\u6709\u6548\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa3RSeT\u65b9\u6848\uff0c\u5229\u7528\u6807\u7b7e\u4f4e\u4f4d\u4fe1\u606f\u5728\u6bcf\u6b21\u8bbf\u95ee\u65f6\u4e3b\u52a8\u7981\u7528\u4e0d\u53ef\u80fd\u547d\u4e2d\uff08hit\uff09\u7684\u6807\u7b7e\uff0c\u4ece\u800c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u6807\u7b7e\u8bfb\u53d6\uff0c\u964d\u4f4e\u8bfb\u5e72\u6270\u53d1\u751f\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c3RSeT\u5c06\u6807\u7b7e\u9635\u5217\u7684\u8bfb\u5e72\u6270\u7387\u964d\u4f4e71.8%\uff0c\u5e73\u5747\u6545\u969c\u95f4\u9694\u65f6\u95f4\uff08MTTF\uff09\u63d0\u53473.6\u500d\uff0c\u80fd\u8017\u964d\u4f4e62.1%\uff0c\u4e14\u6027\u80fd\u65e0\u635f\u3001\u9762\u79ef\u5f00\u9500\u4f4e\u4e8e0.4%\u3002", "conclusion": "3RSeT\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u663e\u8457\u63d0\u5347STT-MRAM\u7f13\u5b58\u7684\u53ef\u9760\u6027\u4e0e\u80fd\u6548\uff0c\u9002\u7528\u4e8e\u672a\u6765\u9ad8\u5bc6\u5ea6\u975e\u6613\u5931\u6027\u7f13\u5b58\u8bbe\u8ba1\u3002"}}
{"id": "2511.22956", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.22956", "abs": "https://arxiv.org/abs/2511.22956", "authors": ["Atsushi Kitazawa", "Chihaya Ito", "Yuta Yoshida", "Takamitsu Shioi"], "title": "Extended Serial Safety Net: A Refined Serializability Criterion for Multiversion Concurrency Control", "comment": null, "summary": "A long line of concurrency-control (CC) protocols argues correctness via a single serialization point (begin or commit), an assumption that is incompatible with snapshot isolation (SI), where read-write anti-dependencies arise. Serial Safety Net (SSN) offers a lightweight commit-time test but is conservative and effectively anchored on commit time as the sole point. We present ESSN, a principled generalization of SSN that relaxes the exclusion condition to allow more transactions to commit safely, and we prove that this preserves multiversion serializability (MVSR) and that it strictly subsumes SSN. ESSN states an MVSG (Multiversion Serialization Graph)-based criterion and introduces a known total order over transactions (KTO; e.g., begin-ordered or commit-ordered) for reasoning about the graph's serializability. With a single commit-time check under invariant-based semantics, ESSN's exclusion condition preserves monotonicity along per-item version chains, and eliminates chain traversal. The protocol is Direct Serialization Graph (DSG)-based with commit-time work linear in the number of reads and writes, matching SSN's per-version footprint. We also make mixed workloads explicit by defining a Long transaction via strict interval containment of Short transactions, and we evaluate ESSN on reproducible workloads. Under a commit-ordered KTO, using begin-snapshot reads reduces the long-transaction abort rate by up to approximately 0.25 absolute (about 50% relative) compared with SSN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ESSN\uff0c\u4e00\u79cd\u5bf9Serial Safety Net\uff08SSN\uff09\u534f\u8bae\u7684\u63a8\u5e7f\uff0c\u901a\u8fc7\u653e\u5bbd\u6392\u9664\u6761\u4ef6\uff0c\u5728\u4fdd\u8bc1\u591a\u7248\u672c\u53ef\u4e32\u884c\u5316\uff08MVSR\uff09\u7684\u540c\u65f6\u5141\u8bb8\u66f4\u591a\u4e8b\u52a1\u5b89\u5168\u63d0\u4ea4\uff0c\u5e76\u5728\u6df7\u5408\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u663e\u8457\u964d\u4f4e\u957f\u4e8b\u52a1\u7684\u4e2d\u6b62\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5355\u4e00\u5e8f\u5217\u5316\u70b9\uff08\u5982\u5f00\u59cb\u6216\u63d0\u4ea4\u65f6\u523b\uff09\u7684\u5e76\u53d1\u63a7\u5236\u534f\u8bae\u65e0\u6cd5\u517c\u5bb9\u5feb\u7167\u9694\u79bb\uff08SI\uff09\uff0c\u800cSSN\u867d\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u63d0\u4ea4\u65f6\u68c0\u6d4b\uff0c\u4f46\u8fc7\u4e8e\u4fdd\u5b88\u4e14\u4ec5\u4ee5\u63d0\u4ea4\u65f6\u95f4\u4e3a\u951a\u70b9\uff0c\u9650\u5236\u4e86\u5e76\u53d1\u6027\u80fd\u3002", "method": "ESSN\u5f15\u5165\u57fa\u4e8e\u591a\u7248\u672c\u5e8f\u5217\u5316\u56fe\uff08MVSG\uff09\u7684\u5224\u5b9a\u51c6\u5219\uff0c\u5e76\u5229\u7528\u4e8b\u52a1\u7684\u5df2\u77e5\u5168\u5e8f\uff08KTO\uff0c\u5982\u6309\u5f00\u59cb\u6216\u63d0\u4ea4\u6392\u5e8f\uff09\u6765\u63a8\u7406\u53ef\u4e32\u884c\u6027\uff1b\u5176\u5728\u63d0\u4ea4\u65f6\u8fdb\u884c\u4e00\u6b21\u68c0\u67e5\uff0c\u7ef4\u6301\u5404\u6570\u636e\u9879\u7248\u672c\u94fe\u4e0a\u7684\u5355\u8c03\u6027\uff0c\u907f\u514d\u94fe\u904d\u5386\uff0c\u4e14\u5f00\u9500\u4e0eSSN\u76f8\u5f53\u3002", "result": "\u5728\u63d0\u4ea4\u6709\u5e8f\u7684KTO\u4e0b\uff0c\u4f7f\u7528\u5f00\u59cb\u5feb\u7167\u8bfb\u53d6\u53ef\u4f7f\u957f\u4e8b\u52a1\u7684\u4e2d\u6b62\u7387\u76f8\u6bd4SSN\u6700\u591a\u964d\u4f4e\u7ea60.25\uff08\u7edd\u5bf9\u503c\uff09\uff0c\u5373\u76f8\u5bf9\u51cf\u5c11\u7ea650%\u3002", "conclusion": "ESSN\u5728\u4fdd\u6301\u591a\u7248\u672c\u53ef\u4e32\u884c\u5316\u7684\u540c\u65f6\u4e25\u683c\u5305\u542b\u5e76\u4f18\u4e8eSSN\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6df7\u5408\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u4e8b\u52a1\u63d0\u4ea4\u6210\u529f\u7387\u548c\u7cfb\u7edf\u5e76\u53d1\u6027\u80fd\u3002"}}
{"id": "2511.21920", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21920", "abs": "https://arxiv.org/abs/2511.21920", "authors": ["Apu Kumar Chakroborti", "Yi Ding", "Lipeng Wan"], "title": "Toward Automated and Trustworthy Scientific Analysis and Visualization with LLM-Generated Code", "comment": null, "summary": "As modern science becomes increasingly data-intensive, the ability to analyze and visualize large-scale, complex datasets is critical to accelerating discovery. However, many domain scientists lack the programming expertise required to develop custom data analysis workflows, creating barriers to timely and effective insight. Large language models (LLMs) offer a promising solution by generating executable code from natural language descriptions. In this paper, we investigate the trustworthiness of open-source LLMs in autonomously producing Python scripts for scientific data analysis and visualization. We construct a benchmark suite of domain-inspired prompts that reflect real-world research tasks and systematically evaluate the executability and correctness of the generated code. Our findings show that, without human intervention, the reliability of LLM-generated code is limited, with frequent failures caused by ambiguous prompts and the models' insufficient understanding of domain-specific contexts. To address these challenges, we design and assess three complementary strategies: data-aware prompt disambiguation, retrieval-augmented prompt enhancement, and iterative error repair. While these methods significantly improve execution success rates and output quality, further refinement is needed. This work highlights both the promise and current limitations of LLM-driven automation in scientific workflows and introduces actionable techniques and a reusable benchmark for building more inclusive, accessible, and trustworthy AI-assisted research tools.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u79d1\u5b66\u6570\u636e\u5206\u6790\u4e0e\u53ef\u89c6\u5316\u4efb\u52a1\u4e2d\u81ea\u52a8\u751f\u6210Python\u4ee3\u7801\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u5176\u5728\u65e0\u5e72\u9884\u60c5\u51b5\u4e0b\u5b58\u5728\u6267\u884c\u5931\u8d25\u548c\u7406\u89e3\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e09\u79cd\u6539\u8fdb\u7b56\u7565\u4ee5\u63d0\u5347\u751f\u6210\u4ee3\u7801\u7684\u53ef\u6267\u884c\u6027\u4e0e\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u4ee3\u79d1\u5b66\u7814\u7a76\u65e5\u76ca\u4f9d\u8d56\u5927\u89c4\u6a21\u590d\u6742\u6570\u636e\u7684\u5206\u6790\u4e0e\u53ef\u89c6\u5316\uff0c\u4f46\u8bb8\u591a\u9886\u57df\u79d1\u5b66\u5bb6\u7f3a\u4e4f\u7f16\u7a0b\u80fd\u529b\uff0c\u96be\u4ee5\u6784\u5efa\u5b9a\u5236\u5316\u5206\u6790\u6d41\u7a0b\u3002\u5927\u8bed\u8a00\u6a21\u578b\u6709\u671b\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u6765\u964d\u4f4e\u8fd9\u4e00\u95e8\u69db\uff0c\u4f46\u5176\u5728\u79d1\u5b66\u573a\u666f\u4e0b\u7684\u53ef\u4fe1\u5ea6\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u79d1\u7814\u4efb\u52a1\u7684\u63d0\u793a\u8bcd\u57fa\u51c6\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5f00\u6e90LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u6267\u884c\u6027\u4e0e\u6b63\u786e\u6027\uff1b\u5e76\u8bbe\u8ba1\u4e09\u79cd\u7b56\u7565\uff1a\u6570\u636e\u611f\u77e5\u7684\u63d0\u793a\u6d88\u6b67\u3001\u68c0\u7d22\u589e\u5f3a\u7684\u63d0\u793a\u4f18\u5316\u548c\u8fed\u4ee3\u5f0f\u9519\u8bef\u4fee\u590d\uff0c\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "result": "\u672a\u7ecf\u4eba\u5de5\u5e72\u9884\u65f6\uff0cLLM\u751f\u6210\u7684\u4ee3\u7801\u53ef\u9760\u6027\u6709\u9650\uff0c\u5e38\u56e0\u63d0\u793a\u6a21\u7cca\u6216\u7f3a\u4e4f\u9886\u57df\u7406\u89e3\u800c\u5931\u8d25\uff1b\u6240\u63d0\u51fa\u7684\u4e09\u79cd\u7b56\u7565\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u6267\u884c\u6210\u529f\u7387\u548c\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "LLM\u5728\u79d1\u5b66\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\uff1b\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u7528\u7684\u57fa\u51c6\u548c\u5b9e\u7528\u6280\u672f\uff0c\u4e3a\u6784\u5efa\u66f4\u5305\u5bb9\u3001\u6613\u7528\u4e14\u53ef\u4fe1\u7684AI\u8f85\u52a9\u79d1\u7814\u5de5\u5177\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.22481", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.22481", "abs": "https://arxiv.org/abs/2511.22481", "authors": ["Jun Wang", "Yunxiang Yao", "Wenwei Kuang", "Runze Mao", "Zhenhao Sun", "Zhuang Tao", "Ziyang Zhang", "Dengyu Li", "Jiajun Chen", "Zhili Wang", "Kai Cui", "Congzhi Cai", "Longwen Lan", "Ken Zhang"], "title": "OmniInfer: System-Wide Acceleration Techniques for Optimizing LLM Serving Throughput and Latency", "comment": "Project page: [this https URL](https://gitee.com/omniai/omniinfer)", "summary": "Large Language Models drive a wide range of modern AI applications but impose substantial challenges on large-scale serving systems due to intensive computation, strict latency constraints, and throughput bottlenecks. We introduce OmniInfer, a unified system-level acceleration framework designed to maximize end-to-end serving efficiency through fine-grained optimization of expert placement, cache compression, and scheduling. OmniInfer integrates three complementary components: OmniPlacement for load-aware Mixture-of-Experts scheduling, OmniAttn for sparse attention acceleration, and OmniProxy for disaggregation-aware request scheduling. Built atop vLLM, OmniInfer delivers system-wide performance gains through adaptive resource disaggregation, efficient sparsity exploitation, and global coordination across prefill and decode phases. Evaluated on DeepSeek-R1 within a 10-node Ascend 910C cluster, OmniInfer achieves 616 QPM, where the unified framework reduces TPOT by 36\\%, and the superimposition of OmniProxy further slashes TTFT by 38\\%. The project is open-sourced at [this https URL](https://gitee.com/omniai/omniinfer).", "AI": {"tldr": "OmniInfer \u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u7cfb\u7edf\u7ea7\u52a0\u901f\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u653e\u7f6e\u3001\u7f13\u5b58\u538b\u7f29\u548c\u8c03\u5ea6\u7684\u7ec6\u7c92\u5ea6\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u7aef\u5230\u7aef\u6548\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u9762\u4e34\u8ba1\u7b97\u5bc6\u96c6\u3001\u5ef6\u8fdf\u4e25\u683c\u548c\u541e\u5410\u74f6\u9888\u7b49\u6311\u6218\uff0c\u4e9f\u9700\u7cfb\u7edf\u7ea7\u4f18\u5316\u65b9\u6848\u4ee5\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "method": "OmniInfer \u57fa\u4e8e vLLM \u6784\u5efa\uff0c\u6574\u5408\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1aOmniPlacement\uff08\u8d1f\u8f7d\u611f\u77e5\u7684\u6df7\u5408\u4e13\u5bb6\u8c03\u5ea6\uff09\u3001OmniAttn\uff08\u7a00\u758f\u6ce8\u610f\u529b\u52a0\u901f\uff09\u548c OmniProxy\uff08\u9762\u5411\u8d44\u6e90\u89e3\u8026\u7684\u8bf7\u6c42\u8c03\u5ea6\uff09\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u8d44\u6e90\u89e3\u8026\u3001\u9ad8\u6548\u7a00\u758f\u6027\u5229\u7528\u53ca\u9884\u586b\u5145\u4e0e\u89e3\u7801\u9636\u6bb5\u7684\u5168\u5c40\u534f\u8c03\u5b9e\u73b0\u7cfb\u7edf\u7ea7\u4f18\u5316\u3002", "result": "\u5728 10 \u8282\u70b9 Ascend 910C \u96c6\u7fa4\u4e0a\u4f7f\u7528 DeepSeek-R1 \u8bc4\u4f30\uff0cOmniInfer \u8fbe\u5230 616 QPM\uff0c\u6574\u4f53\u6846\u67b6\u964d\u4f4e TPOT 36%\uff0c\u53e0\u52a0 OmniProxy \u540e\u8fdb\u4e00\u6b65\u51cf\u5c11 TTFT 38%\u3002", "conclusion": "OmniInfer \u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u7684\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u5177\u5907\u826f\u597d\u7684\u5b9e\u7528\u4ef7\u503c\uff0c\u5e76\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.22889", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.22889", "abs": "https://arxiv.org/abs/2511.22889", "authors": ["Fang Li"], "title": "The Immutable Tensor Architecture: A Pure Dataflow Approach for Secure, Energy-Efficient AI Inference", "comment": "Code and data can be found here: https://github.com/fanglioc/ita-fpga-prototype", "summary": "The deployment of Large Language Models (LLMs) on consumer edge devices is throttled by the \"Memory Wall\" -- the prohibitive bandwidth and energy cost of fetching gigabytes of model weights from DRAM for every token generated. Current architectures (GPUs, NPUs) treat model weights as mutable software data, incurring massive energy penalties to maintain general-purpose programmability. We propose The Immutable Tensor Architecture (ITA), a paradigm shift that treats model weights not as data, but as physical circuit topology. By encoding parameters directly into the metal interconnects and logic of mature-node ASICs (28nm/40nm), ITA eliminates the memory hierarchy entirely. We present a \"Split-Brain\" system design where a host CPU manages dynamic KV-cache operations while the ITA ASIC acts as a stateless, ROM-embedded dataflow engine.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u4e0d\u53ef\u53d8\u5f20\u91cf\u67b6\u6784\u201d\uff08ITA\uff09\u7684\u65b0\u786c\u4ef6\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u56fa\u5316\u5230ASIC\u7684\u91d1\u5c5e\u4e92\u8fde\u4e0e\u903b\u8f91\u4e2d\uff0c\u5f7b\u5e95\u6d88\u9664\u5185\u5b58\u5c42\u7ea7\uff0c\u4ece\u800c\u7a81\u7834\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72LLM\u65f6\u9762\u4e34\u7684\u201c\u5185\u5b58\u5899\u201d\u74f6\u9888\u3002", "motivation": "\u5f53\u524d\u5728\u6d88\u8d39\u7ea7\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u53d7\u9650\u4e8e\u201c\u5185\u5b58\u5899\u201d\u95ee\u9898\u2014\u2014\u6bcf\u6b21\u751f\u6210token\u90fd\u9700\u8981\u4eceDRAM\u4e2d\u8bfb\u53d6GB\u7ea7\u6a21\u578b\u6743\u91cd\uff0c\u5e26\u6765\u5de8\u5927\u7684\u5e26\u5bbd\u548c\u80fd\u8017\u5f00\u9500\uff1b\u73b0\u6709GPU/NPU\u67b6\u6784\u5c06\u6743\u91cd\u89c6\u4e3a\u53ef\u53d8\u8f6f\u4ef6\u6570\u636e\uff0c\u4e3a\u4fdd\u6301\u901a\u7528\u53ef\u7f16\u7a0b\u6027\u800c\u4ed8\u51fa\u9ad8\u6602\u80fd\u8017\u4ee3\u4ef7\u3002", "method": "\u63d0\u51faITA\u67b6\u6784\uff0c\u5c06\u6a21\u578b\u6743\u91cd\u7f16\u7801\u8fdb\u6210\u719f\u5de5\u827a\u8282\u70b9\uff0828nm/40nm\uff09ASIC\u7684\u7269\u7406\u7535\u8def\u62d3\u6251\u4e2d\uff0c\u4f7f\u5176\u6210\u4e3a\u4e0d\u53ef\u53d8\u7684\u786c\u4ef6\u7ed3\u6784\uff1b\u5e76\u91c7\u7528\u201cSplit-Brain\u201d\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u7531\u4e3b\u673aCPU\u5904\u7406\u52a8\u6001KV\u7f13\u5b58\uff0cITA ASIC\u4f5c\u4e3a\u65e0\u72b6\u6001\u3001\u5185\u5d4cROM\u7684\u6570\u636e\u6d41\u5f15\u64ce\u3002", "result": "\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u4f20\u7edf\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\uff0c\u663e\u8457\u964d\u4f4e\u6743\u91cd\u8bbf\u95ee\u7684\u80fd\u8017\u4e0e\u5ef6\u8fdf\uff0c\u4e3a\u5728\u8fb9\u7f18\u8bbe\u5907\u9ad8\u6548\u90e8\u7f72LLM\u63d0\u4f9b\u65b0\u8def\u5f84\u3002", "conclusion": "\u5c06\u6a21\u578b\u6743\u91cd\u89c6\u4e3a\u7269\u7406\u7535\u8def\u800c\u975e\u8f6f\u4ef6\u6570\u636e\uff0c\u662f\u4e00\u79cd\u7a81\u7834\u201c\u5185\u5b58\u5899\u201d\u7684\u6709\u6548\u8303\u5f0f\u8f6c\u53d8\uff0cITA\u67b6\u6784\u5c55\u793a\u4e86\u5728\u6210\u719f\u5236\u7a0b\u4e0b\u5b9e\u73b0\u9ad8\u80fd\u6548LLM\u63a8\u7406\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.21956", "categories": ["cs.SE", "physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2511.21956", "abs": "https://arxiv.org/abs/2511.21956", "authors": ["M. Polzin", "M. Guzman"], "title": "Beyond Like-for-Like: A User-centered Approach to Modernizing Legacy Applications", "comment": "The 20th International Conference on Accelerator and Large Experimental Physics Control Systems", "summary": "When modernizing a legacy application, it is easy to fall back on a like-for-like replica with new tools and updated design stylings, but this is an opportunity to explore making a more intuitive application that supports user tasks and efficiency. Rather than having a blank canvas-unburdened by legacy tech debt-to create a new application, you are working with an existing application that is integral to accelerator operations and one that expert users are already familiar with. Due to this, you might assume people will prefer the like-for-like, but you could be carrying forward the pain points, processes that are inefficient, and ultimately wind up with an application that no one wants to use because it doesn't solve existing problems. Getting users involved can make all the difference in your approach to modernizing a legacy application that caters to both newer and expert users. It also can bridge the gap between like-for-like and introducing new GUI design. Having a legacy application doesn't have to make the modernized one difficult to develop, as the existing application is a tool in how you move forward with the new application. It provides insight into areas that an application with a clean slate doesn't give you.", "AI": {"tldr": "\u5728\u73b0\u4ee3\u5316\u9057\u7559\u5e94\u7528\u7a0b\u5e8f\u65f6\uff0c\u4e0d\u5e94\u4ec5\u505a\u8868\u9762\u7ffb\u65b0\uff0c\u800c\u5e94\u901a\u8fc7\u7528\u6237\u53c2\u4e0e\u4f18\u5316\u7528\u6237\u4f53\u9a8c\uff0c\u517c\u987e\u65b0\u8001\u7528\u6237\u9700\u6c42\uff0c\u5e76\u5229\u7528\u539f\u6709\u7cfb\u7edf\u7684\u4f18\u52bf\u6307\u5bfc\u65b0\u8bbe\u8ba1\u3002", "motivation": "\u907f\u514d\u5728\u73b0\u4ee3\u5316\u8fc7\u7a0b\u4e2d\u7b80\u5355\u590d\u5236\u65e7\u7cfb\u7edf\uff0c\u4ece\u800c\u5ef6\u7eed\u5176\u4f4e\u6548\u6d41\u7a0b\u548c\u75db\u70b9\uff0c\u5bfc\u81f4\u65b0\u5e94\u7528\u65e0\u6cd5\u6ee1\u8db3\u7528\u6237\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u8ba9\u7528\u6237\u79ef\u6781\u53c2\u4e0e\u73b0\u4ee3\u5316\u8fc7\u7a0b\uff0c\u7ed3\u5408\u9057\u7559\u7cfb\u7edf\u7684\u65e2\u6709\u4fe1\u606f\u4e0e\u65b0GUI\u8bbe\u8ba1\u7406\u5ff5\uff0c\u5e73\u8861\u201c\u539f\u6837\u590d\u523b\u201d\u4e0e\u521b\u65b0\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u901a\u8fc7\u5229\u7528\u73b0\u6709\u9057\u7559\u5e94\u7528\u4f5c\u4e3a\u8bbe\u8ba1\u53c2\u8003\uff0c\u5e76\u878d\u5408\u7528\u6237\u53cd\u9988\uff0c\u53ef\u5f00\u53d1\u51fa\u66f4\u76f4\u89c2\u3001\u9ad8\u6548\u4e14\u88ab\u7528\u6237\u63a5\u53d7\u7684\u65b0\u5e94\u7528\u3002", "conclusion": "\u9057\u7559\u5e94\u7528\u5e76\u975e\u73b0\u4ee3\u5316\u7684\u969c\u788d\uff0c\u800c\u662f\u5b9d\u8d35\u8d44\u6e90\uff1b\u901a\u8fc7\u7528\u6237\u53c2\u4e0e\u548c\u5408\u7406\u5229\u7528\u65e2\u6709\u7cfb\u7edf\uff0c\u53ef\u6253\u9020\u771f\u6b63\u89e3\u51b3\u7528\u6237\u95ee\u9898\u7684\u65b0\u4e00\u4ee3\u5e94\u7528\u3002"}}
{"id": "2511.22421", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.22421", "abs": "https://arxiv.org/abs/2511.22421", "authors": ["Hanshuai Cui", "Zhiqing Tang", "Zhi Yao", "Weijia Ji", "Wei Zhao"], "title": "Semantic-Aware Caching for Efficient Image Generation in Edge Computing", "comment": null, "summary": "Text-to-image generation employing diffusion models has attained significant popularity due to its capability to produce high-quality images that adhere to textual prompts. However, the integration of diffusion models faces critical challenges into resource-constrained mobile and edge environments because it requires multiple denoising steps from the original random noise. A practical way to speed up denoising is to initialize the process with a noised reference image that is similar to the target, since both images share similar layouts, structures, and details, allowing for fewer denoising steps. Based on this idea, we present CacheGenius, a hybrid image generation system in edge computing that accelerates generation by combining text-toimage and image-to-image workflows. It generates images from user text prompts using cached reference images. CacheGenius introduces a semantic-aware classified storage scheme and a request-scheduling algorithm that ensures semantic alignment between references and targets. To ensure sustained performance, it employs a cache maintenance policy that proactively evicts obsolete entries via correlation analysis. Evaluated in a distributed edge computing system, CacheGenius reduces generation latency by 41% and computational costs by 48% relative to baselines, while maintaining competitive evaluation metrics.", "AI": {"tldr": "CacheGenius \u662f\u4e00\u79cd\u9762\u5411\u8fb9\u7f18\u8ba1\u7b97\u7684\u6df7\u5408\u56fe\u50cf\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u6587\u672c\u5230\u56fe\u50cf\u4e0e\u56fe\u50cf\u5230\u56fe\u50cf\u6d41\u7a0b\uff0c\u5e76\u5229\u7528\u8bed\u4e49\u5bf9\u9f50\u7684\u7f13\u5b58\u53c2\u8003\u56fe\u50cf\u52a0\u901f\u6269\u6563\u6a21\u578b\u7684\u53bb\u566a\u8fc7\u7a0b\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u867d\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u56fe\u50cf\uff0c\u4f46\u5176\u591a\u6b65\u53bb\u566a\u8fc7\u7a0b\u5728\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u548c\u8fb9\u7f18\u8bbe\u5907\u4e0a\u6548\u7387\u4f4e\u4e0b\uff0c\u4e9f\u9700\u52a0\u901f\u65b9\u6848\u3002", "method": "\u63d0\u51fa CacheGenius \u7cfb\u7edf\uff0c\u91c7\u7528\u8bed\u4e49\u611f\u77e5\u7684\u5206\u7c7b\u5b58\u50a8\u7b56\u7565\u3001\u8bf7\u6c42\u8c03\u5ea6\u7b97\u6cd5\u4ee5\u786e\u4fdd\u53c2\u8003\u56fe\u50cf\u4e0e\u76ee\u6807\u8bed\u4e49\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u76f8\u5173\u6027\u5206\u6790\u7684\u7f13\u5b58\u7ef4\u62a4\u7b56\u7565\u4e3b\u52a8\u6dd8\u6c70\u8fc7\u65f6\u6761\u76ee\u3002", "result": "\u5728\u5206\u5e03\u5f0f\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0cCacheGenius \u5c06\u751f\u6210\u5ef6\u8fdf\u964d\u4f4e 41%\uff0c\u8ba1\u7b97\u6210\u672c\u51cf\u5c11 48%\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "\u901a\u8fc7\u6709\u6548\u5229\u7528\u7f13\u5b58\u53c2\u8003\u56fe\u50cf\u5e76\u4fdd\u969c\u8bed\u4e49\u4e00\u81f4\u6027\uff0cCacheGenius \u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u5728\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u9ad8\u6548\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.23011", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.23011", "abs": "https://arxiv.org/abs/2511.23011", "authors": ["Yanjing Wang", "Lizhou Wu", "Sunfeng Gao", "Yibo Tang", "Junhui Luo", "Zicong Wang", "Yang Ou", "Dezun Dong", "Nong Xiao", "Mingche Lai"], "title": "Cohet: A CXL-Driven Coherent Heterogeneous Computing Framework with Hardware-Calibrated Full-System Simulation", "comment": "Accepted by HPCA 2026", "summary": "Conventional heterogeneous computing systems built on PCIe interconnects suffer from inefficient fine-grained host-device interactions and complex programming models. In recent years, many proprietary and open cache-coherent interconnect standards have emerged, among which compute express link (CXL) prevails in the open-standard domain after acquiring several competing solutions. Although CXL-based coherent heterogeneous computing holds the potential to fundamentally transform the collaborative computing mode of CPUs and XPUs, research in this direction remains hampered by the scarcity of available CXL-supported platforms, immature software/hardware ecosystems, and unclear application prospects. This paper presents Cohet, the first CXL-driven coherent heterogeneous computing framework. Cohet decouples the compute and memory resources to form unbiased CPU and XPU pools which share a single unified and coherent memory pool. It exposes a standard malloc/mmap interface to both CPU and XPU compute threads, leaving the OS dealing with smart memory allocation and management of heterogeneous resources. To facilitate Cohet research, we also present a full-system cycle-level simulator named SimCXL, which is capable of modeling all CXL sub-protocols and device types. SimCXL has been rigorously calibrated against a real CXL testbed with various CXL memory and accelerators, showing an average simulation error of 3%. Our evaluation reveals that CXL.cache reduces latency by 68% and increases bandwidth by 14.4x compared to DMA transfers at cacheline granularity. Building upon these insights, we demonstrate the benefits of Cohet with two killer apps, which are remote atomic operation (RAO) and remote procedure call (RPC). Compared to PCIe-NIC design, CXL-NIC achieves a 5.5 to 40.2x speedup for RAO offloading and an average speedup of 1.86x for RPC (de)serialization offloading.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Cohet\u2014\u2014\u9996\u4e2a\u57fa\u4e8eCXL\u7684\u7f13\u5b58\u4e00\u81f4\u5f02\u6784\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u8ba1\u7b97\u4e0e\u5185\u5b58\u8d44\u6e90\u6784\u5efa\u7edf\u4e00\u4e00\u81f4\u5185\u5b58\u6c60\uff0c\u5e76\u63d0\u4f9b\u6807\u51c6\u5185\u5b58\u63a5\u53e3\uff1b\u540c\u65f6\u5f00\u53d1\u4e86\u9ad8\u7cbe\u5ea6\u5168\u7cfb\u7edf\u6a21\u62df\u5668SimCXL\uff0c\u5b9e\u9a8c\u8868\u660eCXL\u5728\u5ef6\u8fdf\u3001\u5e26\u5bbd\u53ca\u5178\u578b\u5e94\u7528\uff08\u5982RAO\u548cRPC\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edfPCIe\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8ePCIe\u7684\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\u5b58\u5728\u7ec6\u7c92\u5ea6\u4e3b\u673a-\u8bbe\u5907\u4ea4\u4e92\u6548\u7387\u4f4e\u548c\u7f16\u7a0b\u6a21\u578b\u590d\u6742\u7684\u95ee\u9898\uff1b\u5c3d\u7ba1CXL\u7b49\u7f13\u5b58\u4e00\u81f4\u4e92\u8fde\u6807\u51c6\u5174\u8d77\uff0c\u4f46\u53d7\u9650\u4e8e\u786c\u4ef6\u5e73\u53f0\u7a00\u7f3a\u3001\u8f6f\u786c\u4ef6\u751f\u6001\u4e0d\u6210\u719f\u53ca\u5e94\u7528\u573a\u666f\u4e0d\u660e\uff0c\u76f8\u5173\u7814\u7a76\u8fdb\u5c55\u7f13\u6162\u3002", "method": "\u63d0\u51faCohet\u6846\u67b6\uff0c\u5c06CPU\u4e0eXPU\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u8d44\u6e90\u89e3\u8026\uff0c\u6784\u5efa\u5171\u4eab\u7684\u7edf\u4e00\u7f13\u5b58\u4e00\u81f4\u5185\u5b58\u6c60\uff0c\u5e76\u5411\u8ba1\u7b97\u7ebf\u7a0b\u66b4\u9732\u6807\u51c6malloc/mmap\u63a5\u53e3\uff1b\u540c\u65f6\u5f00\u53d1\u652f\u6301\u6240\u6709CXL\u5b50\u534f\u8bae\u548c\u8bbe\u5907\u7c7b\u578b\u7684\u5468\u671f\u7ea7\u5168\u7cfb\u7edf\u6a21\u62df\u5668SimCXL\uff0c\u5e76\u901a\u8fc7\u771f\u5b9eCXL\u6d4b\u8bd5\u5e73\u53f0\u6821\u51c6\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u76f8\u6bd4DMA\u4f20\u8f93\uff0cCXL.cache\u5728\u7f13\u5b58\u884c\u7c92\u5ea6\u4e0b\u5ef6\u8fdf\u964d\u4f4e68%\uff0c\u5e26\u5bbd\u63d0\u534714.4\u500d\uff1b\u5728\u8fdc\u7a0b\u539f\u5b50\u64cd\u4f5c\uff08RAO\uff09\u548c\u8fdc\u7a0b\u8fc7\u7a0b\u8c03\u7528\uff08RPC\uff09\u4e24\u4e2a\u5178\u578b\u5e94\u7528\u4e2d\uff0cCXL-NIC\u76f8\u8f83PCIe-NIC\u5206\u522b\u5b9e\u73b05.5\u201340.2\u500d\u548c\u5e73\u57471.86\u500d\u7684\u52a0\u901f\u3002", "conclusion": "CXL\u9a71\u52a8\u7684\u7f13\u5b58\u4e00\u81f4\u5f02\u6784\u8ba1\u7b97\u80fd\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u4e0e\u7f16\u7a0b\u6548\u7387\uff0cCohet\u6846\u67b6\u4e0eSimCXL\u6a21\u62df\u5668\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u548c\u9a8c\u8bc1\u57fa\u7840\uff0c\u5c55\u793a\u4e86CXL\u5728\u4e0b\u4e00\u4ee3\u5f02\u6784\u8ba1\u7b97\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.21964", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.21964", "abs": "https://arxiv.org/abs/2511.21964", "authors": ["Ali Sayedsalehi", "Peter C. Rigby", "Audris Mockus"], "title": "DRS-OSS: LLM-Driven Diff Risk Scoring Tool for PR Risk Prediction", "comment": "8 pages, 4 figures, includes system architecture diagrams, Web UI screenshots, GitHub App examples, and an appendix with API endpoints. Full replication package and demo materials available", "summary": "In large-scale open-source projects, hundreds of pull requests land daily, each a potential source of regressions. Diff Risk Scoring (DRS) estimates the likelihood that a diff will introduce a defect, enabling better review prioritization, test planning, and CI/CD gating. We present DRS-OSS, an open-source DRS system equipped with a public API, web UI, and GitHub plugin. DRS-OSS uses a fine-tuned Llama 3.1 8B sequence classifier trained on the ApacheJIT dataset, consuming long-context representations that combine commit messages, structured diffs, and change metrics. Through parameter-efficient adaptation, 4-bit QLoRA, and DeepSpeed ZeRO-3 CPU offloading, we train 22k-token contexts on a single 20 GB GPU. On the ApacheJIT benchmark, DRS-OSS achieves state-of-the-art performance (F1 = 0.64, ROC-AUC = 0.89). Simulations show that gating only the riskiest 30% of commits can prevent up to 86.4% of defect-inducing changes. The system integrates with developer workflows through an API gateway, a React dashboard, and a GitHub App that posts risk labels on pull requests. We release the full replication package, fine-tuning scripts, deployment artifacts, code, demo video, and public website.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DRS-OSS\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684\u5dee\u5f02\u98ce\u9669\u8bc4\u5206\u7cfb\u7edf\uff0c\u5229\u7528\u5fae\u8c03\u540e\u7684Llama 3.1 8B\u6a21\u578b\u5bf9\u4ee3\u7801\u63d0\u4ea4\u8fdb\u884c\u7f3a\u9677\u98ce\u9669\u9884\u6d4b\uff0c\u5728ApacheJIT\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u5e76\u901a\u8fc7GitHub\u63d2\u4ef6\u3001Web\u754c\u9762\u548cAPI\u96c6\u6210\u5230\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u4e2d\u3002", "motivation": "\u5728\u5927\u578b\u5f00\u6e90\u9879\u76ee\u4e2d\uff0c\u6bcf\u5929\u6709\u5927\u91cf\u62c9\u53d6\u8bf7\u6c42\u5408\u5e76\uff0c\u53ef\u80fd\u5f15\u5165\u56de\u5f52\u7f3a\u9677\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u8bc4\u4f30\u6bcf\u4e2a\u4ee3\u7801\u5dee\u5f02\uff08diff\uff09\u5f15\u5165\u7f3a\u9677\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u4f18\u5316\u4ee3\u7801\u5ba1\u67e5\u4f18\u5148\u7ea7\u3001\u6d4b\u8bd5\u8ba1\u5212\u548cCI/CD\u95e8\u7981\u7b56\u7565\u3002", "method": "\u57fa\u4e8eApacheJIT\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\uff084-bit QLoRA\uff09\u548cDeepSpeed ZeRO-3 CPU\u5378\u8f7d\uff0c\u5728\u5355\u5f2020GB GPU\u4e0a\u8bad\u7ec3Llama 3.1 8B\u5e8f\u5217\u5206\u7c7b\u5668\uff0c\u8f93\u5165\u5305\u542b\u63d0\u4ea4\u4fe1\u606f\u3001\u7ed3\u6784\u5316diff\u548c\u53d8\u66f4\u6307\u6807\u7684\u957f\u4e0a\u4e0b\u6587\uff08\u6700\u957f22k token\uff09\u3002\u7cfb\u7edf\u63d0\u4f9bGitHub\u63d2\u4ef6\u3001React\u4eea\u8868\u76d8\u548cAPI\u7f51\u5173\u3002", "result": "\u5728ApacheJIT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDRS-OSS\u53d6\u5f97F1=0.64\u3001ROC-AUC=0.89\u7684SOTA\u6027\u80fd\uff1b\u6a21\u62df\u663e\u793a\uff0c\u4ec5\u5bf9\u98ce\u9669\u6700\u9ad8\u768430%\u63d0\u4ea4\u5b9e\u65bd\u95e8\u7981\uff0c\u53ef\u963b\u6b62\u9ad8\u8fbe86.4%\u7684\u7f3a\u9677\u5f15\u5165\u3002", "conclusion": "DRS-OSS\u662f\u4e00\u4e2a\u5b9e\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u5f00\u6e90\u5dee\u5f02\u98ce\u9669\u8bc4\u5206\u7cfb\u7edf\uff0c\u80fd\u6709\u6548\u652f\u6301\u7f3a\u9677\u9884\u9632\u548c\u5f00\u53d1\u6d41\u7a0b\u96c6\u6210\uff0c\u5e76\u5df2\u516c\u5f00\u53d1\u5e03\u5b8c\u6574\u590d\u73b0\u5305\u548c\u90e8\u7f72\u8d44\u6e90\u3002"}}
{"id": "2511.22779", "categories": ["cs.DC", "physics.med-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.22779", "abs": "https://arxiv.org/abs/2511.22779", "authors": ["Shijie Yan", "Douglas Dwyer", "David R. Kaeli", "Qianqian Fang"], "title": "Accelerating mesh-based Monte Carlo simulations using contemporary graphics ray-tracing hardware", "comment": null, "summary": "Significance: Monte Carlo (MC) methods are the gold-standard for modeling light-tissue interactions due to their accuracy. Mesh-based MC (MMC) offers enhanced precision for complex tissue structures using tetrahedral mesh models. Despite significant speedups achieved on graphics processing units (GPUs), MMC performance remains hindered by the computational cost of frequent ray-boundary intersection tests.\n  Aim: We propose a highly accelerated MMC algorithm, RT-MMC, that leverages the hardware-accelerated ray traversal and intersection capabilities of ray-tracing cores (RT-cores) on modern GPUs.\n  Approach: Implemented using NVIDIA's OptiX platform, RT-MMC extends graphics ray-tracing pipelines towards volumetric ray-tracing in turbid media, eliminating the need for challenging tetrahedral mesh generation while delivering significant speed improvements through hardware acceleration. It also intrinsically supports wide-field sources without complex mesh retesselation.\n  Results: RT-MMC demonstrates excellent agreement with traditional software-ray-tracing MMC algorithms while achieving 1.5x to 4.5x speedups across multiple GPU architectures. These performance gains significantly enhance the practicality of MMC for routine simulations.\n  Conclusion: Migration from software- to hardware-based ray-tracing not only greatly simplifies MMC simulation workflows, but also results in significant speedups that are expected to increase further as ray-tracing hardware rapidly gains adoption. Adoption of graphics ray-tracing pipelines in quantitative MMC simulations enables leveraging of emerging hardware resources and benefits a wide range of biophotonics applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPU\u5149\u7ebf\u8ffd\u8e2a\u6838\u5fc3\uff08RT-cores\uff09\u7684\u52a0\u901f\u7248\u7f51\u683c\u8499\u7279\u5361\u6d1b\u5149\u4f20\u8f93\u6a21\u62df\u7b97\u6cd5RT-MMC\uff0c\u5229\u7528NVIDIA OptiX\u5e73\u53f0\u5b9e\u73b0\u786c\u4ef6\u52a0\u901f\u7684\u4f53\u5149\u7ebf\u8ffd\u8e2a\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u83b7\u5f971.5\u81f34.5\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u7f51\u683c\u8499\u7279\u5361\u6d1b\uff08MMC\uff09\u65b9\u6cd5\u867d\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u56e0\u9891\u7e41\u8fdb\u884c\u5149\u7ebf-\u8fb9\u754c\u76f8\u4ea4\u6d4b\u8bd5\u800c\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u7ec4\u7ec7\u7ed3\u6784\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6548\u7387\u3002", "method": "\u91c7\u7528NVIDIA OptiX\u5e73\u53f0\uff0c\u5c06\u56fe\u5f62\u5b66\u4e2d\u7684\u5149\u7ebf\u8ffd\u8e2a\u7ba1\u7ebf\u6269\u5c55\u81f3\u6d51\u6d4a\u4ecb\u8d28\u4e2d\u7684\u4f53\u5149\u7ebf\u8ffd\u8e2a\uff0c\u5229\u7528\u73b0\u4ee3GPU\u4e0a\u7684RT-cores\u8fdb\u884c\u786c\u4ef6\u52a0\u901f\uff0c\u907f\u514d\u590d\u6742\u7684\u56db\u9762\u4f53\u7f51\u683c\u751f\u6210\uff0c\u5e76\u539f\u751f\u652f\u6301\u5bbd\u573a\u5149\u6e90\u3002", "result": "RT-MMC\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u5149\u7ebf\u8ffd\u8e2aMMC\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5728\u591a\u79cdGPU\u67b6\u6784\u4e0a\u5b9e\u73b01.5x\u81f34.5x\u7684\u52a0\u901f\uff0c\u663e\u8457\u63d0\u5347MMC\u5728\u5e38\u89c4\u6a21\u62df\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u4ece\u8f6f\u4ef6\u5149\u7ebf\u8ffd\u8e2a\u8f6c\u5411\u786c\u4ef6\u5149\u7ebf\u8ffd\u8e2a\u4e0d\u4ec5\u7b80\u5316\u4e86MMC\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8fd8\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u968f\u7740\u5149\u7ebf\u8ffd\u8e2a\u786c\u4ef6\u7684\u666e\u53ca\uff0c\u8be5\u65b9\u6cd5\u5c06\u5728\u751f\u7269\u5149\u5b50\u5b66\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2511.23203", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23203", "abs": "https://arxiv.org/abs/2511.23203", "authors": ["Jordi Fornt", "Pau Fontova-Must\u00e9", "Adrian Gras", "Omar Lahyani", "Mart\u00ed Caro", "Jaume Abella", "Francesc Moll", "Josep Altet"], "title": "GAVINA: flexible aggressive undervolting for bit-serial mixed-precision DNN acceleration", "comment": "Presented in the 2025 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED). Conference proceedings pending to be published", "summary": "Voltage overscaling, or undervolting, is an enticing approximate technique in the context of energy-efficient Deep Neural Network (DNN) acceleration, given the quadratic relationship between power and voltage. Nevertheless, its very high error rate has thwarted its general adoption. Moreover, recent undervolting accelerators rely on 8-bit arithmetic and cannot compete with state-of-the-art low-precision (<8b) architectures. To overcome these issues, we propose a new technique called Guarded Aggressive underVolting (GAV), which combines the ideas of undervolting and bit-serial computation to create a flexible approximation method based on aggressively lowering the supply voltage on a select number of least significant bit combinations. Based on this idea, we implement GAVINA (GAV mIxed-precisioN Accelerator), a novel architecture that supports arbitrary mixed precision and flexible undervolting, with an energy efficiency of up to 89 TOP/sW in its most aggressive configuration. By developing an error model of GAVINA, we show that GAV can achieve an energy efficiency boost of 20% via undervolting, with negligible accuracy degradation on ResNet-18.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGAV\u7684\u65b0\u6280\u672f\uff0c\u7ed3\u5408\u6b20\u538b\u4e0e\u4f4d\u4e32\u884c\u8ba1\u7b97\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u80fd\u6548\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u4e86\u652f\u6301\u6df7\u5408\u7cbe\u5ea6\u7684\u52a0\u901f\u5668GAVINA\u3002", "motivation": "\u7535\u538b\u8fc7\u7f29\u653e\uff08\u6b20\u538b\uff09\u867d\u80fd\u663e\u8457\u964d\u4f4e\u529f\u8017\uff0c\u4f46\u9519\u8bef\u7387\u9ad8\u4e14\u73b0\u6709\u65b9\u6848\u591a\u9650\u4e8e8\u4f4d\u8fd0\u7b97\uff0c\u96be\u4ee5\u4e0e\u5f53\u524d\u4f4e\u7cbe\u5ea6\uff08<8\u4f4d\uff09\u67b6\u6784\u7ade\u4e89\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u517c\u987e\u80fd\u6548\u4e0e\u7cbe\u5ea6\u7684\u65b0\u578b\u8fd1\u4f3c\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGuarded Aggressive underVolting\uff08GAV\uff09\u6280\u672f\uff0c\u901a\u8fc7\u5728\u9009\u5b9a\u7684\u6700\u4f4e\u6709\u6548\u4f4d\u7ec4\u5408\u4e0a\u6fc0\u8fdb\u5730\u964d\u4f4e\u4f9b\u7535\u7535\u538b\uff0c\u7ed3\u5408\u4f4d\u4e32\u884c\u8ba1\u7b97\u5b9e\u73b0\u7075\u6d3b\u8fd1\u4f3c\uff1b\u5e76\u636e\u6b64\u8bbe\u8ba1\u4e86\u652f\u6301\u4efb\u610f\u6df7\u5408\u7cbe\u5ea6\u548c\u7075\u6d3b\u6b20\u538b\u7684\u52a0\u901f\u5668GAVINA\u3002", "result": "GAVINA\u5728\u6700\u6fc0\u8fdb\u914d\u7f6e\u4e0b\u80fd\u6548\u8fbe89 TOP/sW\uff1b\u901a\u8fc7\u8bef\u5dee\u5efa\u6a21\u8868\u660e\uff0cGAV\u53ef\u5728ResNet-18\u4e0a\u5b9e\u73b020%\u7684\u80fd\u6548\u63d0\u5347\uff0c\u540c\u65f6\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u3002", "conclusion": "GAV\u901a\u8fc7\u667a\u80fd\u9009\u62e9\u6b20\u538b\u4f4d\u7ec4\u5408\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u80fd\u6548\uff0c\u4e3a\u4f4e\u529f\u8017DNN\u52a0\u901f\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.22118", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.22118", "abs": "https://arxiv.org/abs/2511.22118", "authors": ["Yihan Dai", "Dimitrios Stamatios Bouras", "Haoxiang Jia", "Sergey Mechtaev"], "title": "Statistical Independence Aware Caching for LLM Workflows", "comment": null, "summary": "Large language models (LLMs) inference is both expensive and slow. Local caching of responses offers a practical solution to reduce the cost and latency of LLM queries. In research contexts, caching also enhances reproducibility and provides flexibility for experimentation. However, naive reuse of cached responses compromises statistical independence, a critical property for probabilistic workflows. In applications of LLM for code, it underpins performance metrics such as Pass@k and uncertainty estimation, as well as algorithms like program repair loops and retries. Existing LLM caching systems lack ways to enforce statistical independence constraints. To address this, we introduce Mnimi, a cache design pattern that supports modular LLM workflows while ensuring statistical integrity at the component level. Its core innovation lies in encapsulating statistical constraints within the type of LLM references, allowing users to manage and transform these types according to the scope and requirements of their algorithm. We implemented this design pattern in Python using a combination of decorators and iterators over infinite sequences. A case study on SpecFix, an recent automated program specification repair system, highlights how Mnimi improves reproducibility, ease of debugging, time and cost efficiency while preserving statistical correctness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMnimi\uff0c\u4e00\u79cd\u65b0\u578b\u7f13\u5b58\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5728\u652f\u6301\u6a21\u5757\u5316\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5de5\u4f5c\u6d41\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5728LLM\u5f15\u7528\u7c7b\u578b\u4e2d\u5c01\u88c5\u7edf\u8ba1\u72ec\u7acb\u6027\u7ea6\u675f\uff0c\u786e\u4fdd\u7ec4\u4ef6\u7ea7\u522b\u7684\u7edf\u8ba1\u5b8c\u6574\u6027\uff0c\u4ece\u800c\u517c\u987e\u6548\u7387\u3001\u53ef\u590d\u73b0\u6027\u4e0e\u7edf\u8ba1\u6b63\u786e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6210\u672c\u9ad8\u3001\u901f\u5ea6\u6162\uff0c\u672c\u5730\u7f13\u5b58\u867d\u80fd\u964d\u4f4e\u6210\u672c\u548c\u5ef6\u8fdf\u5e76\u63d0\u5347\u53ef\u590d\u73b0\u6027\uff0c\u4f46\u7b80\u5355\u590d\u7528\u7f13\u5b58\u4f1a\u7834\u574f\u6982\u7387\u6027\u5de5\u4f5c\u6d41\u6240\u9700\u7684\u7edf\u8ba1\u72ec\u7acb\u6027\uff0c\u800c\u73b0\u6709\u7f13\u5b58\u7cfb\u7edf\u65e0\u6cd5\u4fdd\u969c\u8fd9\u4e00\u5173\u952e\u5c5e\u6027\u3002", "method": "\u63d0\u51faMnimi\u7f13\u5b58\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5c06\u7edf\u8ba1\u7ea6\u675f\u5c01\u88c5\u5728LLM\u5f15\u7528\u7684\u7c7b\u578b\u4e2d\uff0c\u7528\u6237\u53ef\u6839\u636e\u7b97\u6cd5\u8303\u56f4\u548c\u9700\u6c42\u7ba1\u7406\u4e0e\u8f6c\u6362\u8fd9\u4e9b\u7c7b\u578b\uff1b\u4f7f\u7528Python\u7ed3\u5408\u88c5\u9970\u5668\u548c\u65e0\u9650\u5e8f\u5217\u8fed\u4ee3\u5668\u5b9e\u73b0\u8be5\u6a21\u5f0f\u3002", "result": "\u5728SpecFix\uff08\u81ea\u52a8\u7a0b\u5e8f\u89c4\u8303\u4fee\u590d\u7cfb\u7edf\uff09\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cMnimi\u5728\u4fdd\u6301\u7edf\u8ba1\u6b63\u786e\u6027\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u53ef\u590d\u73b0\u6027\u3001\u8c03\u8bd5\u4fbf\u5229\u6027\u4ee5\u53ca\u65f6\u95f4\u548c\u6210\u672c\u6548\u7387\u3002", "conclusion": "Mnimi\u6709\u6548\u89e3\u51b3\u4e86LLM\u7f13\u5b58\u4e2d\u7edf\u8ba1\u72ec\u7acb\u6027\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u4e3a\u6a21\u5757\u5316LLM\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u4e00\u79cd\u517c\u987e\u6548\u7387\u4e0e\u7edf\u8ba1\u5b8c\u6574\u6027\u7684\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2511.23278", "categories": ["cs.NI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.23278", "abs": "https://arxiv.org/abs/2511.23278", "authors": ["Jhonatan Tavori", "Anat Bremler-Barr", "Hanoch Levy", "Ofek Lavi"], "title": "RetryGuard: Preventing Self-Inflicted Retry Storms in Cloud Microservices Applications", "comment": null, "summary": "Modern cloud applications are built on independent, diverse microservices, offering scalability, flexibility, and usage-based billing. However, the structural design of these varied services, along with their reliance on auto-scalers for dynamic internet traffic, introduces significant coordination challenges. As we demonstrate in this paper, common default retry patterns used between misaligned services can turn into retry storms which drive up resource usage and costs, leading to self-inflicted Denial-of-Wallet (DoW) scenarios. To overcome these problems we introduce RetryGuard, a distributed framework for productive control of retry patterns across interdependent microservices. By managing retry policy on a per-service basis and making parallel decisions, RetryGuard prevents retry storms, curbs resource contention, and mitigates escalating operational costs. RetryGuard makes its decisions based on an analytic model that captures the relationships among retries, throughput (rejections), delays, and costs. Experimental results show that RetryGuard significantly reduces resource usage and costs compared to AWS standard and advanced retry policies. We further demonstrate its scalability and superior performance in a more complex Kubernetes deployment with the Istio service mesh, where it achieves substantial improvements.", "AI": {"tldr": "RetryGuard \u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u6846\u67b6\uff0c\u7528\u4e8e\u63a7\u5236\u5fae\u670d\u52a1\u95f4\u7684\u91cd\u8bd5\u884c\u4e3a\uff0c\u6709\u6548\u9632\u6b62\u91cd\u8bd5\u98ce\u66b4\u3001\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u4e0e\u8fd0\u8425\u6210\u672c\u3002", "motivation": "\u73b0\u4ee3\u4e91\u5e94\u7528\u4e2d\u5fae\u670d\u52a1\u67b6\u6784\u548c\u81ea\u52a8\u6269\u7f29\u5bb9\u673a\u5236\u5bfc\u81f4\u670d\u52a1\u95f4\u534f\u8c03\u56f0\u96be\uff0c\u4e0d\u5f53\u7684\u91cd\u8bd5\u7b56\u7565\u6613\u5f15\u53d1\u91cd\u8bd5\u98ce\u66b4\uff0c\u9020\u6210\u8d44\u6e90\u6d6a\u8d39\u548c\u201c\u94b1\u5305\u62d2\u7edd\u201d\uff08Denial-of-Wallet\uff09\u95ee\u9898\u3002", "method": "\u63d0\u51fa RetryGuard \u6846\u67b6\uff0c\u57fa\u4e8e\u5206\u6790\u6a21\u578b\u5bf9\u6bcf\u4e2a\u670d\u52a1\u72ec\u7acb\u7ba1\u7406\u91cd\u8bd5\u7b56\u7565\uff0c\u5e76\u884c\u51b3\u7b56\u4ee5\u63a7\u5236\u91cd\u8bd5\u884c\u4e3a\uff0c\u7efc\u5408\u8003\u8651\u91cd\u8bd5\u3001\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRetryGuard \u76f8\u8f83\u4e8e AWS \u9ed8\u8ba4\u548c\u9ad8\u7ea7\u91cd\u8bd5\u7b56\u7565\u663e\u8457\u964d\u4f4e\u8d44\u6e90\u4f7f\u7528\u548c\u6210\u672c\uff0c\u5e76\u5728 Kubernetes \u4e0e Istio \u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u53ef\u6269\u5c55\u6027\u4e0e\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "RetryGuard \u80fd\u6709\u6548\u7f13\u89e3\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u7684\u91cd\u8bd5\u98ce\u66b4\u95ee\u9898\uff0c\u63d0\u5347\u7cfb\u7edf\u7a33\u5b9a\u6027\u5e76\u63a7\u5236\u8fd0\u8425\u5f00\u9500\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4e91\u539f\u751f\u73af\u5883\u3002"}}
{"id": "2511.22880", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22880", "abs": "https://arxiv.org/abs/2511.22880", "authors": ["Shashwat Jaiswal", "Shrikara Arun", "Anjaly Parayil", "Ankur Mallick", "Spyros Mastorakis", "Alind Khare", "Chloi Alverti", "Renee St Amant", "Chetan Bansal", "Victor R\u00fchle", "Josep Torrellas"], "title": "Serving Heterogeneous LoRA Adapters in Distributed LLM Inference Systems", "comment": null, "summary": "Low-Rank Adaptation (LoRA) has become the de facto method for parameter-efficient fine-tuning of large language models (LLMs), enabling rapid adaptation to diverse domains. In production, LoRA-based models are served at scale, creating multi-tenant environments with hundreds of adapters sharing a base model. However, state-of-the-art serving systems co-batch heterogeneous adapters without accounting for rank (size) variability, leading to severe performance skew, which ultimately requires adding more GPUs to satisfy service-level objectives (SLOs). Existing optimizations, focused on loading, caching, and kernel execution, ignore this heterogeneity, leaving GPU resources underutilized. We present LoRAServe, a workload-aware dynamic adapter placement and routing framework designed to tame rank diversity in LoRA serving. By dynamically rebalancing adapters across GPUs and leveraging GPU Direct RDMA for remote access, LoRAServe maximizes throughput and minimizes tail latency under real-world workload drift. Evaluations on production traces from Company X show that LoRAServe elicits up to 2$\\times$ higher throughput, up to 9$\\times$ lower TTFT, while using up to 50% fewer GPUs under SLO constraints compared to state-of-the-art systems.", "AI": {"tldr": "LoRAServe \u662f\u4e00\u79cd\u9762\u5411 LoRA \u670d\u52a1\u7684\u52a8\u6001\u9002\u914d\u5668\u653e\u7f6e\u4e0e\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u611f\u77e5\u5de5\u4f5c\u8d1f\u8f7d\u5e76\u5229\u7528 GPU Direct RDMA \u6280\u672f\uff0c\u5728\u771f\u5b9e\u751f\u4ea7\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u3001\u964d\u4f4e\u9996 Token \u5ef6\u8fdf\uff0c\u5e76\u51cf\u5c11\u6240\u9700 GPU \u6570\u91cf\u3002", "motivation": "\u73b0\u6709 LoRA \u670d\u52a1\u7cfb\u7edf\u5728\u591a\u79df\u6237\u73af\u5883\u4e0b\u5bf9\u4e0d\u540c\u79e9\uff08rank\uff09\u7684\u9002\u914d\u5668\u8fdb\u884c\u5171\u6279\u5904\u7406\u65f6\u672a\u8003\u8651\u5176\u5927\u5c0f\u5dee\u5f02\uff0c\u5bfc\u81f4\u6027\u80fd\u4e25\u91cd\u4e0d\u5747\u8861\uff0cGPU \u8d44\u6e90\u5229\u7528\u7387\u4f4e\uff0c\u96be\u4ee5\u6ee1\u8db3\u670d\u52a1\u7b49\u7ea7\u76ee\u6807\uff08SLO\uff09\uff0c\u9700\u989d\u5916\u589e\u52a0 GPU\u3002", "method": "\u63d0\u51fa LoRAServe \u6846\u67b6\uff0c\u91c7\u7528\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u7684\u52a8\u6001\u9002\u914d\u5668\u653e\u7f6e\u7b56\u7565\uff0c\u5e76\u7ed3\u5408 GPU Direct RDMA \u5b9e\u73b0\u8fdc\u7a0b\u8bbf\u95ee\uff0c\u4ee5\u5e94\u5bf9 LoRA \u9002\u914d\u5668\u79e9\u591a\u6837\u6027\u5e26\u6765\u7684\u6311\u6218\u3002", "result": "\u5728 Company X \u7684\u771f\u5b9e\u751f\u4ea7\u8f68\u8ff9\u8bc4\u4f30\u4e2d\uff0cLoRAServe \u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7cfb\u7edf\uff0c\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u5347 2 \u500d\uff0c\u9996 Token \u5ef6\u8fdf\uff08TTFT\uff09\u6700\u591a\u964d\u4f4e 9 \u500d\uff0c\u5e76\u5728\u6ee1\u8db3 SLO \u7684\u524d\u63d0\u4e0b\u6700\u591a\u8282\u7701 50% \u7684 GPU \u8d44\u6e90\u3002", "conclusion": "LoRAServe \u6709\u6548\u89e3\u51b3\u4e86 LoRA \u591a\u79df\u6237\u670d\u52a1\u4e2d\u56e0\u9002\u914d\u5668\u79e9\u5f02\u6784\u5bfc\u81f4\u7684\u8d44\u6e90\u5229\u7528\u4e0d\u5747\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.22186", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.22186", "abs": "https://arxiv.org/abs/2511.22186", "authors": ["Chayanid Termphaiboon", "Raula Gaikovina Kula", "Youmei Fan", "Morakot Choetkiertikul", "Chaiyong Ragkhitwetsagul", "Thanwadee Sunetnanta", "Kenichi Matsumoto"], "title": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem", "comment": "8 pages, 5 figures, accepted to ISE 2025 (International Workshop on Intelligent Software Engineering)", "summary": "Security policies, such as SECURITY.md files, are now common in open-source projects. They help guide responsible vulnerability reporting and build trust among users and contributors. Despite their growing use, it is still unclear how these policies influence the structure and evolution of software dependencies. Software dependencies are external packages or libraries that a project relies on, and their interconnected nature affects both functionality and security. This study explores the relationship between security policies and dependency management in PyPI projects. We analyzed projects with and without a SECURITY.md file by examining their dependency trees and tracking how dependencies change over time. The analysis shows that projects with a security policy tend to rely on a broader set of direct dependencies, while overall depth and transitive dependencies remain similar. Historically, projects created after the introduction of SECURITY.md, particularly later adopters, show more frequent dependency updates. These results suggest that security policies are linked to more modular and feature-rich projects, and highlight the role of SECURITY.md in promoting proactive dependency management and reducing risks in the software supply chain.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\uff0c\u62e5\u6709 SECURITY.md \u5b89\u5168\u7b56\u7565\u7684 PyPI \u9879\u76ee\u503e\u5411\u4e8e\u4f7f\u7528\u66f4\u591a\u76f4\u63a5\u4f9d\u8d56\u9879\uff0c\u5e76\u66f4\u9891\u7e41\u5730\u66f4\u65b0\u4f9d\u8d56\uff0c\u8868\u660e\u5b89\u5168\u7b56\u7565\u4e0e\u66f4\u6a21\u5757\u5316\u3001\u529f\u80fd\u4e30\u5bcc\u7684\u9879\u76ee\u76f8\u5173\uff0c\u5e76\u6709\u52a9\u4e8e\u63d0\u5347\u4f9d\u8d56\u7ba1\u7406\u7684\u4e3b\u52a8\u6027\u3002", "motivation": "\u5c3d\u7ba1 SECURITY.md \u7b49\u5b89\u5168\u7b56\u7565\u5728\u5f00\u6e90\u9879\u76ee\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5176\u5bf9\u8f6f\u4ef6\u4f9d\u8d56\u7ed3\u6784\u548c\u6f14\u5316\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5b89\u5168\u7b56\u7565\u4e0e\u4f9d\u8d56\u7ba1\u7406\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u5305\u542b\u4e0e\u4e0d\u5305\u542b SECURITY.md \u6587\u4ef6\u7684 PyPI \u9879\u76ee\uff0c\u8003\u5bdf\u5176\u4f9d\u8d56\u6811\u7ed3\u6784\u53ca\u968f\u65f6\u95f4\u53d8\u5316\u7684\u4f9d\u8d56\u66f4\u65b0\u884c\u4e3a\u3002", "result": "\u62e5\u6709\u5b89\u5168\u7b56\u7565\u7684\u9879\u76ee\u901a\u5e38\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u76f4\u63a5\u4f9d\u8d56\uff0c\u4f46\u6574\u4f53\u4f9d\u8d56\u6df1\u5ea6\u548c\u4f20\u9012\u4f9d\u8d56\u76f8\u4f3c\uff1b\u7279\u522b\u662f\u540e\u671f\u91c7\u7528 SECURITY.md \u7684\u9879\u76ee\u8868\u73b0\u51fa\u66f4\u9891\u7e41\u7684\u4f9d\u8d56\u66f4\u65b0\u3002", "conclusion": "SECURITY.md \u4e0e\u66f4\u6a21\u5757\u5316\u3001\u529f\u80fd\u4e30\u5bcc\u7684\u9879\u76ee\u76f8\u5173\uff0c\u5e76\u5728\u4fc3\u8fdb\u4e3b\u52a8\u4f9d\u8d56\u7ba1\u7406\u3001\u964d\u4f4e\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u98ce\u9669\u65b9\u9762\u53d1\u6325\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2511.22409", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.22409", "abs": "https://arxiv.org/abs/2511.22409", "authors": ["Polydoros Giannouris", "Sophia Ananiadou"], "title": "NOMAD: A Multi-Agent LLM System for UML Class Diagram Generation from Natural Language Requirements", "comment": null, "summary": "Large Language Models (LLMs) are increasingly utilised in software engineering, yet their ability to generate structured artefacts such as UML diagrams remains underexplored. In this work we present NOMAD, a cognitively inspired, modular multi-agent framework that decomposes UML generation into a series of role-specialised subtasks. Each agent handles a distinct modelling activity, such as entity extraction, relationship classification, and diagram synthesis, mirroring the goal-directed reasoning processes of an engineer. This decomposition improves interpretability and allows for targeted verification strategies. We evaluate NOMAD through a mixed design: a large case study (Northwind) for in-depth probing and error analysis, and human-authored UML exercises for breadth and realism. NOMAD outperforms all selected baselines, while revealing persistent challenges in fine-grained attribute extraction. Building on these observations, we introduce the first systematic taxonomy of errors in LLM-generated UML diagrams, categorising structural, relationship, and semantic/logical. Finally, we examine verification as a design probe, showing its mixed effects and outlining adaptive strategies as promising directions. Together, these contributions position NOMAD as both an effective framework for UML class diagram generation and a lens onto the broader research challenges of reliable language-to-model workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NOMAD\uff0c\u4e00\u4e2a\u53d7\u8ba4\u77e5\u542f\u53d1\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210UML\u7c7b\u56fe\u3002\u8be5\u6846\u67b6\u5c06\u5efa\u6a21\u4efb\u52a1\u5206\u89e3\u4e3a\u591a\u4e2a\u4e13\u4e1a\u5316\u5b50\u4efb\u52a1\uff0c\u63d0\u5347\u4e86\u53ef\u89e3\u91ca\u6027\u4e0e\u9a8c\u8bc1\u80fd\u529b\uff0c\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5bf9LLM\u751f\u6210UML\u4e2d\u7684\u9519\u8bef\u8fdb\u884c\u4e86\u5206\u7c7b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u751f\u6210\u5982UML\u56fe\u7b49\u7ed3\u6784\u5316\u5236\u54c1\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u5efa\u6a21\u8fc7\u7a0b\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u9a8c\u8bc1\u673a\u5236\u3002", "method": "\u63d0\u51faNOMAD\u6846\u67b6\uff0c\u91c7\u7528\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06UML\u751f\u6210\u5206\u89e3\u4e3a\u5b9e\u4f53\u63d0\u53d6\u3001\u5173\u7cfb\u5206\u7c7b\u548c\u56fe\u8868\u5408\u6210\u7b49\u89d2\u8272\u4e13\u7528\u7684\u5b50\u4efb\u52a1\uff0c\u6a21\u62df\u5de5\u7a0b\u5e08\u7684\u76ee\u6807\u5bfc\u5411\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u7ed3\u5408\u9488\u5bf9\u6027\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "\u5728Northwind\u6848\u4f8b\u548c\u4eba\u5de5\u7f16\u5199\u7684UML\u7ec3\u4e60\u4e0a\u8bc4\u4f30\u8868\u660e\uff0cNOMAD\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\uff1b\u540c\u65f6\u63ed\u793a\u4e86\u5c5e\u6027\u63d0\u53d6\u7b49\u7ec6\u7c92\u5ea6\u4efb\u52a1\u7684\u6301\u7eed\u6311\u6218\uff0c\u5e76\u6784\u5efa\u4e86\u9996\u4e2aLLM\u751f\u6210UML\u9519\u8bef\u7684\u7cfb\u7edf\u5206\u7c7b\u4f53\u7cfb\u3002", "conclusion": "NOMAD\u4e0d\u4ec5\u662f\u4e00\u4e2a\u9ad8\u6548\u7684UML\u7c7b\u56fe\u751f\u6210\u6846\u67b6\uff0c\u4e5f\u4e3a\u8bed\u8a00\u5230\u6a21\u578b\u8f6c\u6362\u6d41\u7a0b\u4e2d\u7684\u53ef\u9760\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u9a8c\u8bc1\u673a\u5236\u867d\u6548\u679c\u4e0d\u4e00\uff0c\u4f46\u81ea\u9002\u5e94\u7b56\u7565\u5c55\u73b0\u51fa\u6f5c\u529b\u3002"}}
{"id": "2511.22513", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.22513", "abs": "https://arxiv.org/abs/2511.22513", "authors": ["J\u00e9r\u00f4me Pfeiffer", "Nicolai Maisch", "Sebastian Friedl", "Matthias Milan Strljic", "Armin Lechler", "Oliver Riedel", "Andreas Wortmann"], "title": "Declarative Policy Control for Data Spaces: A DSL-Based Approach for Manufacturing-X", "comment": null, "summary": "The growing adoption of federated data spaces, such as in the GAIA-X and the International Data Spaces (IDS) initiative, promises secure and sovereign data sharing across organizational boundaries in Industry 4.0. In manufacturing ecosystems, this enables use cases, such as cross-factory process optimization, predictive maintenance, and supplier integration. Frameworks and standards, such as the Asset Administration Shell (AAS), Eclipse Dataspace Connector (EDC), ID-Link and Open Platform Communications Unified Architecture (OPC UA) provide a strong foundation to realize this ecosystem. However, a major open challenge is the practical description and enforcement of context-dependent data usage policies using these base technologies - especially by domain experts without software engineering backgrounds. Therefore, this article proposes a method for leveraging domain-specific languages (DSLs) to enable declarative, human-readable, and machine-executable policy definitions for sovereign data sharing via data space connectors. The DSL empowers domain experts to specify fine-grained data governance requirements - such as restricting access to data from specific production batches or enforcing automatic deletion after a defined retention period - without writing imperative code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u7684\u65b9\u6cd5\uff0c\u4f7f\u975e\u7f16\u7a0b\u80cc\u666f\u7684\u9886\u57df\u4e13\u5bb6\u80fd\u591f\u4ee5\u58f0\u660e\u5f0f\u3001\u53ef\u8bfb\u4e14\u53ef\u6267\u884c\u7684\u65b9\u5f0f\u5b9a\u4e49\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u4f7f\u7528\u7b56\u7565\uff0c\u7528\u4e8e\u8054\u90a6\u6570\u636e\u7a7a\u95f4\u4e2d\u7684\u4e3b\u6743\u6570\u636e\u5171\u4eab\u3002", "motivation": "\u5728\u5de5\u4e1a4.0\u80cc\u666f\u4e0b\uff0c\u5c3d\u7ba1\u5df2\u6709\u5982AAS\u3001EDC\u3001ID-Link\u548cOPC UA\u7b49\u6280\u672f\u6846\u67b6\u652f\u6301\u8de8\u7ec4\u7ec7\u7684\u5b89\u5168\u6570\u636e\u5171\u4eab\uff0c\u4f46\u5982\u4f55\u8ba9\u975e\u8f6f\u4ef6\u5de5\u7a0b\u80cc\u666f\u7684\u9886\u57df\u4e13\u5bb6\u6709\u6548\u63cf\u8ff0\u548c\u5b9e\u65bd\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6570\u636e\u4f7f\u7528\u7b56\u7565\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\uff0c\u652f\u6301\u58f0\u660e\u5f0f\u3001\u4eba\u7c7b\u53ef\u8bfb\u4e14\u673a\u5668\u53ef\u6267\u884c\u7684\u7b56\u7565\u5b9a\u4e49\uff0c\u4f7f\u9886\u57df\u4e13\u5bb6\u65e0\u9700\u7f16\u5199\u547d\u4ee4\u5f0f\u4ee3\u7801\u5373\u53ef\u8bbe\u5b9a\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u6cbb\u7406\u89c4\u5219\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u9886\u57df\u4e13\u5bb6\u80fd\u591f\u76f4\u63a5\u6307\u5b9a\u5982\u201c\u4ec5\u9650\u7279\u5b9a\u751f\u4ea7\u6279\u6b21\u7684\u6570\u636e\u8bbf\u95ee\u201d\u6216\u201c\u5728\u4fdd\u7559\u671f\u540e\u81ea\u52a8\u5220\u9664\u6570\u636e\u201d\u7b49\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u6570\u636e\u6cbb\u7406\u7684\u53ef\u7528\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u3002", "conclusion": "\u901a\u8fc7DSL\u8d4b\u80fd\u9886\u57df\u4e13\u5bb6\u53c2\u4e0e\u6570\u636e\u7b56\u7565\u5236\u5b9a\uff0c\u6709\u6548\u5f25\u5408\u4e86\u6280\u672f\u5b9e\u73b0\u4e0e\u4e1a\u52a1\u9700\u6c42\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u8054\u90a6\u6570\u636e\u7a7a\u95f4\u4e2d\u7684\u4e3b\u6743\u6570\u636e\u5171\u4eab\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.22726", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.22726", "abs": "https://arxiv.org/abs/2511.22726", "authors": ["Ethan Friesen", "Sasha Morton-Salmon", "Md Nahidul Islam Opu", "Shahidul Islam", "Shaiful Chowdhury"], "title": "The Repeat Offenders: Characterizing and Predicting Extremely Bug-Prone Source Methods", "comment": null, "summary": "Identifying the small subset of source code that repeatedly attracts bugs is critical for reducing long-term maintenance effort. We define ExtremelyBuggy methods as those involved in more than one bug fix and present the first large-scale study of their prevalence, characteristics, and predictability. Using a dataset of over 1.25 million methods from 98 open-source Java projects, we find that ExtremelyBuggy methods constitute only a tiny fraction of all methods, yet frequently account for a disproportionately large share of bugs. At their inception, these methods are significantly larger, more complex, less readable, and less maintainable than both singly-buggy and non-buggy methods. However, despite these measurable differences, a comprehensive evaluation of five machine learning models shows that early prediction of ExtremelyBuggy methods remains highly unreliable due to data imbalance, project heterogeneity, and the fact that many bugs emerge through subsequent evolution rather than initial implementation. To complement these quantitative findings, we conduct a thematic analysis of 265 ExtremelyBuggy methods, revealing recurring visual issues (e.g., confusing control flow, poor readability), contextual roles (e.g., core logic, data transformation, external resource handling), and common defect patterns (e.g., faulty conditionals, fragile error handling, misuse of variables). These results highlight the need for richer, evolution-aware representations of code and provide actionable insights for practitioners seeking to prioritize high-risk methods early in the development lifecycle.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf998\u4e2a\u5f00\u6e90Java\u9879\u76ee\u4e2d\u8d85\u8fc7125\u4e07\u65b9\u6cd5\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u53d1\u73b0\u201c\u6781\u7f3a\u9677\u65b9\u6cd5\u201d\uff08ExtremelyBuggy methods\uff09\u867d\u5360\u6bd4\u6781\u5c0f\uff0c\u5374\u96c6\u4e2d\u4e86\u5927\u91cf\u7f3a\u9677\uff1b\u8fd9\u4e9b\u65b9\u6cd5\u5728\u521d\u59cb\u9636\u6bb5\u5c31\u8868\u73b0\u51fa\u66f4\u5927\u3001\u66f4\u590d\u6742\u3001\u53ef\u8bfb\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u66f4\u5dee\u7b49\u7279\u5f81\uff0c\u4f46\u56e0\u6570\u636e\u4e0d\u5e73\u8861\u3001\u9879\u76ee\u5f02\u8d28\u6027\u53ca\u7f3a\u9677\u591a\u5728\u6f14\u5316\u4e2d\u4ea7\u751f\u7b49\u539f\u56e0\uff0c\u65e9\u671f\u9884\u6d4b\u4ecd\u4e0d\u53ef\u9760\u3002\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u63ed\u793a\u4e86\u5176\u5e38\u89c1\u89c6\u89c9\u95ee\u9898\u3001\u4e0a\u4e0b\u6587\u89d2\u8272\u548c\u7f3a\u9677\u6a21\u5f0f\uff0c\u4e3a\u9ad8\u98ce\u9669\u65b9\u6cd5\u7684\u65e9\u671f\u8bc6\u522b\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u3002", "motivation": "\u8bc6\u522b\u53cd\u590d\u5f15\u53d1\u7f3a\u9677\u7684\u5c11\u91cf\u6e90\u4ee3\u7801\u5b50\u96c6\u5bf9\u4e8e\u964d\u4f4e\u957f\u671f\u7ef4\u62a4\u6210\u672c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u8fd9\u7c7b\u201c\u6781\u7f3a\u9677\u65b9\u6cd5\u201d\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u4e0e\u6709\u6548\u9884\u6d4b\u624b\u6bb5\u3002", "method": "\u7ed3\u5408\u5927\u89c4\u6a21\u5b9a\u91cf\u5206\u6790\uff08\u57fa\u4e8e1.25M+\u65b9\u6cd5\u7684\u6570\u636e\u96c6\u4e0e5\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff09\u4e0e\u5b9a\u6027\u4e3b\u9898\u5206\u6790\uff08\u5bf9265\u4e2a\u6781\u7f3a\u9677\u65b9\u6cd5\u8fdb\u884c\u4eba\u5de5\u7f16\u7801\uff09\uff0c\u4ece\u4ee3\u7801\u7279\u5f81\u3001\u53ef\u9884\u6d4b\u6027\u53ca\u6f14\u5316\u89d2\u5ea6\u5c55\u5f00\u7814\u7a76\u3002", "result": "\u6781\u7f3a\u9677\u65b9\u6cd5\u5360\u6bd4\u6781\u5c0f\u4f46\u7f3a\u9677\u96c6\u4e2d\uff1b\u521d\u59cb\u5373\u5177\u66f4\u9ad8\u590d\u6742\u5ea6\u4e0e\u66f4\u4f4e\u8d28\u91cf\uff1b\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u53ef\u9760\u9884\u6d4b\uff1b\u4e3b\u9898\u5206\u6790\u63ed\u793a\u4e86\u4e09\u7c7b\u5171\u6027\uff1a\u89c6\u89c9\u6df7\u4e71\u3001\u6838\u5fc3\u529f\u80fd\u89d2\u8272\u3001\u5178\u578b\u7f3a\u9677\u6a21\u5f0f\u3002", "conclusion": "\u6781\u7f3a\u9677\u65b9\u6cd5\u5177\u6709\u663e\u8457\u65e9\u671f\u7279\u5f81\u4f46\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\uff0c\u9700\u53d1\u5c55\u878d\u5408\u6f14\u5316\u4fe1\u606f\u7684\u4ee3\u7801\u8868\u5f81\u65b9\u6cd5\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u4f18\u5148\u5ba1\u67e5\u9ad8\u98ce\u9669\u4ee3\u7801\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u4e0e\u5b9e\u7528\u6d1e\u89c1\u3002"}}
{"id": "2511.22921", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.22921", "abs": "https://arxiv.org/abs/2511.22921", "authors": ["Hengyuan Liu", "Xia Song", "Yong Liu", "Zheng Li"], "title": "MBFL-DKMR: Improving Mutation-based Fault Localization through Denoising-based Kill Matrix Refinement", "comment": null, "summary": "Software debugging is a critical and time-consuming aspect of software development, with fault localization being a fundamental step that significantly impacts debugging efficiency. Mutation-Based Fault Localization (MBFL) has gained prominence due to its robust theoretical foundations and fine-grained analysis capabilities. However, recent studies have identified a critical challenge: noise phenomena, specifically the false kill relationships between mutants and tests, which significantly degrade localization effectiveness. While several approaches have been proposed to rectify the final localization results, they do not directly address the underlying noise. In this paper, we propose a novel approach to refine the kill matrix, a core data structure capturing mutant-test relationships in MBFL, by treating it as a signal that contains both meaningful fault-related patterns and high-frequency noise. Inspired by signal processing theory, we introduce DKMR (Denoising-based Kill Matrix Refinement), which employs two key stages: (1) signal enhancement through hybrid matrix construction to improve the signal-to-noise ratio for better denoising, and (2) signal denoising via frequency domain filtering to suppress noise while preserving fault-related patterns. Building on this foundation, we develop MBFL-DKMR, a fault localization framework that utilizes the refined matrix with fuzzy values for suspiciousness calculation. Our evaluation on Defects4J v2.0.0 demonstrates that MBFL-DKMR effectively mitigates the noise and outperforms the state-of-the-art MBFL techniques. Specifically, MBFL-DKMR achieves 129 faults localized at Top-1 compared to 85 for BLMu and 103 for Delta4Ms, with negligible additional computational overhead (0.11 seconds, 0.001\\% of total time). This work highlights the potential of signal processing techniques to enhance the effectiveness of MBFL by refining the kill matrix.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u53f7\u53bb\u566a\u601d\u60f3\u7684\u65b0\u65b9\u6cd5DKMR\uff0c\u7528\u4e8e\u4f18\u5316\u53d8\u5f02\u4f53-\u6d4b\u8bd5\u5173\u7cfb\u77e9\u9635\uff08kill matrix\uff09\uff0c\u4ece\u800c\u63d0\u5347\u57fa\u4e8e\u53d8\u5f02\u7684\u6545\u969c\u5b9a\u4f4d\uff08MBFL\uff09\u7684\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Defects4J\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\u3002", "motivation": "\u73b0\u6709MBFL\u65b9\u6cd5\u53d7\u5230\u201c\u566a\u58f0\u201d\uff08\u5373\u9519\u8bef\u7684\u53d8\u5f02\u4f53-\u6d4b\u8bd5\u6740\u6b7b\u5173\u7cfb\uff09\u7684\u4e25\u91cd\u5f71\u54cd\uff0c\u800c\u5f53\u524d\u7684\u6539\u8fdb\u7b56\u7565\u4ec5\u4fee\u6b63\u6700\u7ec8\u5b9a\u4f4d\u7ed3\u679c\uff0c\u672a\u4ece\u6839\u6e90\u4e0a\u5904\u7406\u566a\u58f0\u95ee\u9898\u3002", "method": "\u5c06kill matrix\u89c6\u4e3a\u5305\u542b\u6545\u969c\u76f8\u5173\u4fe1\u53f7\u548c\u9ad8\u9891\u566a\u58f0\u7684\u6df7\u5408\u4fe1\u53f7\uff0c\u63d0\u51faDKMR\u6846\u67b6\uff1a\u9996\u5148\u901a\u8fc7\u6df7\u5408\u77e9\u9635\u6784\u5efa\u589e\u5f3a\u4fe1\u53f7\uff0c\u7136\u540e\u5728\u9891\u57df\u8fdb\u884c\u6ee4\u6ce2\u53bb\u566a\uff0c\u6700\u540e\u5229\u7528\u53bb\u566a\u540e\u7684\u6a21\u7cca\u503c\u77e9\u9635\u8fdb\u884c\u53ef\u7591\u5ea6\u8ba1\u7b97\u3002", "result": "\u5728Defects4J v2.0.0\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cMBFL-DKMR\u5728Top-1\u5b9a\u4f4d\u4e86129\u4e2a\u6545\u969c\uff0c\u4f18\u4e8eBLMu\uff0885\u4e2a\uff09\u548cDelta4Ms\uff08103\u4e2a\uff09\uff0c\u4e14\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u4ec5\u4e3a0.11\u79d2\u3002", "conclusion": "\u5c06\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u53bb\u566a\u601d\u60f3\u5e94\u7528\u4e8ekill matrix\u7684\u4f18\u5316\uff0c\u80fd\u6709\u6548\u63d0\u5347MBFL\u7684\u5b9a\u4f4d\u6548\u679c\uff0c\u4e3a\u8f6f\u4ef6\u8c03\u8bd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.23050", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.23050", "abs": "https://arxiv.org/abs/2511.23050", "authors": ["Nikita Repnkiov", "Vladimir Faerman"], "title": "Software for Studying CASCADE Error Correction Protocols in Quantum Communications", "comment": "Reported in Omsk State Technical University, November 13", "summary": "This article addresses the development of quantum communication methods in the context of emerging quantum computing threats and emphasizes the importance of key reconciliation in quantum communication systems. The study focuses on the CASCADE protocol and the design of a software prototype intended for research and educational purposes. A parallel error-correction algorithm based on the actor model was implemented, improving the efficiency of key reconciliation and reducing the amount of exchanged data. Evaluation of the prototype revealed limitations, including the computational cost of message passing, complexity of error handling, and code redundancy due to iterative development. Experimental results confirmed the correct implementation of the core CASCADE algorithms and informed the design of future improvements. Proposed enhancements include redesigning the system architecture, developing interfaces for exporting intermediate data, defining the communication channel as a separate component, and expanding tools for systematic verification and comparative analysis of blind key-reconciliation methods.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u4e0b\u7684\u91cf\u5b50\u901a\u4fe1\u9700\u6c42\uff0c\u805a\u7126CASCADE\u534f\u8bae\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u7814\u7a76\u4e0e\u6559\u5b66\u7684\u8f6f\u4ef6\u539f\u578b\uff0c\u901a\u8fc7\u57fa\u4e8eActor\u6a21\u578b\u7684\u5e76\u884c\u7ea0\u9519\u7b97\u6cd5\u63d0\u5347\u4e86\u5bc6\u94a5\u534f\u8c03\u6548\u7387\uff0c\u5e76\u63d0\u51fa\u4e86\u82e5\u5e72\u67b6\u6784\u4e0e\u529f\u80fd\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u4f20\u7edf\u52a0\u5bc6\u9762\u4e34\u5a01\u80c1\uff0c\u91cf\u5b50\u901a\u4fe1\u4e2d\u7684\u5bc6\u94a5\u534f\u8c03\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff1b\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u4f18\u5316\u4e0e\u9a8c\u8bc1\u5de5\u5177\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eActor\u6a21\u578b\u7684\u5e76\u884c\u9519\u8bef\u6821\u6b63\u7b97\u6cd5\u7684CASCADE\u534f\u8bae\u8f6f\u4ef6\u539f\u578b\uff0c\u7528\u4e8e\u5bc6\u94a5\u534f\u8c03\uff0c\u5e76\u5bf9\u5176\u6027\u80fd\u548c\u5b9e\u73b0\u7ec6\u8282\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u539f\u578b\u9a8c\u8bc1\u4e86CASCADE\u6838\u5fc3\u7b97\u6cd5\u7684\u6b63\u786e\u5b9e\u73b0\uff0c\u63d0\u9ad8\u4e86\u5bc6\u94a5\u534f\u8c03\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u901a\u4fe1\u6570\u636e\u91cf\uff0c\u4f46\u4e5f\u66b4\u9732\u51fa\u6d88\u606f\u4f20\u9012\u5f00\u9500\u5927\u3001\u9519\u8bef\u5904\u7406\u590d\u6742\u548c\u4ee3\u7801\u5197\u4f59\u7b49\u95ee\u9898\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u539f\u578b\u4e3a\u5bc6\u94a5\u534f\u8c03\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u5e73\u53f0\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u805a\u7126\u4e8e\u7cfb\u7edf\u67b6\u6784\u91cd\u6784\u3001\u4e2d\u95f4\u6570\u636e\u5bfc\u51fa\u63a5\u53e3\u3001\u901a\u4fe1\u4fe1\u9053\u6a21\u5757\u5316\u53ca\u66f4\u5b8c\u5584\u7684\u9a8c\u8bc1\u4e0e\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2511.23157", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.23157", "abs": "https://arxiv.org/abs/2511.23157", "authors": ["Hana Kataoka", "Jialong Li", "Yutaka Matsuno"], "title": "Amplifiers or Equalizers? A Longitudinal Study of LLM Evolution in Software Engineering Project-Based Learning", "comment": "Accepted by ICSE-SEET (ACM/IEEE 48th International Conference on Software Engineering: Software Engineering Education and Training)", "summary": "As LLMs reshape software development, integrating LLM-augmented practices into SE education has become imperative. While existing studies explore LLMs' educational use in introductory programming or isolated SE tasks, their impact in more open-ended Project-Based Learning (PBL) remains unexplored. This paper introduces a two-year longitudinal study comparing a 2024 (using early free LLMs, $n$=48) and 2025 (using the latest paid LLMs, $n$=46) cohort. Our findings suggest the latest powerful LLMs' dual role: they act as \"equalizers,\" boosting average performance even for programming-weak students, providing opportunities for more authentic SE practices; yet also as \"amplifiers,\" dramatically widening absolute performance gaps, creating new pedagogical challenges for addressing educational inequities.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e24\u5e74\u7eb5\u5411\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u6700\u65b0\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9879\u76ee\u5f0f\u5b66\u4e60\u4e2d\u7684\u53cc\u91cd\u4f5c\u7528\uff1a\u65e2\u63d0\u5347\u6574\u4f53\u5b66\u751f\u8868\u73b0\uff08\u5c24\u5176\u662f\u7f16\u7a0b\u80fd\u529b\u8f83\u5f31\u8005\uff09\uff0c\u53c8\u52a0\u5267\u4e86\u6210\u7ee9\u5dee\u8ddd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u91cd\u5851\u8f6f\u4ef6\u5f00\u53d1\uff0c\u5c06\u5176\u6574\u5408\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u6559\u80b2\u53d8\u5f97\u8feb\u5207\uff1b\u7136\u800c\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u4e8e\u5165\u95e8\u7f16\u7a0b\u6216\u5b64\u7acb\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u5f00\u653e\u6027\u9879\u76ee\u5f0f\u5b66\u4e60\uff08PBL\uff09\u4e2dLLM\u5f71\u54cd\u7684\u63a2\u7d22\u3002", "method": "\u5f00\u5c55\u4e3a\u671f\u4e24\u5e74\u7684\u7eb5\u5411\u7814\u7a76\uff0c\u6bd4\u8f832024\u5e74\u4f7f\u7528\u65e9\u671f\u514d\u8d39LLM\uff08n=48\uff09\u4e0e2025\u5e74\u4f7f\u7528\u6700\u65b0\u4ed8\u8d39LLM\uff08n=46\uff09\u7684\u4e24\u4e2a\u5b66\u751f\u7fa4\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9879\u76ee\u5f0f\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u6700\u65b0\u5f3a\u5927\u7684LLM\u517c\u5177\u201c\u5747\u8861\u5668\u201d\u548c\u201c\u653e\u5927\u5668\u201d\u53cc\u91cd\u89d2\u8272\uff1a\u4e00\u65b9\u9762\u63d0\u5347\u6574\u4f53\u5e73\u5747\u8868\u73b0\uff0c\u4f7f\u7f16\u7a0b\u80fd\u529b\u8f83\u5f31\u7684\u5b66\u751f\u4e5f\u80fd\u53c2\u4e0e\u66f4\u771f\u5b9e\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff1b\u53e6\u4e00\u65b9\u9762\u663e\u8457\u62c9\u5927\u7edd\u5bf9\u6210\u7ee9\u5dee\u8ddd\uff0c\u5e26\u6765\u65b0\u7684\u6559\u80b2\u516c\u5e73\u6311\u6218\u3002", "conclusion": "\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u5f15\u5165\u5148\u8fdbLLM\u867d\u80fd\u4fc3\u8fdb\u5b9e\u8df5\u771f\u5b9e\u6027\u5e76\u63d0\u5347\u5f31\u52bf\u5b66\u751f\u8868\u73b0\uff0c\u4f46\u4e5f\u53ef\u80fd\u52a0\u5267\u6559\u80b2\u4e0d\u5e73\u7b49\uff0c\u9700\u8bbe\u8ba1\u76f8\u5e94\u6559\u5b66\u7b56\u7565\u4ee5\u5e94\u5bf9\u8fd9\u4e00\u53cc\u91cd\u6548\u5e94\u3002"}}
{"id": "2511.23159", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23159", "abs": "https://arxiv.org/abs/2511.23159", "authors": ["Bertrand Meyer"], "title": "AI for software engineering: from probable to provable", "comment": null, "summary": "Vibe coding, the much-touted use of AI techniques for programming, faces two overwhelming obstacles: the difficulty of specifying goals (\"prompt engineering\" is a form of requirements engineering, one of the toughest disciplines of software engineering); and the hallucination phenomenon. Programs are only useful if they are correct or very close to correct.\n  The solution? Combine the creativity of artificial intelligence with the rigor of formal specification methods and the power of formal program verification, supported by modern proof tools.", "AI": {"tldr": "Vibe coding struggles with goal specification and hallucinations; combining AI creativity with formal methods and verification offers a solution.", "motivation": "To address the challenges of vibe coding\u2014namely, the difficulty of accurately specifying programming goals and the risk of AI-generated code hallucinations that compromise correctness.", "method": "Integrate artificial intelligence with formal specification techniques and formal program verification, leveraging modern proof tools to ensure correctness.", "result": "A hybrid approach that retains AI's creativity while enforcing the rigor needed for producing correct or near-correct programs.", "conclusion": "The fusion of AI and formal methods is essential to overcome the limitations of current AI-assisted programming and achieve reliable software development."}}
{"id": "2511.23213", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.23213", "abs": "https://arxiv.org/abs/2511.23213", "authors": ["Samuele Doria", "Eleonora Losiouk"], "title": "GAPS: Guiding Dynamic Android Analysis with Static Path Synthesis", "comment": null, "summary": "Dynamically resolving method reachability in Android applications remains a critical and largely unsolved problem. Despite notable advancements in GUI testing and static call graph construction, current tools are insufficient for reliably driving execution toward specific target methods, especially those not embedded in a graphical component (e.g., libraries' methods), a capability essential for tasks such as vulnerability validation, debugging, and behavioral analysis.\n  We present GAPS (Graph-based Automated Path Synthesizer), the first system that integrates static, method-guided call graph analysis with dynamic, interaction-driven execution. GAPS performs a lightweight backward traversal of the call graph, guided by data-flow analysis, to reconstruct paths reaching the target methods. These paths are then translated into instructions that guide runtime app exploration.\n  On the AndroTest benchmark, GAPS statically identifies paths to reach 88.24\\% of the target methods in just 4.27 seconds per app and dynamically reaches 57.44\\% of them. In contrast, state-of-the-art dynamic interaction tools show significantly lower reachability over three runs: APE, one of the best model-based GUI testers, achieves 12.82\\%, while GoalExplorer, a hybrid analysis tool, reaches 9.69\\%, and Guardian, an LLM-based UI automator, reaches 17.12\\%. Static analysis tools also fall short: FlowDroid and DroidReach identify paths to reach 58.81\\% and 9.48\\% of the targets, requiring 35.06 seconds and 23.46 seconds per app, respectively.\n  Finally, an evaluation on the 50 most downloaded real-world apps demonstrates GAPS's practical utility in analyzing security-critical code under a realistic scenario. With an average static analysis time of 278.9 seconds, GAPS statically reconstructs paths to 62.03\\% of the target methods and dynamically reaches 59.86\\% of them.", "AI": {"tldr": "GAPS \u662f\u9996\u4e2a\u7ed3\u5408\u9759\u6001\u65b9\u6cd5\u5bfc\u5411\u8c03\u7528\u56fe\u5206\u6790\u4e0e\u52a8\u6001\u4ea4\u4e92\u9a71\u52a8\u6267\u884c\u7684\u7cfb\u7edf\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u5728 Android \u5e94\u7528\u4e2d\u52a8\u6001\u89e6\u8fbe\u76ee\u6807\u65b9\u6cd5\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d Android \u5e94\u7528\u4e2d\u7684\u65b9\u6cd5\u53ef\u8fbe\u6027\u95ee\u9898\u5c1a\u672a\u6709\u6548\u89e3\u51b3\uff0c\u5c24\u5176\u5bf9\u4e8e\u672a\u5d4c\u5165\u56fe\u5f62\u754c\u9762\u7684\u65b9\u6cd5\uff08\u5982\u5e93\u51fd\u6570\uff09\uff0c\u73b0\u6709 GUI \u6d4b\u8bd5\u548c\u9759\u6001\u8c03\u7528\u56fe\u6784\u5efa\u5de5\u5177\u96be\u4ee5\u53ef\u9760\u5730\u9a71\u52a8\u6267\u884c\u5230\u8fbe\u8fd9\u4e9b\u76ee\u6807\u65b9\u6cd5\uff0c\u800c\u8fd9\u5bf9\u6f0f\u6d1e\u9a8c\u8bc1\u3001\u8c03\u8bd5\u548c\u884c\u4e3a\u5206\u6790\u81f3\u5173\u91cd\u8981\u3002", "method": "GAPS \u91c7\u7528\u8f7b\u91cf\u7ea7\u7684\u3001\u7531\u6570\u636e\u6d41\u5206\u6790\u5f15\u5bfc\u7684\u8c03\u7528\u56fe\u540e\u5411\u904d\u5386\uff0c\u91cd\u6784\u901a\u5f80\u76ee\u6807\u65b9\u6cd5\u7684\u8def\u5f84\uff0c\u5e76\u5c06\u8fd9\u4e9b\u8def\u5f84\u8f6c\u5316\u4e3a\u8fd0\u884c\u65f6\u5e94\u7528\u63a2\u7d22\u7684\u6307\u4ee4\uff0c\u4ece\u800c\u5b9e\u73b0\u9759\u6001\u4e0e\u52a8\u6001\u5206\u6790\u7684\u7ed3\u5408\u3002", "result": "\u5728 AndroTest \u57fa\u51c6\u4e0a\uff0cGAPS \u9759\u6001\u8bc6\u522b 88.24% \u76ee\u6807\u65b9\u6cd5\u8def\u5f84\uff08\u5e73\u5747 4.27 \u79d2/\u5e94\u7528\uff09\uff0c\u52a8\u6001\u89e6\u8fbe 57.44%\uff1b\u8fdc\u8d85 APE\uff0812.82%\uff09\u3001GoalExplorer\uff089.69%\uff09\u548c Guardian\uff0817.12%\uff09\u7b49\u52a8\u6001\u5de5\u5177\uff0c\u4e5f\u4f18\u4e8e FlowDroid\uff0858.81%\uff09\u548c DroidReach\uff089.48%\uff09\u7b49\u9759\u6001\u5de5\u5177\u3002\u5728 50 \u4e2a\u70ed\u95e8\u771f\u5b9e\u5e94\u7528\u4e2d\uff0cGAPS \u5e73\u5747\u9759\u6001\u5206\u6790\u8017\u65f6 278.9 \u79d2\uff0c\u9759\u6001\u8986\u76d6 62.03% \u76ee\u6807\u65b9\u6cd5\uff0c\u52a8\u6001\u89e6\u8fbe 59.86%\u3002", "conclusion": "GAPS \u5728\u9759\u6001\u8def\u5f84\u91cd\u6784\u548c\u52a8\u6001\u65b9\u6cd5\u89e6\u8fbe\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5c55\u73b0\u51fa\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u5206\u6790\u5b89\u5168\u5173\u952e\u4ee3\u7801\u7684\u5f3a\u5927\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.23302", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.23302", "abs": "https://arxiv.org/abs/2511.23302", "authors": ["Hengyuan Liu", "Zheng Li", "Donghua Wang", "Yankai Wu", "Xiang Chen", "Yong Liu"], "title": "FLIMs: Fault Localization Interference Mutants, Definition, Recognition and Mitigation", "comment": null, "summary": "Mutation-based Fault Localization (MBFL) has been widely explored for automated software debugging, leveraging artificial mutants to identify faulty code entities. However, MBFL faces significant challenges due to interference mutants generated from non-faulty code entities but can be killed by failing tests. These mutants mimic the test sensitivity behaviors of real faulty code entities and weaken the effectiveness of fault localization. To address this challenge, we introduce the concept of Fault Localization Interference Mutants (FLIMs) and conduct a theoretical analysis based on the Reachability, Infection, Propagation, and Revealability (RIPR) model, identifying four distinct interference causes. Building on this, we propose a novel approach to semantically recognize and mitigate FLIMs using LLM-based semantic analysis, enhanced by fine-tuning techniques and confidence estimation strategies to address LLM output instability. The recognized FLIMs are then mitigated by refining the suspiciousness scores calculated from MBFL techniques. We integrate FLIM recognition and mitigation into the MBFL workflow, developing MBFL-FLIM, a fault localization framework that enhances MBFL's effectiveness by reducing misleading interference while preserving real fault-revealing information. Our empirical experiments on the Defects4J benchmark with 395 program versions using eight LLMs demonstrate MBFL-FLIM's superiority over traditional SBFL and MBFL methods, advanced dynamic feature-based approaches, and recent LLM-based fault localization techniques. Specifically, MBFL-FLIM achieves an average improvement of 44 faults in the Top-1 metric, representing a significant enhancement over baseline methods. Further evaluation confirms MBFL-FLIM's robust performance in multi-fault scenarios, with ablation experiments validating the contributions of the fine-tuning and confidence estimation components.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMBFL-FLIM\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u6545\u969c\u5b9a\u4f4d\u5e72\u6270\u53d8\u5f02\u4f53\uff08FLIMs\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8bed\u4e49\u5206\u6790\u8bc6\u522b\u548c\u7f13\u89e3\u8fd9\u4e9b\u5e72\u6270\u53d8\u5f02\u4f53\uff0c\u4ece\u800c\u63d0\u5347\u57fa\u4e8e\u53d8\u5f02\u7684\u6545\u969c\u5b9a\u4f4d\uff08MBFL\uff09\u7684\u6548\u679c\u3002\u5728Defects4J\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Top-1\u6307\u6807\u4e0a\u5e73\u5747\u591a\u5b9a\u4f4d44\u4e2a\u6545\u969c\uff0c\u4f18\u4e8e\u4f20\u7edfSBFL\u3001MBFL\u53ca\u5176\u4ed6\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "MBFL\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u8c03\u8bd5\u4e2d\u53d7\u5230\u5e72\u6270\u53d8\u5f02\u4f53\uff08\u5373\u975e\u6545\u969c\u4ee3\u7801\u751f\u6210\u4f46\u80fd\u88ab\u5931\u8d25\u6d4b\u8bd5\u6740\u6b7b\u7684\u53d8\u5f02\u4f53\uff09\u7684\u5f71\u54cd\uff0c\u8fd9\u4e9b\u53d8\u5f02\u4f53\u4f1a\u6a21\u4eff\u771f\u5b9e\u6545\u969c\u884c\u4e3a\uff0c\u964d\u4f4e\u5b9a\u4f4d\u7cbe\u5ea6\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u8bc6\u522b\u5e76\u7f13\u89e3\u8fd9\u7c7b\u5e72\u6270\u53d8\u5f02\u4f53\u3002", "method": "\u57fa\u4e8eRIPR\u6a21\u578b\u7406\u8bba\u5206\u6790\u5e72\u6270\u539f\u56e0\uff0c\u63d0\u51fa\u5229\u7528LLM\u8fdb\u884c\u8bed\u4e49\u5206\u6790\u4ee5\u8bc6\u522bFLIMs\uff0c\u5e76\u7ed3\u5408\u5fae\u8c03\u4e0e\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7b56\u7565\u589e\u5f3aLLM\u8f93\u51fa\u7a33\u5b9a\u6027\uff1b\u968f\u540e\u5c06\u8bc6\u522b\u51fa\u7684FLIMs\u7528\u4e8e\u4fee\u6b63MBFL\u4e2d\u7684\u53ef\u7591\u5ea6\u8bc4\u5206\uff0c\u6784\u5efaMBFL-FLIM\u6846\u67b6\u3002", "result": "\u5728Defects4J\u7684395\u4e2a\u7a0b\u5e8f\u7248\u672c\u4e0a\u4f7f\u75288\u79cdLLM\u8fdb\u884c\u5b9e\u9a8c\uff0cMBFL-FLIM\u5728Top-1\u6307\u6807\u4e0a\u5e73\u5747\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u591a\u5b9a\u4f4d44\u4e2a\u6545\u969c\uff0c\u4e14\u5728\u591a\u6545\u969c\u573a\u666f\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u5fae\u8c03\u548c\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u8bed\u4e49\u8bc6\u522b\u4e0e\u7f13\u89e3FLIMs\uff0cMBFL-FLIM\u663e\u8457\u63d0\u5347\u4e86MBFL\u7684\u6545\u969c\u5b9a\u4f4d\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408LLM\u8bed\u4e49\u5206\u6790\u4e0e\u4f20\u7edfMBFL\u6d41\u7a0b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.23321", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.23321", "abs": "https://arxiv.org/abs/2511.23321", "authors": ["Yifei Wang", "Jacky Keung", "Zhenyu Mao", "Jingyu Zhang", "Yuchen Cao"], "title": "Chart2Code-MoLA: Efficient Multi-Modal Code Generation via Adaptive Expert Routing", "comment": null, "summary": "Chart-to-code generation is a critical task in automated data visualization, translating complex chart structures into executable programs. While recent Multi-modal Large Language Models (MLLMs) improve chart representation, existing approaches still struggle to achieve cross-type generalization, memory efficiency, and modular design. To address these challenges, this paper proposes C2C-MoLA, a multimodal framework that synergizes Mixture of Experts (MoE) with Low-Rank Adaptation (LoRA). The MoE component uses a complexity-aware routing mechanism with domain-specialized experts and load-balanced sparse gating, dynamically allocating inputs based on learnable structural metrics like element count and chart complexity. LoRA enables parameter-efficient updates for resource-conscious tuning, further supported by a tailored training strategy that aligns routing stability with semantic accuracy. Experiments on Chart2Code-160k show that the proposed model improves generation accuracy by up to 17%, reduces peak GPU memory by 18%, and accelerates convergence by 20%, when compared to standard fine-tuning and LoRA-only baselines, particularly on complex charts. Ablation studies validate optimal designs, such as 8 experts and rank-8 LoRA, and confirm scalability for real-world multimodal code generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faC2C-MoLA\u6846\u67b6\uff0c\u7ed3\u5408Mixture of Experts\uff08MoE\uff09\u4e0eLow-Rank Adaptation\uff08LoRA\uff09\uff0c\u5728Chart-to-code\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u751f\u6210\u51c6\u786e\u6027\u3001\u5185\u5b58\u6548\u7387\u548c\u8bad\u7ec3\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u96be\u4ee5\u517c\u987e\u8de8\u7c7b\u578b\u6cdb\u5316\u80fd\u529b\u3001\u5185\u5b58\u6548\u7387\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u591a\u6a21\u6001\u6a21\u578b\u67b6\u6784\u3002", "method": "C2C-MoLA\u91c7\u7528\u590d\u6742\u5ea6\u611f\u77e5\u7684MoE\u8def\u7531\u673a\u5236\uff0c\u7ed3\u5408\u9886\u57df\u4e13\u5bb6\u548c\u8d1f\u8f7d\u5747\u8861\u7a00\u758f\u95e8\u63a7\uff0c\u5e76\u5229\u7528LoRA\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff1b\u540c\u65f6\u8bbe\u8ba1\u5bf9\u9f50\u8def\u7531\u7a33\u5b9a\u6027\u4e0e\u8bed\u4e49\u51c6\u786e\u6027\u7684\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728Chart2Code-160k\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u6807\u51c6\u5fae\u8c03\u548c\u4ec5LoRA\u57fa\u7ebf\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534717%\uff0c\u5cf0\u503cGPU\u5185\u5b58\u51cf\u5c1118%\uff0c\u6536\u655b\u901f\u5ea6\u52a0\u5feb20%\u3002", "conclusion": "C2C-MoLA\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u591a\u6a21\u6001\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
