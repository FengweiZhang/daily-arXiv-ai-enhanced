<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 1]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.CE](#cs.CE) [Total: 2]
- [cs.SE](#cs.SE) [Total: 8]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [An Efficient Proximity Graph-based Approach to Table Union Search](https://arxiv.org/abs/2511.05082)
*Yiming Xie,Hua Dai,Mingfeng Jiang,Pengyue Li,zhengkai Zhang,Bohan Li*

Main category: cs.DB

TL;DR: 本文提出了一种基于邻近图的高效表联合搜索方法（PGTUS），通过多阶段流程和增强剪枝策略，在保持召回率的同时显著提升搜索速度。


<details>
  <summary>Details</summary>
Motivation: 多向量表征虽能提升语义对齐精度，但因依赖二分图最大匹配计算联合性得分，导致效率低下，亟需更高效的解决方案。

Method: PGTUS采用多阶段流程，结合新颖的精炼策略、基于多对一二分匹配的过滤策略以及增强的剪枝策略，以提升表联合搜索效率。

Result: 在六个基准数据集上的实验表明，该方法相比现有方法提速3.6–6.0倍，同时保持相当的召回率。

Conclusion: 所提出的PGTUS方法在不牺牲检索质量的前提下，有效解决了多向量模型在表联合搜索中的效率瓶颈问题。

Abstract: Neural embedding models are extensively employed in the table union search
problem, which aims to find semantically compatible tables that can be merged
with a given query table. In particular, multi-vector models, which represent a
table as a vector set (typically one vector per column), have been demonstrated
to achieve superior retrieval quality by capturing fine-grained semantic
alignments. However, this problem faces more severe efficiency challenges than
the single-vector problem due to the inherent dependency on bipartite graph
maximum matching to compute unionability scores. Therefore, this paper proposes
an efficient Proximity Graph-based Table Union Search (PGTUS) approach. PGTUS
employs a multi-stage pipeline that combines a novel refinement strategy, a
filtering strategy based on many-to-one bipartite matching. Besides, we propose
an enhanced pruning strategy to prune the candidate set, which further improve
the search efficiency. Extensive experiments on six benchmark datasets
demonstrate that our approach achieves 3.6-6.0X speedup over existing
approaches while maintaining comparable recall rates.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [2] [RAS: A Bit-Exact rANS Accelerator For High-Performance Neural Lossless Compression](https://arxiv.org/abs/2511.04684)
*Yuchao Qin,Anjunyi Fan,Bonan Yan*

Main category: cs.AR

TL;DR: 本文提出了RAS（Range Asymmetric Numeral System Acceleration System），一种用于加速基于rANS算法的神经无损压缩的硬件架构。通过将概率分布以BF16格式存储、统一除法/取模数据通路、两阶段rANS更新、预测引导解码和多通道设计，显著提升了编解码速度并降低了内存开销，在图像任务中相比Python基线实现了超过70倍的解码加速。


<details>
  <summary>Details</summary>
Motivation: 现有基于概率模型的无损压缩方法计算效率低，难以满足数据中心对高速压缩的需求，亟需一种能兼顾压缩率与速度的硬件加速方案。

Method: 提出RAS硬件架构，集成rANS算法，采用BF16格式存储分布、固定点域统一除法/取模通路、两阶段rANS更新配合字节级重归一化、预测引导的CDF搜索窗口缩小机制以及多通道结构实现高效调度与吞吐扩展。

Result: 在RTL仿真中，RAS在图像负载上相比Python rANS基线实现121.2倍编码和70.9倍解码加速，平均解码二分搜索步数从7.00降至3.15（减少约55%），且在搭配神经概率模型时压缩率优于传统编解码器，并超越CPU/GPU上的rANS实现。

Conclusion: RAS为神经无损压缩提供了一种实用且高效的硬件加速方案，在保持高压缩率的同时显著提升处理速度，适用于数据中心等高性能场景。

Abstract: Data centers handle vast volumes of data that require efficient lossless
compression, yet emerging probabilistic models based methods are often
computationally slow. To address this, we introduce RAS, the Range Asymmetric
Numeral System Acceleration System, a hardware architecture that integrates the
rANS algorithm into a lossless compression pipeline and eliminates key
bottlenecks. RAS couples an rANS core with a probabilistic generator, storing
distributions in BF16 format and converting them once into a fixed-point domain
shared by a unified division/modulo datapath. A two-stage rANS update with
byte-level re-normalization reduces logic cost and memory traffic, while a
prediction-guided decoding path speculatively narrows the cumulative
distribution function (CDF) search window and safely falls back to maintain
bit-exactness. A multi-lane organization scales throughput and enables
fine-grained clock gating for efficient scheduling. On image workloads, our
RTL-simulated prototype achieves 121.2x encode and 70.9x decode speedups over a
Python rANS baseline, reducing average decoder binary-search steps from 7.00 to
3.15 (approximately 55% fewer). When paired with neural probability models, RAS
sustains higher compression ratios than classical codecs and outperforms
CPU/GPU rANS implementations, offering a practical approach to fast neural
lossless compression.

</details>


### [3] [Eliminating the Hidden Cost of Zone Management in ZNS SSDs](https://arxiv.org/abs/2511.04687)
*Teona Bagashvili,Tarikul Islam Papon,Subhadeep Sarkar,Manos Athanassoulis*

Main category: cs.AR

TL;DR: SilentZNS 是一种新型 ZNS SSD 区映射与管理方法，通过动态分配物理资源、避免全区域操作和冗余写入，显著降低设备级写放大、磨损并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前 Zoned Namespace（ZNS）SSD 存在设备级写放大（DLWA）、磨损加剧以及因区域映射和管理导致的主机 I/O 干扰等问题，主要源于固定物理区域和全区域操作的设计缺陷。

Method: 提出 SilentZNS 方法，摒弃传统的逻辑到物理区域映射，采用灵活的块级区域分配机制，在运行时动态分配可用资源，并引入约束以保证磨损均衡和高性能读取，同时避免区域重置时的无效写入。

Result: 基于 ConfZNS++ 模拟器实现的实验表明，SilentZNS 可将无效写入减少最多 20 倍，在 10% 区域占用率下 DLWA 降低 86%，整体磨损减少高达 76.9%，工作负载执行速度提升最高达 3.7 倍。

Conclusion: SilentZNS 有效解决了现有 ZNS SSD 的关键瓶颈，显著提升了存储效率、寿命和性能，为未来高效能存储系统提供了可行路径。

Abstract: Zoned Namespace (ZNS) SSDs offer a promising interface for stable throughput
and low-latency storage by eliminating device-side garbage collection. They
expose storage as append-only zones that give the host applications direct
control over data placement. However, current ZNS implementations suffer from
(a) device-level write amplification (DLWA), (b) increased wear, and (c)
interference with host I/O due to zone mapping and management. We identify two
primary design decisions as the main cause: (i) fixed physical zones and (ii)
full-zone operations that lead to excessive physical writes. We propose
SilentZNS, a new zone mapping and management approach that addresses the
aforementioned limitations by on-the-fly allocating available resources to
zones, while minimizing wear, maintaining parallelism, and avoiding unnecessary
writes at the device-level. SilentZNS is a flexible zone allocation scheme that
departs from the traditional logical-to-physical zone mapping and allows for
arbitrary collections of blocks to be assigned to a zone. We add the necessary
constraints to ensure wear-leveling and state-of-the-art read performance, and
use only the required blocks to avoid dummy writes during zone reset. We
implement SilentZNS using the state-of-the-art ConfZNS++ emulator and show that
it eliminates the undue burden of dummy writes by up to 20x, leading to lower
DLWA (86% less at 10% zone occupancy), less overall wear (up to 76.9%), and up
to 3.7x faster workload execution.

</details>


### [4] [MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars](https://arxiv.org/abs/2511.04798)
*Matheus Farias,Wanghley Martins,H. T. Kung*

Main category: cs.AR

TL;DR: MDM 是一种用于忆阻器位切片存内计算（CIM）交叉阵列的训练后权重映射技术，通过优化活跃忆阻器的位置来减轻寄生电阻（PR）非理想性，从而提升模型精度与硬件效率。


<details>
  <summary>Details</summary>
Motivation: 寄生电阻（PR）限制了 CIM 交叉阵列的效率，迫使 DNN 权重矩阵被划分为小块，导致模拟-数字转换增多、延迟增加、I/O 压力增大和芯片面积上升。因此需要一种方法在不改变硬件结构的前提下缓解 PR 影响。

Method: MDM 利用位级结构稀疏性，将来自低阶密集侧的激活输入交叉阵列，并根据曼哈顿距离对行进行重排序，将活跃单元移至受 PR 影响较小的区域，从而降低非理想性因子（NF）。

Result: 在 ImageNet-1k 上对 DNN 模型应用 MDM 后，非理想性因子最多降低 46%，在 ResNet 中平均精度提升 3.6%。

Conclusion: MDM 提供了一种轻量且具有空间感知能力的方法，有助于扩展 CIM DNN 加速器的规模并提升其在模拟非理想条件下的性能。

Abstract: Manhattan Distance Mapping (MDM) is a post-training deep neural network (DNN)
weight mapping technique for memristive bit-sliced compute-in-memory (CIM)
crossbars that reduces parasitic resistance (PR) nonidealities.
  PR limits crossbar efficiency by mapping DNN matrices into small crossbar
tiles, reducing CIM-based speedup. Each crossbar executes one tile, requiring
digital synchronization before the next layer. At this granularity, designers
either deploy many small crossbars in parallel or reuse a few sequentially-both
increasing analog-to-digital conversions, latency, I/O pressure, and chip area.
  MDM alleviates PR effects by optimizing active-memristor placement.
Exploiting bit-level structured sparsity, it feeds activations from the denser
low-order side and reorders rows according to the Manhattan distance,
relocating active cells toward regions less affected by PR and thus lowering
the nonideality factor (NF).
  Applied to DNN models on ImageNet-1k, MDM reduces NF by up to 46% and
improves accuracy under analog distortion by an average of 3.6% in ResNets.
Overall, it provides a lightweight, spatially informed method for scaling CIM
DNN accelerators.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [5] [EPFL-REMNet: Efficient Personalized Federated Digital Twin Towards 6G Heterogeneous Radio Environme](https://arxiv.org/abs/2511.05238)
*Peide Li,Liu Cao,Lyutianyang Zhang,Dongyu Wei,Ye Hu,Qipeng Xie*

Main category: cs.NI

TL;DR: 本文提出EPFL-REMNet，一种面向6G异构无线环境的高效个性化联邦学习框架，通过“共享主干+轻量级个性化头”结构，在Non-IID数据条件下同时提升数字孪生精度并降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 标准联邦学习在构建6G异构无线环境数字孪生（如无线电环境图REM）时，因Non-IID数据分布导致准确性和通信效率下降，亟需更高效的个性化联邦学习方法。

Method: EPFL-REMNet采用“共享主干+轻量级个性化头”的模型架构，仅在服务器与客户端间传输压缩后的共享主干，个性化头部则保留在本地；实验基于90个地理分区客户端构建三种Non-IID场景（轻度、中度、重度）进行验证。

Result: EPFL-REMNet在所有Non-IID设置下均优于FedAvg及最新方法，不仅提高了数字孪生保真度和上行链路效率，还显著缩小了不同客户端间的性能差距，尤其改善了长尾客户端的本地地图精度。

Conclusion: EPFL-REMNet有效解决了6G异构环境中Non-IID数据带来的联邦学习挑战，为高保真、低开销的无线电环境图构建提供了可行方案，增强了数字孪生的整体完整性。

Abstract: Radio Environment Map (REM) is transitioning from 5G homogeneous environments
to B5G/6G heterogeneous landscapes. However, standard Federated Learning (FL),
a natural fit for this distributed task, struggles with performance degradation
in accuracy and communication efficiency under the non-independent and
identically distributed (Non-IID) data conditions inherent to these new
environments. This paper proposes EPFL-REMNet, an efficient personalized
federated framework for constructing a high-fidelity digital twin of the 6G
heterogeneous radio environment. The proposed EPFL-REMNet employs a"shared
backbone + lightweight personalized head" model, where only the compressed
shared backbone is transmitted between the server and clients, while each
client's personalized head is maintained locally. We tested EPFL-REMNet by
constructing three distinct Non-IID scenarios (light, medium, and heavy) based
on radio environment complexity, with data geographically partitioned across 90
clients. Experimental results demonstrate that EPFL-REMNet simultaneously
achieves higher digital twin fidelity (accuracy) and lower uplink overhead
across all Non-IID settings compared to standard FedAvg and recent
state-of-the-art methods. Particularly, it significantly reduces performance
disparities across datasets and improves local map accuracy for long-tail
clients, enhancing the overall integrity of digital twin.

</details>


### [6] [A Formal Model for Path Set Attribute Calculation in Network Systems](https://arxiv.org/abs/2511.05334)
*Giovanni Fiaschi,Carlo Vitucci,Thomas Westerbäck,Daniel Sundmark,Thomas Nolte*

Main category: cs.NI

TL;DR: 本文提出了一种用于刻画路径集合的泛化函数模型，强调在多路径选择中需依据不同属性对路径集合进行特征化分析。


<details>
  <summary>Details</summary>
Motivation: 现有研究对单条路径的评估较为完善，但在路径集合层面缺乏同等细致的分析；而路径集合的特性高度依赖于所考虑的属性，因此需要一种系统性的刻画方法。

Method: 提出一个通用的函数模型，用于形式化地描述和分析路径集合，并展示该模型如何结合具体属性进行上下文化建模。

Result: 该函数模型能够有效表征路径集合的整体特性，并为不同属性下的路径选择提供理论支持。

Conclusion: 路径集合的刻画必须基于其所关注的属性，本文提出的函数模型为此提供了一个灵活且通用的数学框架。

Abstract: In graph theory and its practical networking applications, e.g.,
telecommunications and transportation, the problem of finding paths has
particular importance. Selecting paths requires giving scores to the
alternative solutions to drive a choice. While previous studies have provided
comprehensive evaluation of single-path solutions, the same level of detail is
lacking when considering sets of paths. This paper emphasizes that the path
characterization strongly depends on the properties under consideration. While
property-based characterization is also valid for single paths, it becomes
crucial to analyse multiple path sets. From the above consideration, this paper
proposes a mathematical approach, defining a functional model that lends itself
well to characterizing the path set in its general formulation. The paper shows
how the functional model contextualizes specific attributes.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [7] [Marionette: Data Structure Description and Management for Heterogeneous Computing](https://arxiv.org/abs/2511.04853)
*Nuno dos Santos Fernandes,Pedro Tomás,Nuno Roma,Frank Winklmeier,Patricia Conde-Muíño*

Main category: cs.DC

TL;DR: Marionette 是一个 C++17 库，通过在编译时解耦数据布局与接口定义，支持多种内存管理策略和高效跨设备数据传输，从而简化面向对象 C++ 代码在异构硬件（如 GPU）上的加速。


<details>
  <summary>Details</summary>
Motivation: 将大型面向对象的 C++ 代码库适配到异构硬件（如 GPU）进行加速极具挑战性，主要难点在于数据布局、内存管理和跨设备数据传输的复杂性。

Method: Marionette 利用 C++17 的编译期抽象机制，将数据布局与接口描述解耦，支持灵活的内存管理策略，并允许对接口添加任意函数以兼容现有代码。

Result: 通过 CUDA 案例研究验证了 Marionette 在保持代码兼容性的同时，实现了高效且灵活的硬件加速，运行时开销极小。

Conclusion: Marionette 为 C++ 开发者提供了一种高效、可移植且易于集成的方法，用于在异构平台上加速现有面向对象代码。

Abstract: Adapting large, object-oriented C++ codebases for hardware acceleration might
be extremely challenging, particularly when targeting heterogeneous platforms
such as GPUs. Marionette is a C++17 library designed to address this by
enabling flexible, efficient, and portable data structure definitions. It
decouples data layout from the description of the interface, supports multiple
memory management strategies, and provides efficient data transfers and
conversions across devices, all of this with minimal runtime overhead due to
the compile-time nature of its abstractions. By allowing interfaces to be
augmented with arbitrary functions, Marionette maintains compatibility with
existing code and offers a streamlined interface that supports both
straightforward and advanced use cases. This paper outlines its design, usage,
and performance, including a CUDA-based case study demonstrating its efficiency
and flexibility.

</details>


### [8] [GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters](https://arxiv.org/abs/2511.05067)
*Giuseppe Esposito,Juan-David Guerrero-Balaguera,Josie Esteban Rodriguez Condia,Matteo Sonza Reorda,Marco Barbiero,Rossella Fortuna*

Main category: cs.DC

TL;DR: 本文提出一种结合在线遥测参数与硬件性能计数器的方法，用于评估GPU在不同应用负载下的应力水平，从而预测其可靠性（尤其关注老化效应）。


<details>
  <summary>Details</summary>
Motivation: 由于持续高负载可能导致GPU组件发生故障，进而影响计算结果的正确性，因此有必要准确估计应用程序对GPU造成的应力，以预测其可靠性，特别是老化带来的影响。

Method: 结合GPU的在线遥测数据与硬件性能计数器（重点关注吞吐量、发出指令数量和停顿事件）来评估不同并行工作负载所引起的GPU应力。

Result: 实验结果表明，通过所选的遥测数据与性能计数器组合，可以有效估计并行工作负载对GPU造成的应力。

Conclusion: 利用遥测参数与特定性能计数器的组合，能够有效评估GPU在运行不同应用时的应力水平，为可靠性预测提供支持。

Abstract: Graphics Processing Units (GPUs) are specialized accelerators in data centers
and high-performance computing (HPC) systems, enabling the fast execution of
compute-intensive applications, such as Convolutional Neural Networks (CNNs).
However, sustained workloads can impose significant stress on GPU components,
raising reliability concerns due to potential faults that corrupt the
intermediate application computations, leading to incorrect results. Estimating
the stress induced by an application is thus crucial to predict reliability
(with\,special\,emphasis\,on\,aging\,effects). In this work, we combine online
telemetry parameters and hardware performance counters to assess GPU stress
induced by different applications. The experimental results indicate the stress
induced by a parallel workload can be estimated by combining telemetry data and
Performance Counters that reveal the efficiency in the resource usage of the
target workload. For this purpose the selected performance counters focus on
measuring the i) throughput, ii) amount of issued instructions and iii) stall
events.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [9] [Connectomics Informed by Large Language Models](https://arxiv.org/abs/2511.05383)
*Elinor Thompson,Tiantian He,Anna Schroder,Ahmed Abdulaal,Alec Sargood,Sonja Soskic,Henry F. J. Tregidgo,Daniel C. Alexander*

Main category: cs.CE

TL;DR: 本文提出利用大语言模型（LLM）生成定量先验知识，以提升脑连接组学中纤维束成像的准确性，并验证了这些先验在保留真实连接和改进病理传播模型方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 纤维束成像算法在敏感性与特异性之间存在固有权衡，限制了其准确性；虽然引入白质解剖先验知识可提升准确性，但在连接组学中难以扩展至数千种可能连接。

Method: 开发了一个基于大语言模型的流程，利用其神经解剖知识生成连接组学的定量先验；通过黄金标准图谱评估提示策略，并整合外部知识源以提高准确性；将LLM先验用于增强现有纤维束过滤方法。

Result: 实验表明，LLM能有效提供准确的连接信息；结合外部知识可进一步提升性能；LLM保留的真实阳性连接提高了基于连接组的病理传播模型的准确性。

Conclusion: 利用大语言模型生成解剖先验是一种可行且有效的策略，可显著提升纤维束成像在连接组学中的准确性，并对神经疾病建模具有潜在价值。

Abstract: Tractography is a unique method for mapping white matter connections in the
brain, but tractography algorithms suffer from an inherent trade-off between
sensitivity and specificity that limits accuracy. Incorporating prior knowledge
of white matter anatomy is an effective strategy for improving accuracy and has
been successful for reducing false positives and false negatives in
bundle-mapping protocols. However, it is challenging to scale this approach for
connectomics due to the difficulty in synthesising information relating to many
thousands of possible connections. In this work, we develop and evaluate a
pipeline using large language models (LLMs) to generate quantitative priors for
connectomics, based on their knowledge of neuroanatomy. We benchmark our
approach against an evaluation set derived from a gold-standard tractography
atlas, identifying prompting techniques to elicit accurate connectivity
information from the LLMs. We further identify strategies for incorporating
external knowledge sources into the pipeline, which can provide grounding for
the LLM and improve accuracy. Finally, we demonstrate how the LLM-derived
priors can augment existing tractography filtering approaches by identifying
true-positive connections to retain during the filtering process. We show that
these additional connections can improve the accuracy of a connectome-based
model of pathology spread, which provides supporting evidence that the
connections preserved by the LLM are valid.

</details>


### [10] [Block-structured Operator Inference for coupled multiphysics model reduction](https://arxiv.org/abs/2511.05389)
*Benjamin G. Zastrow,Anirban Chaudhuri,Karen E. Willcox,Anthony Ashley,Michael Chamberlain Henson*

Main category: cs.CE

TL;DR: 本文提出了一种分块结构化的算子推断方法，用于为多物理场系统构建结构保持的降阶模型，在保证精度的同时提升了在线预测速度。


<details>
  <summary>Details</summary>
Motivation: 传统单体式算子推断方法在处理多物理场系统时难以保留物理结构，且维度高、正则化策略单一，限制了模型性能与效率。

Method: 通过显式指定各物理场组件的控制方程结构及其耦合项结构，采用非侵入式算子推断方法从快照数据中学习分块结构化的降阶模型，并对每个物理组件施加定制化正则化。

Result: 在AGARD 445.6机翼气动弹性分析案例中，该方法在亚音速和超音速条件下（包括稳定与颤振工况）相比单体式方法平均提升20%的在线预测速度，同时保持相同精度。

Conclusion: 分块结构化算子推断不仅能有效保留多物理场系统的结构特性（如稳定性），还能降低学习问题维度并提升计算效率，是构建高效高保真降阶模型的有效途径。

Abstract: This paper presents a block-structured formulation of Operator Inference as a
way to learn structured reduced-order models for multiphysics systems. The
approach specifies the governing equation structure for each physics component
and the structure of the coupling terms. Once the multiphysics structure is
specified, the reduced-order model is learned from snapshot data following the
nonintrusive Operator Inference methodology. In addition to preserving physical
system structure, which in turn permits preservation of system properties such
as stability and second-order structure, the block-structured approach has the
advantages of reducing the overall dimensionality of the learning problem and
admitting tailored regularization for each physics component. The numerical
advantages of the block-structured formulation over a monolithic Operator
Inference formulation are demonstrated for aeroelastic analysis, which couples
aerodynamic and structural models. For the benchmark test case of the AGARD
445.6 wing, block-structured Operator Inference provides an average 20% online
prediction speedup over monolithic Operator Inference across subsonic and
supersonic flow conditions in both the stable and fluttering parameter regimes
while preserving the accuracy achieved with monolithic Operator Inference.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [11] [Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach](https://arxiv.org/abs/2511.04849)
*Quang-Dung Nguyen,Tri-Dung Tran,Thanh-Hieu Chu,Hoang-Loc Tran,Xiangwei Cheng,Dirk Slama*

Main category: cs.SE

TL;DR: 本文研究通过提示工程引导大语言模型（LLMs）生成软件定义车辆（SDV）代码，发现少样本提示策略在无需模型训练的情况下表现最优。


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆（SDV）的兴起要求高效开发专用应用，而通用大语言模型因架构封闭难以适配SDV代码生成任务，因此需要一种无需训练即可引导模型的方法。

Method: 采用系统提示结合高级提示工程技术，在不访问模型底层架构或进行训练的前提下，对多个大语言模型进行实验，并使用专为SDV代码生成设计的基准评估不同提示策略的效果。

Result: 实验结果表明，采用少样本（few-shot）提示策略的模型在定量指标上优于其他方法，能更准确地生成符合预期的SDV代码。

Conclusion: 通过精心设计的提示结构，尤其是少样本提示，可有效引导大语言模型完成SDV代码生成任务，显著提升开发效率，且无需模型微调或访问其内部结构。

Abstract: The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in
the automotive industry, where software now plays a pivotal role in defining
vehicle functionality, enabling rapid innovation of modern vehicles. Developing
SDV-specific applications demands advanced tools to streamline code generation
and improve development efficiency. In recent years, general-purpose large
language models (LLMs) have demonstrated transformative potential across
domains. Still, restricted access to proprietary model architectures hinders
their adaption to specific tasks like SDV code generation. In this study, we
propose using prompts, a common and basic strategy to interact with LLMs and
redirect their responses. Using only system prompts with an appropriate and
efficient prompt structure designed using advanced prompt engineering
techniques, LLMs can be crafted without requiring a training session or access
to their base design. This research investigates the extensive experiments on
different models by applying various prompting techniques, including bare
models, using a benchmark specifically created to evaluate LLMs' performance in
generating SDV code. The results reveal that the model with a few-shot
prompting strategy outperforms the others in adjusting the LLM answers to match
the expected outcomes based on quantitative metrics.

</details>


### [12] [What About Our Bug? A Study on the Responsiveness of NPM Package Maintainers](https://arxiv.org/abs/2511.04986)
*Mohammadreza Saeidi,Ethan Thoma,Raula Gaikovina Kula,Gema Rodríguez-Pérez*

Main category: cs.SE

TL;DR: 该研究调查了npm生态系统中500个最被依赖的包的30,340份bug报告，发现维护者整体响应率较高（中位数为70%），但部分bug未被修复的原因包括贡献规范、依赖约束和库特定标准等因素。


<details>
  <summary>Details</summary>
Motivation: 第三方库的广泛使用使npm等生态系统对现代软件开发至关重要，但依赖链中的bug可能向下传播，影响众多项目。作者假设维护者未必总会修复bug，尤其是当他们认为该问题不在其责任范围内时。

Method: 采用混合方法，挖掘仓库issue数据，并通过定性开放式编码分析未处理bug报告背后的原因。

Result: 维护者总体响应积极，项目层面的中位响应率为70%（四分位距：55%-89%）；同时归纳出若干导致bug未被修复的原因类别。

Conclusion: 提出了一个关于未修复bug原因的分类体系，涵盖贡献实践、依赖约束和库特定标准等方面，有助于促进更稳健、响应更及时的开源生态。

Abstract: Background: Widespread use of third-party libraries makes ecosystems like
Node Package Manager (npm) critical to modern software development. However,
this interconnected chain of dependencies also creates challenges: bugs in one
library can propagate downstream, potentially impacting many other libraries
that rely on it. We hypothesize that maintainers may not always decide to fix a
bug, especially if the maintainer decides it falls out of their responsibility
within the chain of dependencies. Aims: To confirm this hypothesis, we
investigate the responsiveness of 30,340 bug reports across 500 of the most
depended-upon npm packages. Method: We adopt a mixed-method approach to mine
repository issue data and perform qualitative open coding to analyze reasons
behind unaddressed bug reports. Results: Our findings show that maintainers are
generally responsive, with a median project-level responsiveness of 70% (IQR:
55%-89%), reflecting their commitment to support downstream developers.
Conclusions: We present a taxonomy of the reasons some bugs remain unresolved.
The taxonomy includes contribution practices, dependency constraints, and
library-specific standards as reasons for not being responsive. Understanding
maintainer behavior can inform practices that promote a more robust and
responsive open-source ecosystem that benefits the entire community.

</details>


### [13] [Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model](https://arxiv.org/abs/2511.05165)
*Ahmad Hatahet,Christoph Knieke,Andreas Rausch*

Main category: cs.SE

TL;DR: 本文提出一种结合逆向工程与大语言模型（LLM）的半自动化方法，从源代码生成软件架构描述（SAD），包括静态组件图和行为状态机图，以减轻人工负担并提升系统可维护性。


<details>
  <summary>Details</summary>
Motivation: 实际中软件架构描述常缺失、过时或与实现不一致，导致开发者需耗费大量时间从代码中推导架构信息，增加认知负担、延缓新人上手，并随时间推移降低系统清晰度。

Method: 整合逆向工程技术与大语言模型（LLM），通过提取完整组件图、利用提示工程筛选核心架构元素，并基于代码逻辑使用少样本提示生成状态机图，从而恢复静态与行为架构视图。

Result: 该方法在C++示例中成功展示了LLM能有效抽象组件图并准确表达复杂行为，尤其在结合领域知识的少样本提示下表现更佳，显著减少人工参与。

Conclusion: 结合LLM与逆向工程可为软件架构文档提供一种可扩展、易维护的替代方案，有助于降低手动工作量、增强系统理解并提升长期可维护性。

Abstract: Software Architecture Descriptions (SADs) are essential for managing the
inherent complexity of modern software systems. They enable high-level
architectural reasoning, guide design decisions, and facilitate effective
communication among diverse stakeholders. However, in practice, SADs are often
missing, outdated, or poorly aligned with the system's actual implementation.
Consequently, developers are compelled to derive architectural insights
directly from source code-a time-intensive process that increases cognitive
load, slows new developer onboarding, and contributes to the gradual
degradation of clarity over the system's lifetime. To address these issues, we
propose a semi-automated generation of SADs from source code by integrating
reverse engineering (RE) techniques with a Large Language Model (LLM). Our
approach recovers both static and behavioral architectural views by extracting
a comprehensive component diagram, filtering architecturally significant
elements (core components) via prompt engineering, and generating state machine
diagrams to model component behavior based on underlying code logic with
few-shots prompting. This resulting views representation offer a scalable and
maintainable alternative to traditional manual architectural documentation.
This methodology, demonstrated using C++ examples, highlights the potent
capability of LLMs to: 1) abstract the component diagram, thereby reducing the
reliance on human expert involvement, and 2) accurately represent complex
software behaviors, especially when enriched with domain-specific knowledge
through few-shot prompting. These findings suggest a viable path toward
significantly reducing manual effort while enhancing system understanding and
long-term maintainability.

</details>


### [14] [CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits](https://arxiv.org/abs/2511.05205)
*Huimin Hu,Michael Pradel*

Main category: cs.SE

TL;DR: 本文提出了CodeMapper，一种与编程语言和程序元素无关的代码映射方法，用于在不同提交之间定位对应代码区域，在多个数据集上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 开发者在软件演化过程中常需将某一提交中的特定代码区域映射到另一提交中，但现有工具（如git diff）无法聚焦于用户指定的代码区域，而其他方法又受限于特定语言或代码元素，适用性有限。

Method: CodeMapper包含两个阶段：(i) 通过分析diff、检测代码移动和搜索特定代码片段生成候选区域；(ii) 通过计算相似度选择最可能的目标区域。

Result: 在四个数据集（包括两个涵盖十种流行语言的手动标注数据集）上的评估表明，CodeMapper在71.0%–94.5%的情况下能正确识别目标区域，比最佳基线方法高出1.5–58.8个百分点。

Conclusion: CodeMapper有效解决了通用、跨语言的代码映射问题，显著优于现有技术，具有广泛适用性和实用价值。

Abstract: During software evolution, developers commonly face the problem of mapping a
specific code region from one commit to another. For example, they may want to
determine how the condition of an if-statement, a specific line in a
configuration file, or the definition of a function changes. We call this the
code mapping problem. Existing techniques, such as git diff, address this
problem only insufficiently because they show all changes made to a file
instead of focusing on a code region of the developer's choice. Other
techniques focus on specific code elements and programming languages (e.g.,
methods in Java), limiting their applicability. This paper introduces
CodeMapper, an approach to address the code mapping problem in a way that is
independent of specific program elements and programming languages. Given a
code region in one commit, CodeMapper finds the corresponding region in another
commit. The approach consists of two phases: (i) computing candidate regions by
analyzing diffs, detecting code movements, and searching for specific code
fragments, and (ii) selecting the most likely target region by calculating
similarities. Our evaluation applies CodeMapper to four datasets, including two
new hand-annotated datasets containing code region pairs in ten popular
programming languages. CodeMapper correctly identifies the expected target
region in 71.0%--94.5% of all cases, improving over the best available
baselines by 1.5--58.8 absolute percent points.

</details>


### [15] [Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2511.05297)
*Mohammed Hilel,Yannis Karmim,Jean De Bodinat,Reda Sarehane,Antoine Gillon*

Main category: cs.SE

TL;DR: 本文提出了一种基于图的检索增强生成框架，将企业级Web应用自动转化为状态-动作知识图谱，以提升大语言模型在数字采用平台（DAP）中的准确性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前数字采用平台（DAP）依赖大量人工构建交互式引导，而直接使用大语言模型（LLM）作为虚拟助手时，由于缺乏对目标软件的结构化理解，容易产生幻觉和不可靠的回答；同时，主流LLM多为黑盒API，难以微调。

Method: 构建一个图结构的检索增强生成（Graph-based RAG）框架，通过工程流水线自动提取并结构化企业软件界面，将其转化为状态-动作知识图谱，并集成到实际DAP工作流中。

Result: 该框架已在与RAKAM和Lemon Learning合作的工业场景中部署，展示了其在可扩展性、鲁棒性和实际部署方面的有效性。

Conclusion: 结合知识图谱与检索增强生成的方法能有效提升LLM在企业软件辅助场景中的准确性和实用性，为DAP提供了一种自动化、可落地的技术路径。

Abstract: Digital Adoption Platforms (DAPs) have become essential tools for helping
employees navigate complex enterprise software such as CRM, ERP, or HRMS
systems. Companies like LemonLearning have shown how digital guidance can
reduce training costs and accelerate onboarding. However, building and
maintaining these interactive guides still requires extensive manual effort.
Leveraging Large Language Models as virtual assistants is an appealing
alternative, yet without a structured understanding of the target software,
LLMs often hallucinate and produce unreliable answers. Moreover, most
production-grade LLMs are black-box APIs, making fine-tuning impractical due to
the lack of access to model weights. In this work, we introduce a Graph-based
Retrieval-Augmented Generation framework that automatically converts enterprise
web applications into state-action knowledge graphs, enabling LLMs to generate
grounded and context-aware assistance. The framework was co-developed with the
AI enterprise RAKAM, in collaboration with Lemon Learning. We detail the
engineering pipeline that extracts and structures software interfaces, the
design of the graph-based retrieval process, and the integration of our
approach into production DAP workflows. Finally, we discuss scalability,
robustness, and deployment lessons learned from industrial use cases.

</details>


### [16] [Code Review Automation using Retrieval Augmented Generation](https://arxiv.org/abs/2511.05302)
*Qianru Meng,Xiao Zhang,Zhaochen Ren,Joost Visser*

Main category: cs.SE

TL;DR: 本文提出了一种名为RARe（Retrieval-Augmented Reviewer）的新方法，结合检索与生成技术，通过引入外部领域知识提升代码评审的准确性和具体性，在两个基准数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自动代码评审方法（包括基于深度学习的生成方法和检索方法）仍存在生成内容偏离主题或过于泛化的问题，因此需要一种能融合两者优势并引入外部知识的方法来提升评审质量。

Method: RARe利用检索增强生成（RAG）框架，通过稠密检索器从代码库中选取最相关的已有评审，将其作为上下文输入给大语言模型驱动的神经生成器，从而生成更精准、具体的代码评审。

Result: RARe在两个基准数据集上分别取得了12.32和12.96的BLEU-4分数，优于当前最先进的方法；并通过人工评估和可解释性工具的案例研究验证了其实用性和可靠性。

Conclusion: 结合检索与生成的RARe方法能有效提升自动代码评审的质量，具有良好的应用前景和实际价值。

Abstract: Code review is essential for maintaining software quality but is
labor-intensive. Automated code review generation offers a promising solution
to this challenge. Both deep learning-based generative techniques and
retrieval-based methods have demonstrated strong performance in this task.
However, despite these advancements, there are still some limitations where
generated reviews can be either off-point or overly general. To address these
issues, we introduce Retrieval-Augmented Reviewer (RARe), which leverages
Retrieval-Augmented Generation (RAG) to combine retrieval-based and generative
methods, explicitly incorporating external domain knowledge into the code
review process. RARe uses a dense retriever to select the most relevant reviews
from the codebase, which then enrich the input for a neural generator,
utilizing the contextual learning capacity of large language models (LLMs), to
produce the final review. RARe outperforms state-of-the-art methods on two
benchmark datasets, achieving BLEU-4 scores of 12.32 and 12.96, respectively.
Its effectiveness is further validated through a detailed human evaluation and
a case study using an interpretability tool, demonstrating its practical
utility and reliability.

</details>


### [17] [SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models](https://arxiv.org/abs/2511.05459)
*Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Xiaojiang Zhang,Jinghui Wang,Huiming Wang,Wenhao Zhuang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu*

Main category: cs.SE

TL;DR: 本文提出了SWE-Compass，一个覆盖8类任务、8种编程场景和10种编程语言的综合性软件工程评测基准，基于2000个来自真实GitHub PR的高质量实例，用于评估大语言模型在贴近开发者实际工作流中的编码能力。


<details>
  <summary>Details</summary>
Motivation: 现有针对大语言模型在软件工程领域的评测存在任务覆盖狭窄、语言偏向性强以及与真实开发者工作流程脱节等问题，尤其缺乏对多语言、多场景下实际编码任务的系统性评估。

Method: 构建SWE-Compass基准，整合来自GitHub真实PR的2000个高质量实例，涵盖8类任务、8种场景和10种语言，并通过系统过滤与验证确保质量；在SWE-Agent和Claude Code两个智能体框架下对10个前沿大模型进行评测。

Result: 评测揭示了不同任务类型、编程语言和场景之间的难度层级差异，验证了SWE-Compass在评估模型实际编码能力方面的有效性与区分度。

Conclusion: SWE-Compass为大语言模型在软件工程领域的评测提供了与真实开发实践对齐、结构清晰且可复现的综合性基准，有助于推动智能体编码能力的诊断与进步。

Abstract: Evaluating large language models (LLMs) for software engineering has been
limited by narrow task coverage, language bias, and insufficient alignment with
real-world developer workflows. Existing benchmarks often focus on algorithmic
problems or Python-centric bug fixing, leaving critical dimensions of software
engineering underexplored. To address these gaps, we introduce SWE-Compass1, a
comprehensive benchmark that unifies heterogeneous code-related evaluations
into a structured and production-aligned framework. SWE-Compass spans 8 task
types, 8 programming scenarios, and 10 programming languages, with 2000
high-quality instances curated from authentic GitHub pull requests and refined
through systematic filtering and validation. We benchmark ten state-of-the-art
LLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear
hierarchy of difficulty across task types, languages, and scenarios. Moreover,
by aligning evaluation with real-world developer practices, SWE-Compass
provides a rigorous and reproducible foundation for diagnosing and advancing
agentic coding capabilities in large language models.

</details>


### [18] [A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](https://arxiv.org/abs/2511.05476)
*Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy*

Main category: cs.SE

TL;DR: 本文指出当前基于准确率的评估无法充分衡量代码语言模型知识蒸馏后学生模型对教师模型行为保真度的模仿程度，为此提出了名为MetaCompress的元蜕变测试框架，通过行为保持的蜕变关系系统评估师生模型输出的一致性，并在多个任务和蒸馏方法上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于准确率的评估方法仅能表面衡量压缩后学生模型的性能，难以揭示其在预测行为和内部表示上与教师模型的深层差异，尤其在面对对抗攻击时表现显著下降，因此需要一种更深入的行为保真度评估方法。

Method: 提出MetaCompress框架，利用一组行为保持的蜕变关系，系统比较教师模型与学生模型的输出，从而评估知识蒸馏过程中学生模型对教师模型行为的模仿程度。

Result: 在两个典型任务和三种知识蒸馏方法（Compressor、AVATAR、MORPH）上实验表明，MetaCompress最多可识别出62%的学生模型行为不一致问题，且学生模型在对抗攻击下性能下降高达285%，远超传统评估所能发现的问题。

Conclusion: 传统准确率评估不足以反映知识蒸馏后模型的行为保真度，MetaCompress提供了一种有效且实用的测试框架，应被纳入代码语言模型压缩流程中以保障模型质量。

Abstract: Transformer-based language models of code have achieved state-of-the-art
performance across a wide range of software analytics tasks, but their
practical deployment remains limited due to high computational costs, slow
inference speeds, and significant environmental impact. To address these
challenges, recent research has increasingly explored knowledge distillation as
a method for compressing a large language model of code (the teacher) into a
smaller model (the student) while maintaining performance. However, the degree
to which a student model deeply mimics the predictive behavior and internal
representations of its teacher remains largely unexplored, as current
accuracy-based evaluation provides only a surface-level view of model quality
and often fails to capture more profound discrepancies in behavioral fidelity
between the teacher and student models. To address this gap, we empirically
show that the student model often fails to deeply mimic the teacher model,
resulting in up to 285% greater performance drop under adversarial attacks,
which is not captured by traditional accuracy-based evaluation. Therefore, we
propose MetaCompress, a metamorphic testing framework that systematically
evaluates behavioral fidelity by comparing the outputs of teacher and student
models under a set of behavior-preserving metamorphic relations. We evaluate
MetaCompress on two widely studied tasks, using compressed versions of popular
language models of code, obtained via three different knowledge distillation
techniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress
identifies up to 62% behavioral discrepancies in student models, underscoring
the need for behavioral fidelity evaluation within the knowledge distillation
pipeline and establishing MetaCompress as a practical framework for testing
compressed language models of code derived through knowledge distillation.

</details>
